<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pl" xml:lang="pl"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Zaawansowane metody uczenia maszynowego - 6&nbsp; Modele językowe</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./rnn.html" rel="prev">
<link href="./images/cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Brak wyników",
    "search-matching-documents-text": "dopasowane dokumenty",
    "search-copy-link-title": "Kopiuj link do wyszukiwania",
    "search-hide-matches-text": "Ukryj dodatkowe dopasowania",
    "search-more-match-text": "więcej dopasowań w tym dokumencie",
    "search-more-matches-text": "więcej dopasowań w tym dokumencie",
    "search-clear-button-title": "Wyczyść",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Anuluj",
    "search-submit-button-title": "Zatwierdź",
    "search-label": "Szukaj"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Przełącz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./llm.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modele językowe</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Przełącz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Zaawansowane metody uczenia maszynowego</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://twitter.com" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
    <a href="https://github.com/dax44/AMLM/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/intent/tweet?url=%7Curl%7C" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Przełącz tryb ciemny"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Przełącz tryb czytnika">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Szukaj"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wstęp</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Wprowadzenie</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multi_target_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Modele z wieloma wyjściami</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Przykłady - metody klasyczne</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./examples2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Przykłady NN</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">DNN dla danych sekwencyjnych</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./llm.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modele językowe</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Literatura</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Spis treści</h2>
   
  <ul>
<li><a href="#rys-historyczny" id="toc-rys-historyczny" class="nav-link active" data-scroll-target="#rys-historyczny"><span class="header-section-number">6.1</span> Rys historyczny</a></li>
  <li>
<a href="#dane-tekstowe" id="toc-dane-tekstowe" class="nav-link" data-scroll-target="#dane-tekstowe"><span class="header-section-number">7</span> Dane tekstowe</a>
  <ul class="collapse">
<li><a href="#standaryzacja-tekstu" id="toc-standaryzacja-tekstu" class="nav-link" data-scroll-target="#standaryzacja-tekstu"><span class="header-section-number">7.1</span> Standaryzacja tekstu</a></li>
  <li><a href="#tokenizacja" id="toc-tokenizacja" class="nav-link" data-scroll-target="#tokenizacja"><span class="header-section-number">7.2</span> Tokenizacja</a></li>
  <li><a href="#indeksowanie-s%C5%82ownika" id="toc-indeksowanie-słownika" class="nav-link" data-scroll-target="#indeksowanie-s%C5%82ownika"><span class="header-section-number">7.3</span> Indeksowanie słownika</a></li>
  <li><a href="#one-hot-encoding" id="toc-one-hot-encoding" class="nav-link" data-scroll-target="#one-hot-encoding"><span class="header-section-number">7.4</span> One-hot encoding</a></li>
  <li>
<a href="#tokenizacja-na-przyk%C5%82adach" id="toc-tokenizacja-na-przykładach" class="nav-link" data-scroll-target="#tokenizacja-na-przyk%C5%82adach"><span class="header-section-number">7.5</span> Tokenizacja na przykładach</a>
  <ul class="collapse">
<li><a href="#przygotowanie-danych-imdb" id="toc-przygotowanie-danych-imdb" class="nav-link" data-scroll-target="#przygotowanie-danych-imdb"><span class="header-section-number">7.5.1</span> Przygotowanie danych IMDB</a></li>
  <li><a href="#modelowanie-za-pomoc%C4%85-bag-of-words" id="toc-modelowanie-za-pomocą-bag-of-words" class="nav-link" data-scroll-target="#modelowanie-za-pomoc%C4%85-bag-of-words"><span class="header-section-number">7.5.2</span> Modelowanie za pomocą bag-of-words</a></li>
  <li><a href="#modelowanie-za-pomoc%C4%85-sekwencji" id="toc-modelowanie-za-pomocą-sekwencji" class="nav-link" data-scroll-target="#modelowanie-za-pomoc%C4%85-sekwencji"><span class="header-section-number">7.5.3</span> Modelowanie za pomocą sekwencji</a></li>
  </ul>
</li>
  <li>
<a href="#osadzenia" id="toc-osadzenia" class="nav-link" data-scroll-target="#osadzenia"><span class="header-section-number">7.6</span> Osadzenia</a>
  <ul class="collapse">
<li><a href="#osadzenie-po%C5%82%C4%85czone-z-sieci%C4%85" id="toc-osadzenie-połączone-z-siecią" class="nav-link" data-scroll-target="#osadzenie-po%C5%82%C4%85czone-z-sieci%C4%85"><span class="header-section-number">7.6.1</span> Osadzenie połączone z siecią</a></li>
  <li><a href="#u%C5%BCycie-wst%C4%99pnie-wytrenowanego-osadzenia" id="toc-użycie-wstępnie-wytrenowanego-osadzenia" class="nav-link" data-scroll-target="#u%C5%BCycie-wst%C4%99pnie-wytrenowanego-osadzenia"><span class="header-section-number">7.6.2</span> Użycie wstępnie wytrenowanego osadzenia</a></li>
  </ul>
</li>
  <li>
<a href="#transformery" id="toc-transformery" class="nav-link" data-scroll-target="#transformery"><span class="header-section-number">7.7</span> Transformery</a>
  <ul class="collapse">
<li><a href="#warstwy-atencji" id="toc-warstwy-atencji" class="nav-link" data-scroll-target="#warstwy-atencji"><span class="header-section-number">7.7.1</span> Warstwy atencji</a></li>
  <li><a href="#uog%C3%B3lnienie-samo-atencji" id="toc-uogólnienie-samo-atencji" class="nav-link" data-scroll-target="#uog%C3%B3lnienie-samo-atencji"><span class="header-section-number">7.7.2</span> Uogólnienie samo-atencji</a></li>
  <li><a href="#atencja-typu-multi-head" id="toc-atencja-typu-multi-head" class="nav-link" data-scroll-target="#atencja-typu-multi-head"><span class="header-section-number">7.7.3</span> Atencja typu <em>multi-head</em></a></li>
  <li><a href="#enkoder-transformera" id="toc-enkoder-transformera" class="nav-link" data-scroll-target="#enkoder-transformera"><span class="header-section-number">7.7.4</span> Enkoder transformera</a></li>
  <li><a href="#kodowanie-pozycyjne" id="toc-kodowanie-pozycyjne" class="nav-link" data-scroll-target="#kodowanie-pozycyjne"><span class="header-section-number">7.7.5</span> Kodowanie pozycyjne</a></li>
  </ul>
</li>
  <li><a href="#wskaz%C3%B3wki-praktyczne-dotycz%C4%85ce-wyboru-modelu" id="toc-wskazówki-praktyczne-dotyczące-wyboru-modelu" class="nav-link" data-scroll-target="#wskaz%C3%B3wki-praktyczne-dotycz%C4%85ce-wyboru-modelu"><span class="header-section-number">7.8</span> Wskazówki praktyczne dotyczące wyboru modelu</a></li>
  <li>
<a href="#t%C5%82umaczenia-typu-sequence-to-sequence" id="toc-tłumaczenia-typu-sequence-to-sequence" class="nav-link" data-scroll-target="#t%C5%82umaczenia-typu-sequence-to-sequence"><span class="header-section-number">7.9</span> Tłumaczenia typu sequence-to-sequence</a>
  <ul class="collapse">
<li><a href="#przyk%C5%82ad-t%C5%82umaczenia-maszynowego" id="toc-przykład-tłumaczenia-maszynowego" class="nav-link" data-scroll-target="#przyk%C5%82ad-t%C5%82umaczenia-maszynowego"><span class="header-section-number">7.9.1</span> Przykład tłumaczenia maszynowego</a></li>
  <li><a href="#uczenie-sekwencyjne-z-wykorzystaniem-sieci-rnn" id="toc-uczenie-sekwencyjne-z-wykorzystaniem-sieci-rnn" class="nav-link" data-scroll-target="#uczenie-sekwencyjne-z-wykorzystaniem-sieci-rnn"><span class="header-section-number">7.9.2</span> Uczenie sekwencyjne z wykorzystaniem sieci RNN</a></li>
  <li><a href="#uczenie-si%C4%99-sekwencyjne-z-transformerem" id="toc-uczenie-się-sekwencyjne-z-transformerem" class="nav-link" data-scroll-target="#uczenie-si%C4%99-sekwencyjne-z-transformerem"><span class="header-section-number">7.9.3</span> Uczenie się sekwencyjne z transformerem</a></li>
  </ul>
</li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/dax44/AMLM/issues/new" class="toc-action"><i class="bi bi-github"></i>Zgłoś problem</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modele językowe</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>W tym rozdziale przedstawimy modele głębokiego uczenia, które mogą przetwarzać tekst (rozumiany jako ciąg słów lub ciąg znaków). Dwa podstawowe algorytmy głębokiego uczenia się dla przetwarzania sekwencji słów to rekurencyjne sieci neuronowe (ang. <em>recurent neural networks</em>) i sieci splotowe 1D, jako jednowymiarowa wersja sieci splotowych 2D. Zastosowania tych algorytmów obejmują:</p>
<ul>
<li>Klasyfikację dokumentów i klasyfikację szeregów czasowych, np. identyfikacja tematu artykułu lub autora książki;</li>
<li>Porównywanie szeregów czasowych, np. szacowanie, jak blisko siebie są dwa dokumenty lub dwa indeksy giełdowe;</li>
<li>Uczenie się od sekwencji do sekwencji, np. dekodowanie zdania angielskiego na francuskie.</li>
<li>Analiza nastrojów (ang. <em>sentiment analysis</em>), np. klasyfikacja nastrojów tweetów lub recenzji filmowych jako pozytywnych lub negatywnych;</li>
<li>Prognozowanie w szeregu czasowym, np. przewidywanie przyszłej pogody w danym miejscu na podstawie ostatnich danych pogodowych (patrze poprzedni rozdział).</li>
</ul>
<p>Przykłady w tym rozdziale skupią się na analizie sentymentu na zbiorze danych IMDB. Jednak techniki, które zademonstrujemy są istotne dla wszystkich zastosowań, które właśnie wymieniliśmy, i wielu innych. I choć zastosowania modele rekurencynje znajdują w różnych dziedzinach nauki, to my skupimy się na modelowaniu języków naturalnych.</p>
<section id="rys-historyczny" class="level2 page-columns page-full" data-number="6.1"><h2 data-number="6.1" class="anchored" data-anchor-id="rys-historyczny">
<span class="header-section-number">6.1</span> Rys historyczny</h2>
<p>W informatyce, ludzkie języki, takie jak angielski czy mandaryński, określa się mianem “naturalnych”, aby odróżnić je od języków zaprojektowanych dla maszyn, takich jak Assembly, LISP czy XML. Każdy język maszynowy został zaprojektowany - jego punkt wyjścia stanowił inżynier, który spisał zbiór formalnych zasad opisujących, jakie stwierdzenia można formułować w danym języku i co one oznaczają. Zasady powstały jako pierwsze, a ludzie zaczęli używać języka dopiero po ukończeniu zestawu reguł. W przypadku języka ludzkiego jest odwrotnie, najpierw pojawia się użycie, a zasady powstają później. Język naturalny został ukształtowany przez proces ewolucji, podobnie jak organizmy biologiczne - to czyni go “naturalnym”. Jego “zasady”, takie jak gramatyka języka polskiego, zostały sformalizowane dopiero po fakcie i często są ignorowane lub łamane przez jego użytkowników. W rezultacie, chociaż język “maszynowy”, czytelny dla maszyn jest wysoce uporządkowany i rygorystyczny, używając precyzyjnych zasad składniowych do łączenia dokładnie zdefiniowanych pojęć z ustalonego słownictwa, język naturalny jest nieuporządkowany – niejednoznaczny, chaotyczny, rozległy i ciągle podlegający zmianom.</p>
<p>Tworzenie algorytmów zdolnych do rozumienia języka naturalnego to poważne wyzwanie, bo w końcu język, a w szczególności tekst, stanowi podstawę większości naszych komunikatów i rozwoju kulturowego. Internet to w większości tekst. Język to sposób, w jaki przechowujemy niemal całą naszą wiedzę. Nasze myśli w dużej mierze opierają się na języku. Jednak zdolność rozumienia języka naturalnego przez długi czas była poza zasięgiem maszyn. Niektórzy ludzie naiwnie sądzili, że można po prostu spisać “zestaw zasad języka angielskiego”, podobnie jak można spisać zestaw zasad LISP<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Wczesne próby budowy systemów przetwarzania języka naturalnego (NLP) były więc podejmowane przez pryzmat “stosowanej lingwistyki”. Inżynierowie i lingwiści ręcznie tworzyli złożone zestawy zasad, aby wykonać podstawowe tłumaczenia maszynowe lub stworzyć proste <em>chatboty</em>, takie jak słynny program ELIZA<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> z lat 60., który używał dopasowywania wzorców, aby podtrzymać bardzo podstawową konwersację. Ale język jest rzeczą niepokorną: nie poddaje się łatwo formalizacji. Po kilku dekadach wysiłków możliwości tych systemów pozostały rozczarowujące.</p>
<div class="no-row-height column-margin column-container"><p><sup>1</sup>&nbsp;LISP (skrót od LISt Processing) jest jednym z najstarszych języków programowania, nadal używanych. Został zaprojektowany w 1958 roku przez Johna McCarthy’ego w Massachusetts Institute of Technology (MIT)</p><p><sup>2</sup>&nbsp;ELIZA to jeden z pierwszych programów komputerowych, który imitował rozmowę z człowiekiem. Został stworzony w połowie lat 60. XX wieku przez Josepha Weizenbauma w Massachusetts Institute of Technology (MIT)</p></div><p>Ręcznie tworzone reguły utrzymywały się jako dominujące podejście aż do lat 90. XX wieku. Jednak zaczynając od końca lat 80., szybsze komputery i większa dostępność danych zaczęły czynić alternatywę bardziej wykonalną. Gdy znajdziemy się w sytuacji, w której budujemy systemy będące dużymi stosami reguł ad hoc, prawdopodobnie zaczniemy zadawać sobie pytanie: “Czy mogę użyć korpusu danych, aby zautomatyzować proces znajdowania tych reguł? Czy mogę szukać reguł w pewnej przestrzeni reguł, zamiast samemu je wymyślać?” I tak właśnie przeszło się do uczenia maszynowego. W związku z tym, pod koniec lat 80. zaczęliśmy obserwować podejścia uczenia maszynowego do przetwarzania języka naturalnego. Najwcześniejsze z nich opierały się na drzewach decyzyjnych – intencją było dosłownie zautomatyzowanie rozwoju rodzaju reguł if/then/else poprzednich systemów. Następnie podejścia statystyczne zaczęły zyskiwać na popularności, zaczynając od regresji logistycznej. Z czasem, modele parametryczne oparte na uczeniu w pełni przejęły kontrolę, a lingwistyka zaczęła być postrzegana bardziej jako przeszkoda niż użyteczne narzędzie. Frederick Jelinek, wczesny badacz rozpoznawania mowy, żartował w latach 90.: “Za każdym razem, gdy zwalniam lingwistę, wydajność systemu rozpoznawania mowy rośnie.”</p>
<p>To na czym polega współczesne przetwarzanie języka naturalnego (NLP), to wykorzystanie uczenia maszynowego i dużych zbiorów danych, aby dać komputerom zdolność nie tyle rozumienia języka, co bardziej ambitnego celu, przyswajania fragmentu języka jako danych wejściowych i zwracania czegoś użytecznego, na przykład przewidywania następujących kwestii:</p>
<ul>
<li>“Jaki jest temat tego tekstu?” (klasyfikacja tekstu);</li>
<li>“Czy ten tekst zawiera treści obraźliwe?” (filtrowanie treści);</li>
<li>“Czy ten tekst brzmi pozytywnie czy negatywnie?” (analiza sentymentu);</li>
<li>“Jaki powinno być następne słowo w tym niekompletnym zdaniu?” (modelowanie języka);</li>
<li>“Jak powiedziałbyś to po niemiecku?” (tłumaczenie);</li>
<li>“Jak można by streścić ten artykuł w jednym akapicie?” (streszczanie);</li>
<li>I tak dalej.</li>
</ul>
<p>Oczywiście, powinniśmy pamiętać, że modele przetwarzania tekstu, które będziemy szkolić, nie będą posiadać ludzkiego zrozumienia języka, raczej będą po prostu szukać statystycznych reguł w danych wejściowych, co okazuje się wystarczające do dobrego wykonywania wielu prostych zadań. W podobny sposób, w jaki rozpoznawanie obrazów, to rozpoznawanie wzorców stosowane do pikseli, przetwarzanie języka naturalnego (NLP) to rozpoznawanie wzorców stosowane do słów, zdań i akapitów.</p>
<p>Narzędzia NLP - drzewa decyzyjne i regresja logistyczna - ewoluowały, choć powoli od lat 90. do wczesnych lat 2010. Większość badań skupiała się na inżynierii cech. Kiedy François Chollet wygrał swój pierwszy konkurs NLP na Kaggle w 2013 roku, jego model opierał się na drzewach decyzyjnych i regresji logistycznej. Jednak około 2014-2015 roku sytuacja zaczęła się wreszcie zmieniać. Wielu badaczy zaczęło badać zdolności rozumienia języka przez rekurencyjne sieci neuronowe, w szczególności LSTM.</p>
<p>Na początku 2015 roku, <code>keras</code> udostępnił pierwszą otwartą, łatwą w użyciu implementację LSTM, tuż na początku ogromnej fali zainteresowania sieciami neuronowymi rekurencyjnymi. Następnie od 2015 do 2017 roku, sieci neuronowe rekurencyjne zdominowały rozwijającą się scenę NLP. Modele LSTM dwukierunkowe, w szczególności, ustanowiły standard w wielu ważnych zadaniach, od streszczania, przez odpowiedzi na pytania, po tłumaczenie maszynowe. W końcu około 2017–2018 roku pojawiła się nowa architektura, która zastąpiła RNN - <em>transformer</em>, o którym dowiemy się więcej w drugiej części tego rozdziału. Transformatory umożliwiły znaczący postęp w całej dziedzinie w krótkim czasie, a obecnie większość systemów NLP opiera się na nich.</p>
</section><section id="dane-tekstowe" class="level1 page-columns page-full" data-number="7"><h1 data-number="7">
<span class="header-section-number">7</span> Dane tekstowe</h1>
<p>Tekst jest jedną z najbardziej rozpowszechnionych form danych sekwencyjnych. Może być rozumiany jako ciąg znaków lub ciąg słów, choć najczęściej pracuje się na poziomie słów. Modele głębokiego uczenia przetwarzające sekwencje, które przedstawimy w kolejnych rozdziałach, mogą wykorzystać tekst do stworzenia podstawowej formy rozumienia języka naturalnego, wystarczającej do zastosowań takich jak klasyfikacja dokumentów, analiza sentymentu, identyfikacja autorów, a nawet odpowiadanie na pytania (w ograniczonym kontekście).</p>
<p>Modele głębokiego uczenia, będąc funkcjami różniczkowalnymi, mogą przetwarzać tylko tensory liczbowe: nie mogą przyjmować surowego tekstu jako danych wejściowych. Wektoryzacja tekstu to proces przekształcania tekstu w tensory liczbowe. Procesy wektoryzacji tekstu mają wiele kształtów i form, ale wszystkie przebiegają według tego samego schematu (patrz <a href="#fig-token1" class="quarto-xref">Rysunek&nbsp;<span>7.1</span></a>):</p>
<ul>
<li>Najpierw standaryzujesz tekst, aby ułatwić jego przetwarzanie, np. zamieniając go na małe litery lub usuwając interpunkcję.</li>
<li>Następnie dzielimy tekst na jednostki (zwane tokenami), takie jak znaki, słowa lub grupy słów. Nazywa się to tokenizacją.</li>
<li>Przekształcasz każdy taki token w wektor liczbowy. Zazwyczaj wymaga to uprzedniego zindeksowania wszystkich tokenów występujących w danych.</li>
</ul>
<div id="fig-token1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-token1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-03-17 o 19.57.48.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-token1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.1: Przebieg procesu zamiany tekstu na wektory liczbowe
</figcaption></figure>
</div>
<section id="standaryzacja-tekstu" class="level2" data-number="7.1"><h2 data-number="7.1" class="anchored" data-anchor-id="standaryzacja-tekstu">
<span class="header-section-number">7.1</span> Standaryzacja tekstu</h2>
<p>Standaryzacja tekstu jest podstawową formą inżynierii cech, która ma na celu usunięcie różnic w kodowaniu, z którymi nie chcemy, aby nasz model miał do czynienia. Nie jest to wyłączna dziedzina uczenia maszynowego - musielibyśmy zrobić to samo, gdybyśmy budowali wyszukiwarkę. Jednym z najprostszych i najbardziej rozpowszechnionych schematów standaryzacji jest “konwersja na małe litery i usunięcie znaków interpunkcyjnych”.</p>
<p>Innym częstym przekształceniem jest konwersja znaków specjalnych do standardowej formy, np. zastąpienie “é” przez “e”, “æ” przez “ae” itd. Np. token “méxico” stałby się wtedy “mexico”.</p>
<p>Ostatnim, znacznie bardziej zaawansowanym wzorcem standaryzacji, który jest rzadziej używany w kontekście uczenia maszynowego, jest <em>stemming</em>: przekształcanie odmian słów (takich jak różne formy koniugacyjne czasownika) w jedną wspólną reprezentację, jak przekształcanie “złapany” i “łapiąc” w “[łapać]” lub “koty” w “[kot]”. Dzięki stemmingowi, “rozpoczynając” i “rozpoczęty” stałyby się czymś w rodzaju “[rozpoczynać]”.</p>
<p>Dzięki tym technikom standaryzacji, nasz model będzie wymagał mniej danych treningowych i będzie lepiej generalizował - nie będzie potrzebował wielu przykładów zarówno “Zachodu słońca”, jak i “zachodów słońca”, aby nauczyć się, że oznaczają one to samo, i będzie w stanie nadać sens słowu “Meksyk”, nawet jeśli widział tylko “meksyk” w swoim zestawie treningowym. Oczywiście standaryzacja może również wymazać pewną ilość informacji, więc zawsze należy pamiętać o kontekście: na przykład, jeśli piszesz model, który wyodrębnia pytania z artykułów z wywiadami, powinien on zdecydowanie traktować “?” jako oddzielny token zamiast go upuszczać, ponieważ jest to przydatny sygnał dla tego konkretnego zadania.</p>
</section><section id="tokenizacja" class="level2" data-number="7.2"><h2 data-number="7.2" class="anchored" data-anchor-id="tokenizacja">
<span class="header-section-number">7.2</span> Tokenizacja</h2>
<p>Kiedy tekst jest już znormalizowany, musimy podzielić go na jednostki do wektoryzacji (<em>tokeny</em>) - krok zwany tokenizacją. Można to zrobić na trzy różne sposoby:</p>
<ul>
<li>Tokenizacja na poziomie słowa - gdzie tokeny są oddzielonymi spacjami (lub interpunkcją) podciągami. Wariantem tego jest dalsze dzielenie słów na podsłowia, gdy ma to zastosowanie, na przykład traktowanie “zaczyna” jako “zaczyna+jąc” lub “wezwany” jako “wezwani”.</li>
<li>N-gram tokenizacji - gdzie tokeny są grupami N kolejnych słów. Na przykład “the cat” lub “he was” byłyby tokenami 2-gramowymi (zwanymi również bigramami). Generalnie N-gramy słów to grupy N (lub mniej) kolejnych słów, które można wyodrębnić ze zdania. Ta sama koncepcja może być również zastosowana do znaków zamiast słów.</li>
<li>Tokenizacja na poziomie znaków - gdzie każdy znak jest swoim własnym tokenem. W praktyce, ten schemat jest rzadko używany i naprawdę widzisz go tylko w specjalistycznych kontekstach, takich jak generowanie tekstu lub rozpoznawanie mowy.</li>
</ul>
<p>Ogólnie rzecz biorąc, zawsze będziemy używać tokenizacji na poziomie słowa lub N-gramu. Istnieją dwa rodzaje modeli przetwarzania tekstu: te, które dbają o kolejność słów, zwane modelami sekwencyjnymi, oraz te, które traktują słowa wejściowe jako zestaw, odrzucając ich oryginalną kolejność, zwane modelami <em>bag-of-words</em>. Jeśli budujesz model sekwencyjny, używasz tokenizacji na poziomie słów, a jeśli budujesz model worka słów, używasz tokenizacji N-gramów. N-gramy są sposobem na sztuczne wprowadzenie do modelu niewielkiej ilości informacji o lokalnym porządku słów. W tym rozdziale dowiesz się więcej o każdym typie modelu i o tym, kiedy należy ich używać.</p>
<p>Przykładowo zdanie “the cat sat on the mat” można zamienić na bigramy w następujący sposób:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"the"</span>, <span class="st">"the cat"</span>, <span class="st">"cat"</span>, <span class="st">"cat sat"</span>, <span class="st">"sat"</span>,</span>
<span> <span class="st">"sat on"</span>, <span class="st">"on"</span>, <span class="st">"on the"</span>, <span class="st">"the mat"</span>, <span class="st">"mat"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] "the"     "the cat" "cat"     "cat sat" "sat"     "sat on"  "on"     
 [8] "on the"  "the mat" "mat"    </code></pre>
</div>
</div>
<p>natomiast w 3-gramy:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"the"</span>, <span class="st">"the cat"</span>, <span class="st">"cat"</span>, <span class="st">"cat sat"</span>, <span class="st">"the cat sat"</span>,</span>
<span> <span class="st">"sat"</span>, <span class="st">"sat on"</span>, <span class="st">"on"</span>, <span class="st">"cat sat on"</span>, <span class="st">"on the"</span>,</span>
<span> <span class="st">"sat on the"</span>, <span class="st">"the mat"</span>, <span class="st">"mat"</span>, <span class="st">"on the mat"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] "the"         "the cat"     "cat"         "cat sat"     "the cat sat"
 [6] "sat"         "sat on"      "on"          "cat sat on"  "on the"     
[11] "sat on the"  "the mat"     "mat"         "on the mat" </code></pre>
</div>
</div>
</section><section id="indeksowanie-słownika" class="level2 page-columns page-full" data-number="7.3"><h2 data-number="7.3" class="anchored" data-anchor-id="indeksowanie-słownika">
<span class="header-section-number">7.3</span> Indeksowanie słownika</h2>
<p>Gdy nasz tekst jest podzielony na tokeny, musimy zakodować każdy token w reprezentacji numerycznej. Wszystkie procesy wektoryzacji tekstu polegają na zastosowaniu pewnego schematu tokenizacji, a następnie skojarzeniu wektorów liczbowych z wygenerowanymi tokenami. Wektory te, spakowane w tensory sekwencji, są wprowadzane do głębokich sieci neuronowych. Istnieje wiele sposobów na powiązanie wektora z tokenem. W tej sekcji przedstawimy dwa główne: kodowanie tokenów metodą <em>one-hot</em> oraz osadzanie tokenów (ang. <em>embeddings</em> - zwykle używane wyłącznie dla słów). Pozostała część tego rozdziału wyjaśnia te techniki i pokazuje jak ich użyć, aby przejść od surowego tekstu do tensora, który można wysłać do sieci.</p>
<p>Technicznie rzecz ujmując, należy zauważyć, że na tym etapie często ogranicza się słownictwo tylko do 20000 lub 30000 najczęściej występujących słów znalezionych w danych treningowych. Każdy zbiór danych tekstowych ma tendencję do zawierania ogromnej liczby unikalnych terminów, z których większość pojawia się tylko raz lub dwa. Indeksowanie tych rzadkich terminów skutkowałoby nadmiernie dużą przestrzenią cech, gdzie większość cech miałaby prawie żadną zawartość informacyjną.</p>
<p>Ważny szczegół, który nie powinien umknąć naszej uwadze: gdy szukamy nowego tokenu w naszym indeksie słownictwa, może się okazać, że go tam nie ma. Nasze dane treningowe mogły nie zawierać żadnego wystąpienia słowa “cherimoya”<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> (lub być może wykluczyliśmy je z indeksu, ponieważ było zbyt rzadkie), więc wykonanie polecenia <code>token_index = match("cherimoya", vocabulary)</code> może zwrócić <code>NA</code>. Aby sobie z tym poradzić, należy użyć indeksu “poza słownictwem” (skrótowo OOV index) - rodzaju schowka na wszystkie tokeny, które nie znalazły się w indeksie. Zwykle jest to indeks 1: tak naprawdę wykonujesz <code>token_index = match("cherimoya", vocabulary, nomatch = 1)</code>. Dekodując sekwencję liczb całkowitych z powrotem na słowa, zastąpisz 1 czymś w rodzaju “[UNK]” (co nazwałbyś “tokenem OOV”).</p>
<div class="no-row-height column-margin column-container"><p><sup>3</sup>&nbsp;przypominający kształtem serce owoc, jest słodki jak budyń, dlatego Anglicy nazywają go <em>custard apple</em> - czyli jabłko o smaku kremu budyniowego</p></div><p>“Dlaczego używamy 1, a nie 0?” można zapytać. Ponieważ 0 jest już zajęte. Istnieją dwa specjalne tokeny, których będziemy często używać: token OOV (indeks 1) i token maski (indeks 0). Chociaż token OOV oznacza “to jest słowo, którego nie rozpoznaliśmy”, to token maski mówi nam “zignoruj mnie, nie jestem słowem”. Używa się go w szczególności do uzupełniania danych sekwencyjnych: ponieważ partie danych muszą być ciągłe, wszystkie sekwencje w partii danych sekwencyjnych muszą mieć tę samą długość, więc krótsze sekwencje powinny być uzupełniane do długości najdłuższej sekwencji. Jeśli chcemy utworzyć partię danych z sekwencjami <code>c(5, 7, 124, 4, 89)</code> i <code>c(8, 34, 21)</code>, musiałaby ona wyglądać następująco:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>,  <span class="fl">7</span>, <span class="fl">124</span>, <span class="fl">4</span>, <span class="fl">89</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">34</span>,  <span class="fl">21</span>, <span class="fl">0</span>,  <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3] [,4] [,5]
[1,]    5    7  124    4   89
[2,]    8   34   21    0    0</code></pre>
</div>
</div>
<p>Wszystkie omówione do tej pory kroki można w prosty sposób zaprogramować w R:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tensorflow.rstudio.com/">keras</a></span><span class="op">)</span> <span class="co"># póki co potrzebny tylko by mieć %&gt;%</span></span>
<span><span class="va">new_vectorizer</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">self</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/environment.html">new.env</a></span><span class="op">(</span>parent <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/environment.html">emptyenv</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="co"># Utworzenie nowego środowiska dla wektoryzatora</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="va">self</span>, <span class="st">"class"</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="st">"Vectorizer"</span>   <span class="co"># Nadanie środowisku klasy "Vectorizer"</span></span>
<span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"[UNK]"</span><span class="op">)</span>         <span class="co"># Inicjalizacja słownika słów z tokenem "[UNK]" (nieznane słowo)</span></span>
<span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">standardize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">text</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">text</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/chartr.html">tolower</a></span><span class="op">(</span><span class="va">text</span><span class="op">)</span>               <span class="co"># Przekształcenie tekstu na małe litery</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/grep.html">gsub</a></span><span class="op">(</span><span class="st">"[[:punct:]]"</span>, <span class="st">""</span>, <span class="va">text</span><span class="op">)</span>       <span class="co"># Usunięcie znaków interpunkcyjnych z tekstu</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">tokenize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">text</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/strsplit.html">strsplit</a></span><span class="op">(</span><span class="va">text</span>, <span class="st">"[[:space:]]+"</span><span class="op">)</span><span class="op">)</span> <span class="co"># Podział tekstu na tokeny (słowa) na podstawie spacji</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">make_vocabulary</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">text_dataset</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">tokens</span> <span class="op">&lt;-</span> <span class="va">text_dataset</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">standardize</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">tokenize</span><span class="op">(</span><span class="op">)</span>                   <span class="co"># Standardyzacja i tokenizacja tekstu</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">vocabulary</span>, <span class="va">tokens</span><span class="op">)</span><span class="op">)</span> <span class="co"># Aktualizacja słownika o unikalne tokeny</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">encode</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">text</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">tokens</span> <span class="op">&lt;-</span> <span class="va">text</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">standardize</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">tokenize</span><span class="op">(</span><span class="op">)</span>                   <span class="co"># Standardyzacja i tokenizacja tekstu</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/match.html">match</a></span><span class="op">(</span><span class="va">tokens</span>, table <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="va">vocabulary</span>, nomatch <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="co"># Zamiana tokenów na ich indeksy w słowniku</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">self</span><span class="op">$</span><span class="va">decode</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">int_sequence</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">vocab_w_mask_token</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">""</span>, <span class="va">self</span><span class="op">$</span><span class="va">vocabulary</span><span class="op">)</span> <span class="co"># Słownik z dodanym pustym tokenem na początku</span></span>
<span>    <span class="va">vocab_w_mask_token</span><span class="op">[</span><span class="va">int_sequence</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span>         <span class="co"># Zamiana sekwencji indeksów na słowa</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">self</span> <span class="co"># Zwrócenie środowiska wektoryzatora</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>A tak wygląda on w działaniu… Najpierw tworzymy słownik na podstawie prostego korpusu.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">vectorizer</span> <span class="op">&lt;-</span> <span class="fu">new_vectorizer</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>    <span class="st">"I write, erase, rewrite"</span>,</span>
<span>    <span class="st">"Erase again, and then"</span>,</span>
<span>    <span class="st">"A poppy blooms."</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">vectorizer</span><span class="op">$</span><span class="fu">make_vocabulary</span><span class="op">(</span><span class="va">dataset</span><span class="op">)</span></span>
<span><span class="va">vectorizer</span><span class="op">$</span><span class="va">vocabulary</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] "[UNK]"   "i"       "write"   "erase"   "rewrite" "again"   "and"    
 [8] "then"    "a"       "poppy"   "blooms" </code></pre>
</div>
</div>
<p>A następnie wykorzystujemy go do nowego zdania.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">test_sentence</span> <span class="op">&lt;-</span> <span class="st">"I write, rewrite, and still rewrite again"</span></span>
<span><span class="va">encoded_sentence</span> <span class="op">&lt;-</span> <span class="va">vectorizer</span><span class="op">$</span><span class="fu">encode</span><span class="op">(</span><span class="va">test_sentence</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">encoded_sentence</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 2 3 5 7 1 5 6</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">decoded_sentence</span> <span class="op">&lt;-</span> <span class="va">vectorizer</span><span class="op">$</span><span class="fu">decode</span><span class="op">(</span><span class="va">encoded_sentence</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">decoded_sentence</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] "i"       "write"   "rewrite" "and"     "[UNK]"   "rewrite" "again"  </code></pre>
</div>
</div>
<p>Choć jak widać wszystko działa poprawnie, to w praktycznych zastosowaniach będziemy korzystali raczej z rozwiązań w <code>keras</code> typu warstwa <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">text_vectorization</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span>output_mode <span class="op">=</span> <span class="st">"int"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Domyślnie, <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code> będzie używać ustawienia “konwertuj na małe litery i usuń znaki interpunkcyjne” do standaryzacji tekstu oraz “dziel względem znaków przerw (typu spacja)” do tokenizacji. Ale co ważne, można dostarczyć niestandardowe funkcje do standaryzacji i tokenizacji, co oznacza, że warstwa jest wystarczająco elastyczna, aby obsłużyć każdy przypadek użycia. Należy pamiętać, że takie niestandardowe funkcje powinny działać na tensorach typu <code>tf.string</code>, a nie na zwykłych wektorach znaków R! Na przykład, domyślne zachowanie warstwy jest równoważne następującemu:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow">tensorflow</a></span><span class="op">)</span></span>
<span><span class="va">custom_standardization_fn</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">string_tensor</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">string_tensor</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="va">tf</span><span class="op">$</span><span class="va">strings</span><span class="op">$</span><span class="fu">lower</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="va">tf</span><span class="op">$</span><span class="va">strings</span><span class="op">$</span><span class="fu">regex_replace</span><span class="op">(</span><span class="st">"[[:punct:]]"</span>, <span class="st">""</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">custom_split_fn</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">string_tensor</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">tf</span><span class="op">$</span><span class="va">strings</span><span class="op">$</span><span class="fu">split</span><span class="op">(</span><span class="va">string_tensor</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">text_vectorization</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span></span>
<span>  output_mode <span class="op">=</span> <span class="st">"int"</span>,</span>
<span>  standardize <span class="op">=</span> <span class="va">custom_standardization_fn</span>,</span>
<span>  split <span class="op">=</span> <span class="va">custom_split_fn</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Aby zindeksować słownictwo korpusu tekstowego, wystarczy wywołać metodę <code><a href="https://rdrr.io/pkg/keras/man/adapt.html">adapt()</a></code> warstwy z obiektem TF Dataset, który daje ciągi znaków, lub po prostu z wektorem znaków R:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"I write, erase, rewrite"</span>,</span>
<span>             <span class="st">"Erase again, and then"</span>,</span>
<span>             <span class="st">"A poppy blooms."</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/adapt.html">adapt</a></span><span class="op">(</span><span class="va">text_vectorization</span>, <span class="va">dataset</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Należy pamiętać, że obliczone słownictwo można pobrać za pomocą funkcji <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">get_vocabulary()</a></code>. Może to być przydatne, jeśli trzeba przekonwertować tekst zakodowany jako sekwencje liczb całkowitych z powrotem na słowa. Pierwsze dwa wpisy w słowniku to token maski (indeks 0) i token OOV (indeks 1). Wpisy na liście słownictwa są sortowane według częstotliwości, więc w przypadku zbioru danych z rzeczywistego świata bardzo popularne słowa, takie jak “the” lub “a”, będą na pierwszym miejscu.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">get_vocabulary</a></span><span class="op">(</span><span class="va">text_vectorization</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] ""        "[UNK]"   "erase"   "write"   "then"    "rewrite" "poppy"  
 [8] "i"       "blooms"  "and"     "again"   "a"      </code></pre>
</div>
</div>
<p>Na potrzeby prezentacji, spróbujmy zakodować, a następnie zdekodować przykładowe zdanie:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="va">text_vectorization</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">get_vocabulary</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">test_sentence</span> <span class="op">&lt;-</span> <span class="st">"I write, rewrite, and still rewrite again"</span></span>
<span><span class="va">encoded_sentence</span> <span class="op">&lt;-</span> <span class="fu">text_vectorization</span><span class="op">(</span><span class="va">test_sentence</span><span class="op">)</span></span>
<span><span class="va">decoded_sentence</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="va">vocabulary</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">encoded_sentence</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span>,</span>
<span>                          collapse <span class="op">=</span> <span class="st">" "</span><span class="op">)</span></span>
<span></span>
<span><span class="va">encoded_sentence</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([ 7  3  5  9  1  5 10], shape=(7), dtype=int64)</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">decoded_sentence</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] "i write rewrite and [UNK] rewrite again"</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Wskazówka
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ponieważ <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code> jest głównie operacją wyszukiwania słownika, która konwertuje tokeny na liczby całkowite, nie może być wykonywana na GPU (lub TPU) - tylko na CPU. Jeśli więc trenujemy nasz model na GPU, funkcja <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code> zostanie uruchomiona na CPU przed wysłaniem danych wyjściowych do GPU. Ma to istotny wpływ na wydajność.</p>
<p>Istnieją dwa sposoby wykorzystania funkcji <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code>. Pierwszą opcją jest umieszczenie jej w potoku TF Dataset, tak jak poniżej:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">int_sequence_dataset</span> <span class="op">&lt;-</span> <span class="va">string_dataset</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">dataset_map</span><span class="op">(</span><span class="va">text_vectorization</span>, num_parallel_calls <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Drugą opcją jest uczynienie go częścią modelu (w końcu jest to warstwa <code>keras</code>), jak poniżej (w pseudokodzie):</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">text_input</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"string"</span><span class="op">)</span></span>
<span><span class="va">vectorized_text</span> <span class="op">&lt;-</span> <span class="fu">text_vectorization</span><span class="op">(</span><span class="va">text_input</span><span class="op">)</span></span>
<span><span class="va">embedded_input</span> <span class="op">&lt;-</span> <span class="va">vectorized_text</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span><span class="va">output</span> <span class="op">&lt;-</span> <span class="va">embedded_input</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">...</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">text_input</span>, <span class="va">output</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Jest między nimi ważna różnica: jeśli krok wektoryzacji jest częścią modelu, będzie on wykonywany synchronicznie z resztą modelu. Oznacza to, że na każdym etapie uczenia reszta modelu (umieszczona na GPU) będzie musiała poczekać, aż dane wyjściowe <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code> (umieszczone na CPU) będą gotowe, zanim będzie mogła rozpocząć pracę. Tymczasem umieszczenie warstwy w potoku TF Dataset umożliwia asynchroniczne wstępne przetwarzanie danych na CPU: podczas gdy GPU uruchamia model na jednej partii zwektoryzowanych danych, CPU pozostaje zajęty wektoryzacją następnej partii surowych ciągów.</p>
<p>Jeśli trenujemy model na GPU lub TPU, prawdopodobnie będziemy chcieli wybrać pierwszą opcję<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>, aby uzyskać najlepszą wydajność. Podczas trenowania na CPU, przetwarzanie synchroniczne jest w porządku: uzyskamy wówczas 100% wykorzystania rdzeni, niezależnie od wybranej opcji.</p>
<p>Teraz, jeśli mielibyśmy wyeksportować nasz model do środowiska produkcyjnego, chcielibyśmy wysłać model, który akceptuje surowe ciągi znaków jako dane wejściowe, jak w powyższym fragmencie kodu dla drugiej opcji; w przeciwnym razie musielibyśmy ponownie wdrożyć standaryzację tekstu i tokenizację w naszym środowisku produkcyjnym (np. w JavaScript). Stanęlibyśmy w obliczu ryzyka wprowadzenia niewielkich zmian w przetwarzaniu wstępnym, które zaszkodziłyby dokładności modelu. Na szczęście funkcja <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code> umożliwia włączenie wstępnego przetwarzania tekstu bezpośrednio do modelu, co ułatwia jego wdrożenie, nawet jeśli pierwotnie warstwa była używana jako część potoku TF Dataset.</p>
</div>
</div>
<div class="no-row-height column-margin column-container"><p><sup>4</sup>&nbsp;czyli osadzenie wektoryzacji w potoku</p></div></section><section id="one-hot-encoding" class="level2" data-number="7.4"><h2 data-number="7.4" class="anchored" data-anchor-id="one-hot-encoding">
<span class="header-section-number">7.4</span> One-hot encoding</h2>
<p>Kodowanie one-hot jest najczęstszym, najbardziej podstawowym sposobem przekształcenia tokena w wektor. Polega ono na skojarzeniu unikalnego indeksu z każdym słowem, a następnie przekształceniu tego indeksu <span class="math inline">\(i\)</span> w wektor binarny o rozmiarze <span class="math inline">\(N\)</span> (rozmiar słownika); wektor składa się ze wszystkich zer, z wyjątkiem <span class="math inline">\(i\)</span>-tego wpisu, który jest 1.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">one_hot_encode_token</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">token</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">vector</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="fl">0</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">vocabulary</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">token_index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/match.html">match</a></span><span class="op">(</span><span class="va">token</span>, <span class="va">vocabulary</span><span class="op">)</span></span>
<span>  <span class="va">vector</span><span class="op">[</span><span class="va">token_index</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span>  <span class="va">vector</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Metoda ta, zważywszy na swoją rzadką reprezentację (większość wartości to 0), rzadko stosowana w praktyce. Słaba wydajność tej techniki spowodowała powstanie <em>embedingów.</em> Zanim jednak przejdziemy do <em>embedingów</em> przyjrzymy się dokładniej dwóm podejściom do reprezentacji grup słów: zbiorom słów (ang. <em>bag-of-words</em>) i ciągom słów, w których kolejność jest ważna. Zrobimy to na przykładzie danych IMDB.</p>
</section><section id="tokenizacja-na-przykładach" class="level2" data-number="7.5"><h2 data-number="7.5" class="anchored" data-anchor-id="tokenizacja-na-przykładach">
<span class="header-section-number">7.5</span> Tokenizacja na przykładach</h2>
<p>Sposób, w jaki model uczenia maszynowego powinien reprezentować poszczególne słowa, jest stosunkowo niekontrowersyjną kwestią: są to cechy kategorialne (wartości z predefiniowanego zestawu) i wiemy, jak sobie z nimi radzić. Powinny one być zakodowane jako wymiary w przestrzeni cech lub jako wektory kategorii (w tym przypadku wektory słów). Znacznie bardziej problematyczną kwestią jest jednak to, jak zakodować sposób, w jaki słowa są wplecione w zdania - kolejność słów.</p>
<p>Problem kolejności w języku naturalnym jest interesujący. W przeciwieństwie do kroków szeregu czasowego, słowa w zdaniu nie mają naturalnej, kanonicznej kolejności. Różne języki porządkują podobne słowa na bardzo różne sposoby. Na przykład, struktura zdań w języku angielskim jest zupełnie inna niż w języku japońskim. Nawet w obrębie danego języka można zazwyczaj powiedzieć to samo na różne sposoby, zmieniając nieco kolejność słów. Co więcej, jeśli słowa w krótkim zadaniu ułożysz losowo, to nadal możesz w dużej mierze dowiedzieć się, co zostało powiedziane, choć w wielu przypadkach pojawia się dwuznaczność. Kolejność jest wyraźnie ważna, ale jej związek ze znaczeniem nie jest prosty.</p>
<p>Sposób reprezentowania kolejności słów jest kluczowym pytaniem, z którego wynikają różne rodzaje architektur NLP. Najprostszą rzeczą, jaką można zrobić, jest po prostu odrzucenie kolejności i traktowanie tekstu jako nieuporządkowanego zbioru słów - daje to modele worków słów. Można również zdecydować, że słowa powinny być przetwarzane ściśle w kolejności, w jakiej się pojawiają, pojedynczo, jak kroki w szeregu czasowym - można wtedy wykorzystać modele rekurencyjne z poprzedniego rozdziału. Wreszcie, możliwe jest również podejście hybrydowe: architektura <em>transformer</em> jest technicznie niezależna od kolejności, ale wprowadza informacje o pozycji słów do przetwarzanych reprezentacji, co pozwala jej jednocześnie patrzeć na różne części zdania (w przeciwieństwie do RNN), a jednocześnie jest świadoma kolejności. Ponieważ uwzględniają one kolejność słów, zarówno RNN, jak i transformatory nazywane są modelami sekwencyjnymi.</p>
<p>Historycznie rzecz ujmując, większość wczesnych zastosowań uczenia maszynowego w NLP obejmowała po prostu modele <em>bag-of-words</em>. Zainteresowanie modelami sekwencyjnymi zaczęło rosnąć dopiero w 2015 roku, wraz z odrodzeniem się rekurencyjnych sieci neuronowych. Obecnie oba podejścia pozostają istotne.</p>
<section id="przygotowanie-danych-imdb" class="level3" data-number="7.5.1"><h3 data-number="7.5.1" class="anchored" data-anchor-id="przygotowanie-danych-imdb">
<span class="header-section-number">7.5.1</span> Przygotowanie danych IMDB</h3>
<p>Zacznijmy od pobrania danych.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Zdefiniowanie URL, z którego ma być pobrany plik</span></span>
<span><span class="va">url</span> <span class="op">&lt;-</span> <span class="st">"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"</span> </span>
<span></span>
<span><span class="va">filename</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"/Users/majerek/"</span>, <span class="fu"><a href="https://rdrr.io/r/base/basename.html">basename</a></span><span class="op">(</span><span class="va">url</span><span class="op">)</span><span class="op">)</span> <span class="co"># Pobranie nazwy pliku z URL, w tym przypadku 'aclImdb_v1.tar.gz'</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html">options</a></span><span class="op">(</span>timeout <span class="op">=</span> <span class="fl">60</span><span class="op">*</span><span class="fl">10</span><span class="op">)</span> <span class="co"># Ustawienie limitu czasu na pobieranie na 10 minut (60 sekund * 10)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span><span class="op">(</span><span class="va">url</span>, destfile <span class="op">=</span> <span class="va">filename</span><span class="op">)</span> <span class="co"># Pobranie pliku z zadanego URL i zapisanie go pod nazwą </span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/untar.html">untar</a></span><span class="op">(</span><span class="va">filename</span>, exdir <span class="op">=</span> <span class="st">"/Users/majerek/"</span><span class="op">)</span> <span class="co"># Rozpakowanie pobranego pliku tar.gz</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Tak wygląda struktura katalogu po rozpakowaniu.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">fs</span><span class="fu">::</span><span class="fu"><a href="https://fs.r-lib.org/reference/dir_tree.html">dir_tree</a></span><span class="op">(</span><span class="st">"/Users/majerek/aclImdb"</span>, recurse <span class="op">=</span> <span class="fl">1</span>, type <span class="op">=</span> <span class="st">"directory"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>/Users/majerek/aclImdb
├── test
│   ├── neg
│   └── pos
├── train
│   ├── neg
│   └── pos
└── val
    ├── neg
    └── pos</code></pre>
</div>
</div>
<p>Na przykład katalog <code>train/pos/</code> zawiera zestaw 12500 plików tekstowych, z których każdy zawiera tekst recenzji filmu o pozytywnym wydźwięku, który zostanie wykorzystany jako dane szkoleniowe. Recenzje o negatywnym wydźwięku znajdują się w katalogach “neg”. W sumie istnieje 25000 plików tekstowych do szkolenia i kolejne 25000 do testowania. Znajduje się tam również podkatalog <code>train/unsup</code>, którego nie potrzebujemy. Usuńmy go:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">fs</span><span class="fu">::</span><span class="fu"><a href="https://fs.r-lib.org/reference/delete.html">dir_delete</a></span><span class="op">(</span><span class="st">"/Users/majerek/aclImdb/train/unsup/"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Spójrzmy na zawartość kilku z tych plików tekstowych.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/readLines.html">readLines</a></span><span class="op">(</span><span class="st">"/Users/majerek/aclImdb/train/pos/4000_10.txt"</span>, warn <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Wow. Saw this last night and I'm still reeling from how good it was. Every character felt so real (although most of them petty, selfish a**holes) and the bizarre story - middle aged widow starts shagging her daughter's feckless boyfriend - felt utterly convincing. Top performances all round but hats off to Anne Reid and Our Friends in the North's Daniel Craig (the latter coming across as the next David Thewlis).&lt;br /&gt;&lt;br /&gt;And director Roger Michell? This is as far from Notting Hill as it's possible to be. Thank God.&lt;br /&gt;&lt;br /&gt;Watch this movie!!!</code></pre>
</div>
</div>
<p>Następnie przygotujmy zestaw walidacyjny, oddzielając 20% treningowych plików tekstowych w nowym katalogu, <code>aclImdb/val</code>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://fs.r-lib.org">fs</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span>
<span><span class="va">base_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://fs.r-lib.org/reference/path.html">path</a></span><span class="op">(</span><span class="st">"/Users/majerek/aclImdb"</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">category</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"neg"</span>, <span class="st">"pos"</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">filepaths</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://fs.r-lib.org/reference/dir_ls.html">dir_ls</a></span><span class="op">(</span><span class="va">base_dir</span> <span class="op">/</span> <span class="st">"train"</span> <span class="op">/</span> <span class="va">category</span><span class="op">)</span></span>
<span>  <span class="va">num_val_samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fl">0.2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">filepaths</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">val_files</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">filepaths</span>, <span class="va">num_val_samples</span><span class="op">)</span></span>
<span></span>
<span>  <span class="fu"><a href="https://fs.r-lib.org/reference/create.html">dir_create</a></span><span class="op">(</span><span class="va">base_dir</span> <span class="op">/</span> <span class="st">"val"</span> <span class="op">/</span> <span class="va">category</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://fs.r-lib.org/reference/file_move.html">file_move</a></span><span class="op">(</span><span class="va">val_files</span>,</span>
<span>            <span class="va">base_dir</span> <span class="op">/</span> <span class="st">"val"</span> <span class="op">/</span> <span class="va">category</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>W zagadnieniach z analizy obrazów używaliśmy funkcji <code><a href="https://rdrr.io/pkg/keras/man/image_dataset_from_directory.html">image_dataset_from_directory()</a></code> do utworzenia zbiorów obrazów i ich etykiet dla struktury katalogów. Dokładnie to samo można zrobić dla plików tekstowych za pomocą narzędzia <code><a href="https://rdrr.io/pkg/keras/man/text_dataset_from_directory.html">text_dataset_from_directory()</a></code>. Utwórzmy trzy obiekty TF Dataset do uczenia, walidacji i testowania:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tensorflow.rstudio.com/">keras</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tfdatasets">tfdatasets</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">train_ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/text_dataset_from_directory.html">text_dataset_from_directory</a></span><span class="op">(</span><span class="st">"/Users/majerek/aclImdb/train"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Found 20000 files belonging to 2 classes.</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">val_ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/text_dataset_from_directory.html">text_dataset_from_directory</a></span><span class="op">(</span><span class="st">"/Users/majerek/aclImdb/val"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Found 5000 files belonging to 2 classes.</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">test_ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/text_dataset_from_directory.html">text_dataset_from_directory</a></span><span class="op">(</span><span class="st">"/Users/majerek/aclImdb/test"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Found 25000 files belonging to 2 classes.</code></pre>
</div>
</div>
<p>Te zestawy danych tworzą dane wejściowe, które są tensorami <code>tf.string</code> i wyjścia, które są tensorami <code>int32</code> kodującymi wartość “0” lub “1”.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">targets</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html">%&lt;-%</a></span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/iterate.html">iter_next</a></span><span class="op">(</span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/iterate.html">as_iterator</a></span><span class="op">(</span><span class="va">train_ds</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Tensor: shape=(32), dtype=string, numpy=…&gt;</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">targets</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Tensor: shape=(32), dtype=int32, numpy=…&gt;</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inputs</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(b'I saw this recently and I must say, I was moved by the factual basis of the story. However, "Holly" as a movie did not quite work. I am however, looking forward to watching the documentary which the producers who organised this project had made because I think that would be a much more compelling work than this film.&lt;br /&gt;&lt;br /&gt;The international cast was composed of B-class actors but their acting was appropriate, and I must give a special mention for the young actress who played Holly. This was her first movie role and she did a very nice job, considering hers is the most challenging part. &lt;br /&gt;&lt;br /&gt;Ron Livingston was adequate but bland as Patrick, the American whose quest is to "save" Holly, but Chris Penn was good in this, his final role. Unfortunately, despite my mostly favourable opinion of Virginie Ledoyen and Udo Kier, both of these actors were very much forgettable and did not do their best work in this film.&lt;br /&gt;&lt;br /&gt;I believe in the film\'s message and intention, but I have to be fair, so I rate "Holly" 3 stars based on its shortcomings as a movie. But I think the subject matter deserves serious consideration and I am pleased that the people behind this movie have made a documentary as well which I hope will have its debut on BBC and other TV networks.', shape=(), dtype=string)</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">targets</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(0, shape=(), dtype=int32)</code></pre>
</div>
</div>
<p>Wszystko gotowe. Teraz spróbujmy nauczyć się czegoś z tych danych.</p>
</section><section id="modelowanie-za-pomocą-bag-of-words" class="level3" data-number="7.5.2"><h3 data-number="7.5.2" class="anchored" data-anchor-id="modelowanie-za-pomocą-bag-of-words">
<span class="header-section-number">7.5.2</span> Modelowanie za pomocą bag-of-words</h3>
<p>Najprostszym sposobem zakodowania fragmentu tekstu do przetwarzania przez model uczenia maszynowego jest odrzucenie kolejności i potraktowanie go jako zbioru (“worka”) tokenów. Najczęściej stosuje się tu unigramy, czyli podział na pojedyncze słowa lub znaki. Zdarza się jednak, gdy chcemy zachować część informacji o kolejności słów, że stosuje się N-gramy.</p>
<p>Dla przywoływanego już przykładu “the cat sat on the mat” podział na unigramy jest następujący:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"cat"</span>, <span class="st">"mat"</span>, <span class="st">"on"</span>, <span class="st">"sat"</span>, <span class="st">"the"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] "cat" "mat" "on"  "sat" "the"</code></pre>
</div>
</div>
<p>Główną zaletą tego kodowania jest możliwość reprezentowania całego tekstu jako pojedynczego wektora, gdzie każdy element jest wskaźnikiem obecności danego słowa. Na przykład, korzystając z kodowania binarnego (ang. <em>multi-hot encoding</em>), zakodujemy tekst jako wektor mający tyle współrzędnych, ile jest słów w naszym słowniku, z 0 niemal wszędzie i kilkoma 1 dla wymiarów, które kodują słowa obecne w tekście.</p>
<p>Najpierw przetwórzmy nasze surowe zbiory danych tekstowych za pomocą warstwy <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code>, tak aby uzyskać wielokrotnie zakodowane binarnie wektory słów. Nasza warstwa będzie patrzeć tylko na pojedyncze słowa (czyli unigramy).</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">text_vectorization</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span>max_tokens <span class="op">=</span> <span class="fl">20000</span>,</span>
<span>                           output_mode <span class="op">=</span> <span class="st">"multi_hot"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">text_only_train_ds</span> <span class="op">&lt;-</span> <span class="va">train_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html">dataset_map</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/adapt.html">adapt</a></span><span class="op">(</span><span class="va">text_vectorization</span>, <span class="va">text_only_train_ds</span><span class="op">)</span></span>
<span></span>
<span><span class="va">binary_1gram_train_ds</span> <span class="op">&lt;-</span> <span class="va">train_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html">dataset_map</a></span><span class="op">(</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu">text_vectorization</span><span class="op">(</span><span class="va">.x</span><span class="op">)</span>, <span class="va">.y</span><span class="op">)</span>,</span>
<span>               num_parallel_calls <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">binary_1gram_val_ds</span> <span class="op">&lt;-</span> <span class="va">val_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html">dataset_map</a></span><span class="op">(</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu">text_vectorization</span><span class="op">(</span><span class="va">.x</span><span class="op">)</span>, <span class="va">.y</span><span class="op">)</span>,</span>
<span>               num_parallel_calls <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">binary_1gram_test_ds</span> <span class="op">&lt;-</span> <span class="va">test_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html">dataset_map</a></span><span class="op">(</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu">text_vectorization</span><span class="op">(</span><span class="va">.x</span><span class="op">)</span>, <span class="va">.y</span><span class="op">)</span>,</span>
<span>               num_parallel_calls <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Sprawdźmy dane wyjściowe dla jednego z tych zestawów.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb50"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">targets</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html">%&lt;-%</a></span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/iterate.html">iter_next</a></span><span class="op">(</span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/iterate.html">as_iterator</a></span><span class="op">(</span><span class="va">binary_1gram_train_ds</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Tensor: shape=(32, 20000), dtype=float32, numpy=…&gt;</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb52"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">targets</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Tensor: shape=(32), dtype=int32, numpy=…&gt;</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inputs</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000), dtype=float32)</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">targets</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(1, shape=(), dtype=int32)</code></pre>
</div>
</div>
<p>Napiszmy funkcję budowania modelu wielokrotnego użytku, której będziemy używać we wszystkich naszych eksperymentach w tej sekcji.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb58"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">get_model</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">max_tokens</span> <span class="op">=</span> <span class="fl">20000</span>, <span class="va">hidden_dim</span> <span class="op">=</span> <span class="fl">16</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">max_tokens</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">hidden_dim</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></span>
<span>  <span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span>  <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>                    loss <span class="op">=</span> <span class="st">"binary_crossentropy"</span>,</span>
<span>                    metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span>  <span class="va">model</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Na koniec wytrenujmy i przetestujmy nasz model.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">get_model</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">model</span></span>
<span><span class="va">callbacks</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span><span class="st">"models/binary_1gram"</span>, save_best_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html">dataset_cache</a></span><span class="op">(</span><span class="va">binary_1gram_train_ds</span><span class="op">)</span>,</span>
<span>  validation_data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html">dataset_cache</a></span><span class="op">(</span><span class="va">binary_1gram_val_ds</span><span class="op">)</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  callbacks <span class="op">=</span> <span class="va">callbacks</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb60"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/binary_1gram"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span></span>
<span>  <span class="st">"Test acc: %.3f\n"</span>, <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">binary_1gram_test_ds</span><span class="op">)</span><span class="op">[</span><span class="st">"accuracy"</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>782/782 - 3s - loss: 0.2856 - accuracy: 0.8868 - 3s/epoch - 4ms/step
Test acc: 0.887</code></pre>
</div>
</div>
<p>Dokładność modelu na zbiorze testowym jest na poziomie 88,7%: nieźle! Należy zauważyć, że w tym przypadku, ponieważ zbiór danych jest zrównoważonym dwuklasowym zbiorem danych klasyfikacyjnych (jest tyle samo próbek pozytywnych, co negatywnych), “naiwny poziom bazowy”, który moglibyśmy osiągnąć bez trenowania rzeczywistego modelu, wynosiłby tylko 50%. Tymczasem najlepszy wynik, jaki można osiągnąć na tym zbiorze danych bez wykorzystywania danych zewnętrznych, wynosi około 95% dokładności testu.</p>
<p>Oczywiście odrzucenie kolejności słów jest bardzo redukcyjne, ponieważ nawet pojęcia elementarne można wyrazić za pomocą wielu słów: termin “Stany Zjednoczone” przekazuje pojęcie, które jest zupełnie odmienne od znaczenia słów “stany” i “zjednoczone” rozpatrywanych osobno. Z tego powodu zwykle kończy się to ponownym wprowadzeniem informacji o lokalnym porządku do reprezentacji worka słów, patrząc na N-gramy, a nie na pojedyncze słowa (najczęściej bigramy).</p>
<p>Warstwę <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code> można skonfigurować tak, aby zwracała dowolne N-gramy: bigramy, trygramy itd. Wystarczy przekazać argument <code>ngrams = N</code>, jak na poniższym listingu.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb62"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">text_vectorization</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span>ngrams <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                           max_tokens <span class="op">=</span> <span class="fl">20000</span>,</span>
<span>                           output_mode <span class="op">=</span> <span class="st">"multi_hot"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Przetestujmy nasz model oparty na bigramach.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/adapt.html">adapt</a></span><span class="op">(</span><span class="va">text_vectorization</span>, <span class="va">text_only_train_ds</span><span class="op">)</span></span>
<span></span>
<span><span class="va">dataset_vectorize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">dataset</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">dataset</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html">dataset_map</a></span><span class="op">(</span><span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu">text_vectorization</span><span class="op">(</span><span class="va">.x</span><span class="op">)</span>, <span class="va">.y</span><span class="op">)</span>,</span>
<span>                num_parallel_calls <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">binary_2gram_train_ds</span> <span class="op">&lt;-</span> <span class="va">train_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dataset_vectorize</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">binary_2gram_val_ds</span> <span class="op">&lt;-</span> <span class="va">val_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dataset_vectorize</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">binary_2gram_test_ds</span> <span class="op">&lt;-</span> <span class="va">test_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dataset_vectorize</span><span class="op">(</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb64"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">get_model</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">model</span></span>
<span><span class="va">callbacks</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span><span class="st">"models/binary_2gram"</span>,</span>
<span>                                           save_best_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html">dataset_cache</a></span><span class="op">(</span><span class="va">binary_2gram_train_ds</span><span class="op">)</span>,</span>
<span>  validation_data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html">dataset_cache</a></span><span class="op">(</span><span class="va">binary_2gram_val_ds</span><span class="op">)</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  callbacks <span class="op">=</span> <span class="va">callbacks</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb65"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/binary_2gram"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">binary_2gram_test_ds</span><span class="op">)</span><span class="op">[</span><span class="st">"accuracy"</span><span class="op">]</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Test acc: %.3f\n"</span>, <span class="va">.</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>782/782 - 3s - loss: 0.2556 - accuracy: 0.9012 - 3s/epoch - 4ms/step
Test acc: 0.901</code></pre>
</div>
</div>
<p>Uzyskujemy teraz 90,1% dokładności testu, co stanowi znaczną poprawę! Okazuje się, że lokalna kolejność jest dość ważna.</p>
<p>Można również dodać nieco więcej informacji do tej reprezentacji, licząc, ile razy występuje każde słowo lub N-gram, czyli biorąc histogram słów w tekście:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb67"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"the"</span> <span class="op">=</span> <span class="fl">2</span>, <span class="st">"the cat"</span> <span class="op">=</span> <span class="fl">1</span>, <span class="st">"cat"</span> <span class="op">=</span> <span class="fl">1</span>, <span class="st">"cat sat"</span> <span class="op">=</span> <span class="fl">1</span>, <span class="st">"sat"</span> <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  <span class="st">"sat on"</span> <span class="op">=</span> <span class="fl">1</span>, <span class="st">"on"</span> <span class="op">=</span> <span class="fl">1</span>, <span class="st">"on the"</span> <span class="op">=</span> <span class="fl">1</span>, <span class="st">"the mat"</span> <span class="op">=</span> <span class="fl">1</span>, <span class="st">"mat"</span> <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>    the the cat     cat cat sat     sat  sat on      on  on the the mat     mat 
      2       1       1       1       1       1       1       1       1       1 </code></pre>
</div>
</div>
<p>Jeśli przeprowadzamy klasyfikację tekstu, wiedza o tym, ile razy słowo występuje w próbce, ma kluczowe znaczenie: każda wystarczająco długa recenzja filmu może zawierać słowo “okropny” niezależnie od nastroju, ale recenzja zawierająca wiele wystąpień słowa “okropny” jest prawdopodobnie negatywna. Oto jak policzyć wystąpienia bigramów za pomocą <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code>:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb69"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">text_vectorization</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span>ngrams <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                           max_tokens <span class="op">=</span> <span class="fl">20000</span>,</span>
<span>                           output_mode <span class="op">=</span> <span class="st">"count"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Oczywiście niektóre słowa będą występować częściej niż inne, niezależnie od tego, o czym jest tekst. Słowa “the”, “a”, “is” i “are” zawsze będą dominować w histogramach liczby słów, zagłuszając inne słowa, mimo że są w zasadzie bezużytecznymi cechami w kontekście klasyfikacji. Jak możemy temu zaradzić?</p>
<p>Poprzez normalizację. Moglibyśmy po prostu znormalizować liczbę słów, odejmując średnią i dzieląc przez wariancję (obliczoną dla całego zbioru danych szkoleniowych). To miałoby sens. Z wyjątkiem tego, że większość wektoryzowanych zdań składa się prawie wyłącznie z zer (nasz poprzedni przykład zawiera 12 niezerowych wpisów i 19 988 zerowych wpisów), co jest właściwością zwaną “rzadkością”. Jest to świetna właściwość, ponieważ znacznie zmniejsza obciążenie obliczeniowe i zmniejsza ryzyko przeuczenia. Gdybyśmy odjęli średnią od każdej cechy, “zniszczylibyśmy” rzadkość. W związku z tym każdy schemat normalizacji, którego używamy, powinien być oparty wyłącznie na dzieleniu. Czego zatem powinniśmy użyć jako mianownika? Najlepszą praktyką jest zastosowanie czegoś, co nazywa się normalizacją TF-IDF - co oznacza “częstotliwość terminów, odwrotność częstotliwości dokumentów”.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Adnotacja
</div>
</div>
<div class="callout-body-container callout-body">
<p>Im częściej dany termin pojawia się w dokumencie, tym ważniejszy jest on dla zrozumienia jego treści. Jednocześnie częstotliwość, z jaką termin pojawia się we wszystkich dokumentach w zbiorze danych, również ma znaczenie: terminy, które pojawiają się w prawie każdym dokumencie (takie jak “the” lub “a”) nie są szczególnie pouczające, podczas gdy terminy, które pojawiają się tylko w niewielkim podzbiorze wszystkich tekstów (takich jak “Herzog”) są bardzo charakterystyczne, a zatem ważne. TF-IDF to metryka, która łączy te dwie koncepcje. Waży dany termin, biorąc “częstotliwość terminu”, ile razy termin pojawia się w bieżącym dokumencie i dzieląc go przez miarę “częstotliwości dokumentu”, która szacuje, jak często termin pojawia się w całym zbiorze danych. Można to obliczyć w następujący sposób:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb70"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tf_idf</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">term</span>, <span class="va">document</span>, <span class="va">dataset</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">term_freq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">document</span> <span class="op">==</span> <span class="va">term</span><span class="op">)</span></span>
<span>  <span class="va">doc_freqs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">dataset</span>, <span class="kw">function</span><span class="op">(</span><span class="va">doc</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">doc</span> <span class="op">==</span> <span class="va">term</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">doc_freq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">doc_freqs</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">term_freq</span> <span class="op">/</span> <span class="va">doc_freq</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>TF-IDF jest tak powszechny, że jest wbudowany w funkcję <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code>. Wszystko, co musimy zrobić, aby zacząć go używać, to przełączyć argument <code>output_mode</code> na “tf_idf”.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb71"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">text_vectorization</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span>ngrams <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                           max_tokens <span class="op">=</span> <span class="fl">20000</span>,</span>
<span>                           output_mode <span class="op">=</span> <span class="st">"tf_idf"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
<p>Przetrenujmy model z tym schematem.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb72"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Wysyłamy tę operację tylko do CPU, ponieważ wykorzystuje ona operacje, których urządzenie GPU jeszcze nie obsługuje.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">device</span><span class="op">(</span><span class="st">"CPU"</span><span class="op">)</span>, <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/adapt.html">adapt</a></span><span class="op">(</span><span class="va">text_vectorization</span>, <span class="va">text_only_train_ds</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="va">tfidf_2gram_train_ds</span> <span class="op">&lt;-</span> <span class="va">train_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dataset_vectorize</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">tfidf_2gram_val_ds</span> <span class="op">&lt;-</span> <span class="va">val_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dataset_vectorize</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">tfidf_2gram_test_ds</span> <span class="op">&lt;-</span> <span class="va">test_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dataset_vectorize</span><span class="op">(</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb73"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">get_model</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">model</span></span>
<span><span class="va">callbacks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span><span class="st">"models/tfidf_2gram"</span>,</span>
<span>                                            save_best_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html">dataset_cache</a></span><span class="op">(</span><span class="va">tfidf_2gram_train_ds</span><span class="op">)</span>,</span>
<span>  validation_data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html">dataset_cache</a></span><span class="op">(</span><span class="va">tfidf_2gram_val_ds</span><span class="op">)</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  callbacks <span class="op">=</span> <span class="va">callbacks</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb74"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/tfidf_2gram"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">tfidf_2gram_test_ds</span><span class="op">)</span><span class="op">[</span><span class="st">"accuracy"</span><span class="op">]</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Test acc: %.3f"</span>, <span class="va">.</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"\n"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>782/782 - 3s - loss: 0.2973 - accuracy: 0.8940 - 3s/epoch - 4ms/step
Test acc: 0.894 </code></pre>
</div>
</div>
<p>Daje nam to 89,4% dokładności testowej w zadaniu klasyfikacji IMDB: nie wydaje się to być szczególnie pomocne w tym przypadku. Jednak w przypadku wielu zestawów danych do klasyfikacji tekstu typowy byłby jednoprocentowy wzrost przy użyciu TF-IDF w porównaniu do zwykłego kodowania binarnego.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Adnotacja
</div>
</div>
<div class="callout-body-container callout-body">
<p>W poprzednich przykładach przeprowadziliśmy standaryzację, podział i indeksowanie tekstu w ramach potoku TF Dataset. Jeśli jednak chcemy wyeksportować samodzielny model niezależny od tego potoku, powinniśmy upewnić się, że zawiera on własne wstępne przetwarzanie tekstu (w przeciwnym razie konieczne będzie ponowne wdrożenie w środowisku produkcyjnym, co może być trudne lub może prowadzić do subtelnych rozbieżności między danymi szkoleniowymi a danymi produkcyjnymi). Na szczęście jest to łatwe.</p>
<p>Wystarczy utworzyć nowy model, który ponownie wykorzysta warstwę <code>text_vectorization</code> i doda do niej właśnie wytrenowany model:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb76"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"string"</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">text_vectorization</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">model</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">inference_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Wynikowy model może przetwarzać partie nieprzetworzonych ciągów znaków:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb77"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">raw_text_data</span> <span class="op">&lt;-</span> <span class="st">"That was an excellent movie, I loved it."</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">predictions</span> <span class="op">&lt;-</span> <span class="fu">inference_model</span><span class="op">(</span><span class="va">raw_text_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">predictions</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.8422111]], dtype=float32)&gt;</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb79"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"%.2f percent positive\n"</span>,</span>
<span>            <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">predictions</span><span class="op">)</span> <span class="op">*</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>84.22 percent positive</code></pre>
</div>
</div>
</div>
</div>
</section><section id="modelowanie-za-pomocą-sekwencji" class="level3" data-number="7.5.3"><h3 data-number="7.5.3" class="anchored" data-anchor-id="modelowanie-za-pomocą-sekwencji">
<span class="header-section-number">7.5.3</span> Modelowanie za pomocą sekwencji</h3>
<p>Te kilka ostatnich przykładów wyraźnie pokazuje, że kolejność słów ma znaczenie: ręczna inżynieria funkcji opartych na kolejności, takich jak bigramy, zapewnia niewielki wzrost dokładności. Zapamiętajmy - historia głębokiego uczenia polega na odejściu od ręcznej inżynierii cech, w kierunku umożliwienia modelom uczenia się własnych cech na podstawie samej ekspozycji na dane. Co by było, gdybyśmy zamiast ręcznie tworzyć funkcje oparte na kolejności, wystawili model na surowe sekwencje słów i pozwolili mu samodzielnie wymyślić takie funkcje? O to właśnie chodzi w modelach opartych na sekwencji.</p>
<p>Aby zaimplementować model sekwencji, należy zacząć od reprezentowania próbek wejściowych jako sekwencji indeksów liczb całkowitych (jedna liczba całkowita oznacza jedno słowo). Następnie mapujemy każdą liczbę całkowitą na wektor, aby uzyskać sekwencje wektorowe. Wreszcie, te sekwencje wektorów należy wprowadzić do stosu warstw, które mogą korelować krzyżowo cechy z sąsiednich wektorów, takich jak konwolucje 1D, RNN lub Transformery.</p>
<p>Przez pewien czas, około 2016-2017 roku, dwukierunkowe RNN (w szczególności dwukierunkowe LSTM) były uważane za najnowocześniejsze rozwiązanie do modelowania sekwencji. Ponieważ jesteśmy już zaznajomieni z tą architekturą, to właśnie jej użyjemy w naszych pierwszych przykładach modeli sekwencji. Jednak obecnie modelowanie sekwencji jest prawie zawsze wykonywane za pomocą transformatorów, które omówimy wkrótce.</p>
<p>Wypróbujmy pierwszy model sekwencji w praktyce. Najpierw przygotujmy zestawy danych zwracające sekwencje liczb całkowitych.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb81"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">max_length</span> <span class="op">&lt;-</span> <span class="fl">600</span></span>
<span><span class="va">max_tokens</span> <span class="op">&lt;-</span> <span class="fl">20000</span></span>
<span></span>
<span><span class="va">text_vectorization</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span></span>
<span>  max_tokens <span class="op">=</span> <span class="va">max_tokens</span>,</span>
<span>  output_mode <span class="op">=</span> <span class="st">"int"</span>,</span>
<span>  output_sequence_length <span class="op">=</span> <span class="va">max_length</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/adapt.html">adapt</a></span><span class="op">(</span><span class="va">text_vectorization</span>, <span class="va">text_only_train_ds</span><span class="op">)</span></span>
<span></span>
<span><span class="va">int_train_ds</span> <span class="op">&lt;-</span> <span class="va">train_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dataset_vectorize</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">int_val_ds</span> <span class="op">&lt;-</span> <span class="va">val_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dataset_vectorize</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">int_test_ds</span> <span class="op">&lt;-</span> <span class="va">test_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dataset_vectorize</span><span class="op">(</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Następnie stwórzmy model. Najprostszym sposobem konwersji naszych sekwencji liczb całkowitych na sekwencje wektorowe jest zakodowanie liczb całkowitych metodą one-hot (każdy wymiar reprezentowałby jeden możliwy termin w słowniku). Na tych wektorach one-hot dodamy prostą dwukierunkową sieć LSTM.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb82"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inputs</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span><span class="op">)</span></span>
<span><span class="va">embedded</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">one_hot</span><span class="op">(</span><span class="va">inputs</span>, depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">max_tokens</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">embedded</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/bidirectional.html">bidirectional</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_lstm.html">layer_lstm</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">32</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">.5</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>                  loss <span class="op">=</span> <span class="st">"binary_crossentropy"</span>,</span>
<span>                  metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span><span class="va">model</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Model: "model_1"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 input_2 (InputLayer)               [(None, None)]                  0           
 tf.one_hot (TFOpLambda)            (None, None, 20000)             0           
 bidirectional (Bidirectional)      (None, 64)                      5128448     
 dropout (Dropout)                  (None, 64)                      0           
 dense (Dense)                      (None, 1)                       65          
================================================================================
Total params: 5128513 (19.56 MB)
Trainable params: 5128513 (19.56 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb84"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">callbacks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span><span class="st">"models/one_hot_bidir_lstm.keras"</span>,</span>
<span>                            save_best_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Podczas uczenia modelu można poczynić dwie obserwacje. Po pierwsze, model ten trenuje się bardzo wolno, szczególnie w porównaniu do modeli z poprzedniego podrozdziału. Wynika to z faktu, że nasze dane wejściowe są dość duże: każda próbka wejściowa jest zakodowana jako macierz o rozmiarze (600, 20000) (600 słów na próbkę, 20 000 możliwych słów). To 12 000 000 wartości dla pojedynczej recenzji filmu. Po drugie, model osiąga tylko 84,7% dokładności testowej, więc nie radzi sobie tak dobrze, jak nasz najlepszy model.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb85"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># aby nie przekroczyć zasobów pamięci GPU zmnieszamy wielkość paczek do 16</span></span>
<span><span class="va">int_train_ds_smaller</span> <span class="op">&lt;-</span> <span class="va">int_train_ds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_unbatch.html">dataset_unbatch</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html">dataset_batch</a></span><span class="op">(</span><span class="fl">16</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">int_train_ds_smaller</span>, validation_data <span class="op">=</span> <span class="va">int_val_ds</span>,</span>
<span>              epochs <span class="op">=</span> <span class="fl">10</span>, callbacks <span class="op">=</span> <span class="va">callbacks</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb86"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># predykcja trwa długo dlatego nie pozwalam na wywołanie tego chunk-a</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/one_hot_bidir_lstm.keras"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Test acc: %.3f"</span>, <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">int_test_ds</span><span class="op">)</span><span class="op">[</span><span class="st">"accuracy"</span><span class="op">]</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Najwyraźniej użycie kodowania one-hot do przekształcenia słów w wektory, nie było dobrym pomysłem. Jest lepszy sposób - osadzanie słów.</p>
</section></section><section id="osadzenia" class="level2 page-columns page-full" data-number="7.6"><h2 data-number="7.6" class="anchored" data-anchor-id="osadzenia">
<span class="header-section-number">7.6</span> Osadzenia</h2>
<p>Kiedy kodujemy coś za pomocą kodowania one-hot, podejmujemy decyzję o inżynierii cech. Wprowadzamy do naszego modelu fundamentalne założenie dotyczące struktury przestrzeni cech. Założeniem tym jest to, że różne tokeny, które kodujemy, są od siebie niezależne: w rzeczywistości wektory one-hot są względem siebie ortogonalne. W przypadku słów założenie to jest oczywiście błędne. Słowa tworzą ustrukturyzowaną przestrzeń: dzielą się ze sobą informacjami. Słowa “movie” i “film” są wymienne w większości zdań, więc wektor reprezentujący “movie” nie powinien być ortogonalny do wektora reprezentującego “film” - powinny być tym samym wektorem lub bardzo zbliżonym.</p>
<p>Podchodząc do sprawy niecobardziej abstrakcyjnie, geometryczna relacja między dwoma wektorami słów powinna odzwierciedlać semantyczną relację między tymi słowami. Na przykład, w rozsądnej przestrzeni wektorów słów można oczekiwać, że synonimy będą osadzone w podobnych wektorach słów, a ogólnie rzecz biorąc, można oczekiwać, że odległość geometryczna (taka jak odległość cosinusowa lub odległość L2) między dowolnymi dwoma wektorami słów będzie odnosić się do “odległości semantycznej” między powiązanymi słowami. Słowa, które oznaczają różne pojęcia, powinny znajdować się daleko od siebie, podczas gdy podobne słowa powinny znajdować się bliżej.</p>
<p>Osadzenia słów to wektorowe reprezentacje słów, które osiągają ten cel: mapują ludzki język na ustrukturyzowaną przestrzeń geometryczną. Podczas gdy wektory uzyskane w wyniku kodowania one-hot są binarne, rzadkie (w większości składają się z zer) i wielowymiarowe (taka sama wymiarowość jak liczba słów w słowniku), osadzenia słów są niskowymiarowymi wektorami typu <em>float</em> (tj. gęstymi wektorami, w przeciwieństwie do rzadkich wektorów) - patrz <a href="#fig-embd1" class="quarto-xref">Rysunek&nbsp;<span>7.2</span></a>. W przypadku bardzo dużych słowników często spotyka się osadzenia słów, które są 256-wymiarowe, 512-wymiarowe lub 1024-wymiarowe. Z drugiej strony, kodowanie słów metodą <em>one-hot</em> zazwyczaj prowadzi do wektorów, które mają 20 000 wymiarów lub więcej (słownik składający się z 20,000 tokenów). Tak więc osadzanie słów zawiera więcej informacji w znacznie mniejszej liczbie wymiarów.</p>
<div id="fig-embd1" class="quarto-figure quarto-figure-center quarto-float anchored" width="400" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-embd1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-03-16 o 16.42.03.png" id="fig-embd1" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-embd1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.2
</figcaption></figure>
</div>
<p>Oprócz tego, że są gęstymi reprezentacjami, osadzenia słów są również reprezentacjami strukturalnymi, a ich struktura jest uczona na podstawie danych. Podobne słowa są osadzone w bliskich lokalizacjach, a ponadto określone kierunki w przestrzeni osadzania mają znaczenie. Aby to wyjaśnić, spójrzmy na konkretny przykład.</p>
<div id="fig-vectors" class="quarto-figure quarto-figure-center quarto-float anchored" width="250" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-vectors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-9 o 22.26.38.png" id="fig-vectors" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" width="250">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-vectors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.3
</figcaption></figure>
</div>
<p>Na <a href="#fig-vectors" class="quarto-xref">Rysunek&nbsp;<span>7.3</span></a> cztery słowa są osadzone na płaszczyźnie 2D: cat, dog, wolf i tiger. Dzięki reprezentacjom wektorowym, które tutaj wybraliśmy, niektóre relacje semantyczne między tymi słowami można zakodować jako transformacje geometryczne. Na przykład ten sam wektor pozwala nam przejść od kota do tygrysa i od psa do wilka: wektor ten można interpretować jako wektor “od zwierzęcia domowego do dzikiego zwierzęcia”. Podobnie, inny wektor pozwala nam przejść od psa do kota i od wilka do tygrysa, co można interpretować jako wektor “od psa do kota”.</p>
<p>W rzeczywistych przestrzeniach osadzania słów, typowymi przykładami znaczących transformacji geometrycznych są wektory “płci” i wektory “liczby mnogiej”. Na przykład, dodając wektor “żeński” do wektora “król”, otrzymujemy wektor “królowa”. Dodając wektor “liczby mnogiej”, otrzymujemy “królów”. Przestrzenie osadzania słów zazwyczaj zawierają tysiące takich interpretowalnych i potencjalnie użytecznych wektorów.</p>
<p>Jeszcze inny przykład osadzenia słów można dostrzec na <a href="#fig-embd2" class="quarto-xref">Rysunek&nbsp;<span>7.4</span></a></p>
<div id="fig-embd2" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-embd2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://editor.analyticsvidhya.com/uploads/450121_sAJdxEsDjsPMioHyzlN3_A.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-embd2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.4: Przykład osadzenia słów
</figcaption></figure>
</div>
<p>Istnieją dwa sposoby na uzyskanie osadzenia słów:</p>
<ul>
<li>Uczenie się embeddingów wspólnie z głównym zadaniem (takim jak klasyfikacja dokumentów lub przewidywanie sentymentu). W tej konfiguracji zaczynamy od losowych wektorów słów, a następnie uczymy się wektorów słów w taki sam sposób, w jaki uczymy się wag sieci neuronowej.</li>
<li>Wczytanie do modelu osadzenia słów, które zostały wstępnie wytrenowane przy użyciu innego zadania uczenia maszynowego niż to, które próbujemy rozwiązać. Są to tzw. wstępnie wytrenowane osadzenia słów.</li>
</ul>
<p>Przyjrzyjmy się obu tym metodom.</p>
<section id="osadzenie-połączone-z-siecią" class="level3" data-number="7.6.1"><h3 data-number="7.6.1" class="anchored" data-anchor-id="osadzenie-połączone-z-siecią">
<span class="header-section-number">7.6.1</span> Osadzenie połączone z siecią</h3>
<p>Czy istnieje jakaś idealna przestrzeń słowotwórcza, która doskonale odwzorowywałaby ludzki język i mogłaby być wykorzystana do każdego zadania związanego z przetwarzaniem języka naturalnego? Możliwe, ale nie udało nam się jeszcze takiej znaleźć. Nie ma też czegoś takiego jak język ludzki - istnieje wiele różnych języków i nie są one izomorficzne, ponieważ język jest odzwierciedleniem konkretnej kultury i konkretnego kontekstu. Bardziej pragmatycznie możemy stwierdzić, że to co czyni przestrzeń osadzania słów dobrą, zależy w dużej mierze od zadania: idealna przestrzeń osadzania słów dla anglojęzycznego modelu analizy sentymentów w recenzji filmowej może wyglądać inaczej niż idealna przestrzeń osadzania dla anglojęzycznego modelu klasyfikacji dokumentów prawnych, ponieważ znaczenie pewnych relacji semantycznych różni się w zależności od zadania.</p>
<p>Dlatego rozsądne jest uczenie się nowej przestrzeni osadzania z każdym nowym zadaniem. Na szczęście wsteczna propagacja to ułatwia, a pakiet <code>keras</code> czyni to jeszcze łatwiejszym. Chodzi o uczenie wag warstwy za pomocą <code>layer_embedding</code>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb87"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">embedding_layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span>input_dim <span class="op">=</span> <span class="va">max_tokens</span>, output_dim <span class="op">=</span> <span class="fl">256</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Funkcja <code><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding()</a></code> jest najlepiej rozumiana jako słownik, który mapuje indeksy liczb całkowitych (które oznaczają określone słowa) na wektory gęste. Przyjmuje liczby całkowite jako dane wejściowe, wyszukuje tych liczb całkowitych w wewnętrznym słowniku i zwraca powiązane wektory.</p>
<p>Warstwa osadzania przyjmuje jako dane wejściowe tensor liczb całkowitych, o kształcie (<code>batch_size, sequence_length</code>), gdzie każdy wpis jest sekwencją liczb całkowitych. Następnie warstwa zwraca tensor zmiennoprzecinkowy 3D o kształcie (<code>batch_size, sequence_length, embedding_dimensionality</code>).</p>
<p>Po utworzeniu instancji <code><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding()</a></code>, jej wagi (wewnętrzny słownik wektorów tokenów) są początkowo losowe, tak jak w przypadku każdej innej warstwy. Podczas uczenia te wektory słów są stopniowo dostosowywane za pomocą wstecznej propagacji, strukturyzując przestrzeń w coś, co może wykorzystać dalszy model. Po pełnym wytrenowaniu, przestrzeń osadzania będzie wykazywać dużą strukturę - rodzaj struktury wyspecjalizowanej dla konkretnego problemu, dla którego trenujemy nasz model.</p>
<p>Zbudujmy model zawierający funkcję <code><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding()</a></code> i przetestujmy go w naszym zadaniu.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb88"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span><span class="op">)</span></span>
<span><span class="va">embedded</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span>input_dim <span class="op">=</span> <span class="va">max_tokens</span>, output_dim <span class="op">=</span> <span class="fl">256</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">embedded</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/bidirectional.html">bidirectional</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_lstm.html">layer_lstm</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">32</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>          loss <span class="op">=</span> <span class="st">"binary_crossentropy"</span>,</span>
<span>          metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span><span class="va">model</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Model: "model_2"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 input_3 (InputLayer)               [(None, None)]                  0           
 embedding_1 (Embedding)            (None, None, 256)               5120000     
 bidirectional_1 (Bidirectional)    (None, 64)                      73984       
 dropout_1 (Dropout)                (None, 64)                      0           
 dense_1 (Dense)                    (None, 1)                       65          
================================================================================
Total params: 5194049 (19.81 MB)
Trainable params: 5194049 (19.81 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb90"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">callbacks</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span><span class="st">"models/embeddings_bidir_lstm.keras"</span>,</span>
<span>                                           save_best_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb91"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">int_train_ds</span>,</span>
<span>      validation_data <span class="op">=</span> <span class="va">int_val_ds</span>,</span>
<span>      epochs <span class="op">=</span> <span class="fl">10</span>,</span>
<span>      callbacks <span class="op">=</span> <span class="va">callbacks</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb92"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/embeddings_bidir_lstm.keras"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">int_test_ds</span><span class="op">)</span><span class="op">[</span><span class="st">"accuracy"</span><span class="op">]</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Test acc: %.3f\n"</span>, <span class="va">.</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"\n"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>782/782 - 26s - loss: 0.4049 - accuracy: 0.8601 - 26s/epoch - 33ms/step
Test acc: 0.860
 </code></pre>
</div>
</div>
<p>Model ten uczy się znacznie szybciej niż model <em>one-hot</em> (ponieważ LSTM musi przetwarzać tylko 256-wymiarowe wektory zamiast 20 000-wymiarowych), a jego dokładność na zbiorze testowym jest porównywalna (86,0%). Jednak wciąż jesteśmy daleko od wyników naszego podstawowego modelu bigramowego. Częściowo wynika to z faktu, że model ten analizuje nieco mniej danych: model bigramowy przetwarza pełne recenzje, podczas gdy nasz model sekwencji obcina sekwencje po 600 słowach.</p>
<p>Jedną z rzeczy, która nieco obniża wydajność modelu, jest to, że nasze sekwencje wejściowe są pełne zer. Wynika to z naszego użycia opcji <code>output_sequence_length = max_length</code> w <code><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization()</a></code> (z <code>max_length</code> równą 600) - zdania dłuższe niż 600 tokenów są obcinane do długości 600 tokenów, a zdania krótsze niż 600 tokenów są wypełniane zerami na końcu, aby można je było połączyć z innymi sekwencjami w celu utworzenia ciągłych partii.</p>
<p>Używamy dwukierunkowej sieci RNN - dwie warstwy RNN działające równolegle, z których jedna przetwarza tokeny w ich naturalnej kolejności, a druga przetwarza te same tokeny w odwrotnej kolejności. RNN, która patrzy na tokeny w ich naturalnej kolejności, poświęci swoje ostatnie iteracje na “oglądaniu” tylko tych wektory, które kodują <em>padding</em> - prawdopodobnie przez kilkaset iteracji, jeśli oryginalne zdanie było krótkie. Informacje przechowywane w wewnętrznym stanie RNN będą stopniowo zanikać, gdy będą narażone na bezsensowne dane wejściowe.</p>
<p>Potrzebujemy zatem jakiegoś sposobu, aby przekazać RNN, że powinna pominąć te iteracje. Jest do tego API - maskowanie. <code><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding()</a></code> jest w stanie wygenerować “maskę”, która odpowiada danym wejściowym. Maska ta jest tensorem jedynek i zer (lub <code>TRUE/FALSE</code>), o kształcie (<code>batch_size, sequence_length</code>), gdzie wpis <code>mask[i, t]</code> odpowiada, czy krok czasowy <code>t</code> próbki <code>i</code> powinien zostać pominięty, czy nie (krok czasowy zostanie pominięty, jeśli <code>mask[i, t]</code> ma wartość 0 lub FALSE, i przetworzony w przeciwnym razie).</p>
<p>Domyślnie opcja ta nie jest aktywna - można ją włączyć, przekazując <code>mask_zero = TRUE</code> do funkcji <code><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding()</a></code>. Maskę można pobrać za pomocą metody <code>compute_mask()</code>:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb94"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">embedding_layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span>input_dim <span class="op">=</span> <span class="fl">10</span>, output_dim <span class="op">=</span> <span class="fl">256</span>,</span>
<span>                                   mask_zero <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">some_input</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">3</span>, <span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>                    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">4</span>, <span class="fl">3</span>, <span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>                    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mask</span> <span class="op">&lt;-</span> <span class="va">embedding_layer</span><span class="op">$</span><span class="fu">compute_mask</span><span class="op">(</span><span class="va">some_input</span><span class="op">)</span></span>
<span><span class="va">mask</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(
[[ True  True  True  True False False False]
 [ True  True  True  True  True False False]
 [ True  True False False False False False]], shape=(3, 7), dtype=bool)</code></pre>
</div>
</div>
<p>W praktyce prawie nigdy nie będziemy musieli ręcznie zarządzać maskami. Zamiast tego, <code>keras</code> automatycznie przekaże maskę do każdej warstwy, która jest w stanie ją przetworzyć (jako metadane dołączone do sekwencji, którą reprezentuje). Maska ta będzie używana przez warstwy RNN do pomijania zamaskowanych kroków. Jeśli model zwraca całą sekwencję, maska będzie również używana przez funkcję straty do pomijania zamaskowanych kroków w sekwencji wyjściowej. Spróbujmy przeformułować nasz model na model z włączoną funkcją maskowania.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb96"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span><span class="op">)</span></span>
<span><span class="va">embedded</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span>input_dim <span class="op">=</span> <span class="va">max_tokens</span>,</span>
<span>                  output_dim <span class="op">=</span> <span class="fl">256</span>,</span>
<span>                  mask_zero <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">embedded</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/bidirectional.html">bidirectional</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_lstm.html">layer_lstm</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">32</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>                  loss <span class="op">=</span> <span class="st">"binary_crossentropy"</span>,</span>
<span>                  metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span><span class="va">model</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Model: "model_3"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 input_4 (InputLayer)               [(None, None)]                  0           
 embedding_3 (Embedding)            (None, None, 256)               5120000     
 bidirectional_2 (Bidirectional)    (None, 64)                      73984       
 dropout_2 (Dropout)                (None, 64)                      0           
 dense_2 (Dense)                    (None, 1)                       65          
================================================================================
Total params: 5194049 (19.81 MB)
Trainable params: 5194049 (19.81 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb98"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">callbacks</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span><span class="st">"models/embeddings_bidir_lstm_with_masking.keras"</span>,</span>
<span>                            save_best_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb99"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  <span class="va">int_train_ds</span>,</span>
<span>  validation_data <span class="op">=</span> <span class="va">int_val_ds</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  callbacks <span class="op">=</span> <span class="va">callbacks</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb100"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/embeddings_bidir_lstm_with_masking.keras"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Test acc: %.3f\n"</span>,</span>
<span>            <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">int_test_ds</span><span class="op">)</span><span class="op">[</span><span class="st">"accuracy"</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>782/782 - 31s - loss: 2.4718 - accuracy: 0.5019 - 31s/epoch - 39ms/step
Test acc: 0.502</code></pre>
</div>
</div>
<p>Tym razem osiągnęliśmy 86,8% dokładności na zbiorze testowym - niewielka, ale zauważalna poprawa.</p>
</section><section id="użycie-wstępnie-wytrenowanego-osadzenia" class="level3 page-columns page-full" data-number="7.6.2"><h3 data-number="7.6.2" class="anchored" data-anchor-id="użycie-wstępnie-wytrenowanego-osadzenia">
<span class="header-section-number">7.6.2</span> Użycie wstępnie wytrenowanego osadzenia</h3>
<p>Czasami dostępnych jest tak mało danych szkoleniowych, aby użyć ich do nauczenia się odpowiedniego, specyficznego dla danego zadania osadzenia słownictwa. W takich przypadkach, zamiast uczyć osadzania słów razem z głównym problemem, który chcemy rozwiązać, możemy załadować wektory osadzania ze wstępnie obliczonej przestrzeni osadzania, o której wiemy, że jest wysoce ustrukturyzowana i wykazuje użyteczne właściwości - takie, które wychwytują ogólne aspekty struktury języka. Uzasadnienie używania wstępnie wytrenowanych osadzeń słów w przetwarzaniu języka naturalnego jest takie samo, jak w przypadku używania wstępnie wytrenowanych sieci konwolucyjnych w klasyfikacji obrazów: nie mamy wystarczającej ilości danych, aby samodzielnie nauczyć się odpowiednich funkcji, ale spodziewamy się, że funkcje, których potrzebujemy, są dość ogólne - to znaczy, że mają wspólne cechy wizualne lub cechy semantyczne. W takim przypadku sensowne jest ponowne wykorzystanie cech wyuczonych dla innego problemu.</p>
<p>Takie osadzenia słów są zazwyczaj tworzone przy użyciu statystyk występowania słów (obserwacje dotyczące tego, jakie słowa współwystępują w zdaniach lub dokumentach), przy użyciu różnych technik, z których niektóre obejmują sieci neuronowe, a inne nie. Idea gęstej, niskowymiarowej przestrzeni osadzania słów, obliczanej w sposób nienadzorowany, została początkowo zbadana przez Bengio i in. na początku XXI wieku <span class="citation" data-cites="bengioNeuralProbabilisticLanguage">(<a href="references.html#ref-bengioNeuralProbabilisticLanguage" role="doc-biblioref">Bengio i in., b.d.</a>)</span>, ale zaczęła się rozwijać w badaniach i zastosowaniach przemysłowych dopiero po wydaniu jednego z najbardziej znanych i udanych schematów osadzania słów: algorytmu Word2Vec (<a href="https://code.google.com/archive/p/word2vec" class="uri">https://code.google.com/archive/p/word2vec</a>), opracowanego przez Tomasa Mikolova w Google w 2013 roku. Osadzenie Word2Vec wychwytuje specyficzne właściwości semantyczne, takie jak płeć.</p>
<p>Można pobrać różne wstępnie wytrenowane bazy danych osadzania słów i użyć ich w funkcji Keras <code><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding()</a></code>. Word2Vec jest jedną z nich. Inną popularną wersją osadzenia słów jest Global Vectors for Word Representation (GloVe, <a href="https://nlp.stanford.edu/projects/glove" class="uri">https://nlp.stanford.edu/projects/glove</a>), która została opracowana przez naukowców ze Stanford w 2014 roku. Ta technika osadzania opiera się na faktoryzacji macierzy statystyk współwystępowania słów. Jej twórcy udostępnili wstępnie obliczone osadzenia dla milionów angielskich tokenów, uzyskanych z Wikipedii i danych Common Crawl<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<div class="no-row-height column-margin column-container"><p><sup>5</sup>&nbsp;Common Crawl to non-profit organizacja udostępniająca darmowe, ogromne archiwa danych internetowych do wykorzystania w badaniach, analizie i projektach z zakresu technologii informatycznych.</p></div><p>Przyjrzyjmy się, jak można rozpocząć korzystanie z GloVe embeddings w modelu Keras. Ta sama metoda jest odpowiednia dla osadzeń Word2Vec lub dowolnej innej bazy danych osadzeń słów. Zaczniemy od pobrania plików GloVe i przeanalizowania ich. Następnie załadujemy wektory słów do warstwy Keras <code><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding()</a></code>, której użyjemy do zbudowania nowego modelu.</p>
<p>Najpierw pobierzmy osadzenia słów GloVe wstępnie obliczone na zbiorze danych angielskiej Wikipedii z 2014 roku. Jest to plik zip o rozmiarze 822 MB zawierający 100-wymiarowe wektory osadzania dla 400 000 słów (lub tokenów niebędących słowami):</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb102"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span><span class="op">(</span><span class="st">"http://nlp.stanford.edu/data/glove.6B.zip"</span>,</span>
<span>              destfile <span class="op">=</span> <span class="st">"glove.6B.zip"</span><span class="op">)</span></span>
<span><span class="fu">zip</span><span class="fu">::</span><span class="fu"><a href="https://r-lib.github.io/zip/reference/unzip.html">unzip</a></span><span class="op">(</span><span class="st">"glove.6B.zip"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Przeanalizujmy rozpakowany plik (plik .txt), aby utworzyć indeks, który mapuje słowa (jako ciągi) na ich reprezentację wektorową.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb103"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">path_to_glove_file</span> <span class="op">&lt;-</span> <span class="st">"~/Downloads/glove.6B/glove.6B.100d.txt"</span></span>
<span><span class="va">embedding_dim</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">readr</span><span class="fu">::</span><span class="fu"><a href="https://readr.tidyverse.org/reference/read_table.html">read_table</a></span><span class="op">(</span></span>
<span>  <span class="va">path_to_glove_file</span>,</span>
<span>  col_names <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  col_types <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"c"</span>, <span class="fu"><a href="https://rdrr.io/r/base/strrep.html">strrep</a></span><span class="op">(</span><span class="st">"n"</span>, <span class="fl">100</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">embeddings_index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">embeddings_index</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">embeddings_index</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/rm.html">rm</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Oto jak wygląda <code>embedding_matrix</code>:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb104"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">embeddings_index</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:400000, 1:100] -0.0382 -0.1077 -0.3398 -0.1529 -0.1897 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:400000] "the" "," "." "of" ...
  ..$ : NULL</code></pre>
</div>
</div>
<p>Następnie zbudujmy macierz osadzania, którą można załadować do funkcji <code><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding()</a></code>, Musi to być macierz o kształcie (<code>max_words, embedding_dim</code>), gdzie każdy wpis i zawiera wektor wymiaru <code>embedding_dim</code> dla słowa o indeksie <code>i</code> w indeksie słowa referencyjnego (zbudowanym podczas tokenizacji).</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb106"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="va">text_vectorization</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">get_vocabulary</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">vocabulary</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> chr [1:20000] "" "[UNK]" "the" "a" "and" "of" "to" "is" "in" "it" "i" ...</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb108"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tokens</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">vocabulary</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span>, <span class="va">max_tokens</span><span class="op">)</span></span>
<span></span>
<span><span class="va">i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/match.html">match</a></span><span class="op">(</span><span class="va">vocabulary</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">embeddings_index</span><span class="op">)</span>,</span>
<span>           nomatch <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">embedding_matrix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="fl">0</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">max_tokens</span>, <span class="va">embedding_dim</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">embedding_matrix</span><span class="op">[</span><span class="va">i</span> <span class="op">!=</span> <span class="fl">0</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">embeddings_index</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">embedding_matrix</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:20000, 1:100] 0 0 -0.0382 -0.2709 -0.072 ...</code></pre>
</div>
</div>
<p>Na koniec użyjemy funkcji <code><a href="https://rdrr.io/pkg/keras/man/initializer_constant.html">initializer_constant()</a></code>, aby załadować wstępnie wytrenowane osadzenia do <code><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding()</a></code>. Aby nie zakłócać wstępnie wytrenowanych reprezentacji podczas szkolenia, zamrażamy warstwę za pomocą <code>trainable = FALSE</code>:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb110"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">embedding_layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span></span>
<span>  input_dim <span class="op">=</span> <span class="va">max_tokens</span>,</span>
<span>  output_dim <span class="op">=</span> <span class="va">embedding_dim</span>,</span>
<span>  embeddings_initializer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/initializer_constant.html">initializer_constant</a></span><span class="op">(</span><span class="va">embedding_matrix</span><span class="op">)</span>,</span>
<span>  trainable <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  mask_zero <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Jesteśmy teraz gotowi do trenowania nowego modelu - identycznego z naszym poprzednim modelem, ale wykorzystującego 100-wymiarowe wstępnie wytrenowane osadzenia GloVe zamiast 128-wymiarowych wyuczonych osadzeń.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb111"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, dtype<span class="op">=</span><span class="st">"int64"</span><span class="op">)</span></span>
<span><span class="va">embedded</span> <span class="op">&lt;-</span> <span class="fu">embedding_layer</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">embedded</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/bidirectional.html">bidirectional</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_lstm.html">layer_lstm</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">32</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">'rmsprop'</span>,</span>
<span>                  loss <span class="op">=</span> <span class="st">"binary_crossentropy"</span>,</span>
<span>                  metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span><span class="va">model</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Model: "model_4"
________________________________________________________________________________
 Layer (type)                  Output Shape               Param #    Trainable  
================================================================================
 input_5 (InputLayer)          [(None, None)]             0          Y          
 embedding_4 (Embedding)       (None, None, 100)          2000000    N          
 bidirectional_3 (Bidirection  (None, 64)                 34048      Y          
 al)                                                                            
 dropout_3 (Dropout)           (None, 64)                 0          Y          
 dense_3 (Dense)               (None, 1)                  65         Y          
================================================================================
Total params: 2034113 (7.76 MB)
Trainable params: 34113 (133.25 KB)
Non-trainable params: 2000000 (7.63 MB)
________________________________________________________________________________</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb113"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">callbacks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span><span class="st">"models/glove_embeddings_sequence_model2.keras"</span>,</span>
<span>                            save_best_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb114"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">int_train_ds</span>, validation_data <span class="op">=</span> <span class="va">int_val_ds</span>,</span>
<span>      epochs <span class="op">=</span> <span class="fl">10</span>, callbacks <span class="op">=</span> <span class="va">callbacks</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb115"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/glove_embeddings_sequence_model2.keras"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span></span>
<span>  <span class="st">"Test acc: %.3f\n"</span>, <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">int_test_ds</span><span class="op">)</span><span class="op">[</span><span class="st">"accuracy"</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>782/782 - 31s - loss: 0.5601 - accuracy: 0.7365 - 31s/epoch - 39ms/step
Test acc: 0.736</code></pre>
</div>
</div>
<p>Przekonaliśmy się, że w tym konkretnym zadaniu wstępnie wytrenowane osadzenia nie są zbyt pomocne (dopasowanie na zbiorze testowym na poziomie 73,6%), ponieważ zbiór danych zawiera wystarczającą liczbę próbek, aby można było nauczyć się od podstaw wystarczająco wyspecjalizowanej przestrzeni osadzania. Jednak wykorzystanie wstępnie wytrenowanych osadzeń może być bardzo pomocne, gdy pracujesz z mniejszym zbiorem danych.</p>
</section></section><section id="transformery" class="level2" data-number="7.7"><h2 data-number="7.7" class="anchored" data-anchor-id="transformery">
<span class="header-section-number">7.7</span> Transformery</h2>
<p>Począwszy od 2017 roku, nowa architektura modelu zaczęła wyprzedzać rekurencyjne sieci neuronowe w większości zadań przetwarzania języka naturalnego. Jest nią transformer lub transformator (ang. <em>transformer</em>). Transformery zostały wprowadzone w przełomowym artykule “Attention Is All You Need” autorstwa <span class="citation" data-cites="vaswaniAttentionAllYou2023">Vaswani i in. (<a href="references.html#ref-vaswaniAttentionAllYou2023" role="doc-biblioref">b.d.</a>)</span>. Sedno artykułu znajduje się w tytule: jak się okazało, prosty mechanizm zwany “uwagą neuronową” (ang. <em>neural attention</em>) można wykorzystać do zbudowania potężnych modeli sekwencji, które nie zawierają żadnych warstw rekurencyjnych ani warstw splotowych.</p>
<p>Odkrycie to zapoczątkowało rewolucję w przetwarzaniu języka naturalnego i nie tylko. Uwaga neuronowa szybko stała się jedną z najbardziej wpływowych idei w uczeniu głębokim. W tym podrozdziale przybliżymy jak to działa i dlaczego okazało się tak skuteczne w przypadku danych sekwencyjnych. Następnie wykorzystamy samouczenie się do stworzenia kodera Transformer, jednego z podstawowych komponentów architektury Transformer i zastosujemy go do zadania klasyfikacji recenzji filmów IMDB.</p>
<section id="warstwy-atencji" class="level3" data-number="7.7.1"><h3 data-number="7.7.1" class="anchored" data-anchor-id="warstwy-atencji">
<span class="header-section-number">7.7.1</span> Warstwy atencji</h3>
<p>Czytając tę książkę, możesz jedynie przeglądać niektóre jej części, a inne uważnie czytać, w zależności od tego, jakie są twoje cele lub zainteresowania. Co by było, gdyby modele robiły to samo? Wykorzystamy prosty pomysł: nie wszystkie informacje wejściowe widziane przez model są równie ważne dla danego zadania, więc modele powinny “zwracać większą uwagę” na niektóre funkcje i “zwracać mniejszą uwagę” na inne funkcje. Czy to brzmi znajomo? Z podobną koncepcją spotkałeś się już dwukrotnie:</p>
<ul>
<li>
<em>Max pooling</em> w sieciach splotowych patrzy na pulę cech w regionie przestrzennym i wybiera tylko jedną cechę do zachowania. Jest to forma uwagi “wszystko albo nic” - zachowaj najważniejszą cechę i odrzuć resztę.</li>
<li>Normalizacja TF-IDF przypisuje tokenom współczynnik ważności w oparciu o to, ile informacji mogą przenosić różne tokeny. Ważne tokeny są wzmacniane, podczas gdy nieistotne tokeny są wygaszane. Jest to ciągła forma uwagi.</li>
</ul>
<p>Istnieje wiele różnych form uwagi, które można sobie wyobrazić, ale wszystkie zaczynają się od znalezienia wskaźnika uwagi dla zestawu cech, z wyższymi wskaźnikami dla bardziej istotnych cech i niższymi dla mniej istotnych (patrz <a href="#fig-attention1" class="quarto-xref">Rysunek&nbsp;<span>7.5</span></a>). Sposób obliczania tych wskaźników i to, co należy z nimi zrobić, będzie się różnić w zależności od podejścia.</p>
<div id="fig-attention1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-attention1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-10 o 13.57.40.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="500">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-attention1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.5: Ogólna koncepcja atencji w uczeniu głębokim: Cechom wejściowym przypisywane są wskaźniki uwagi, które można przekazać do następnej reprezentacji danych wejściowych.
</figcaption></figure>
</div>
<p>Co najważniejsze, ten rodzaj mechanizmu uwagi może być wykorzystywany do czegoś więcej niż tylko podkreślania lub wymazywania pewnych cech. Można go wykorzystać do uświadomienia kontekstu funkcji. Właśnie dowiedzieliśmy się o osadzaniu słów, czyli przestrzeniach wektorowych, które przechwytują “strukturę” relacji semantycznych między różnymi słowami. W przestrzeni osadzania pojedyncze słowo ma stałą pozycję - stały zestaw relacji z każdym innym słowem w przestrzeni. Ale nie do końca tak działa język - znaczenie słowa jest zwykle zależne od kontekstu. Kiedy zaznaczamy datę w kalendarzu (ang. <em>date</em>), nie mówimy o “randce”. Kiedy mówimy “I’ll see you soon”, znaczenie słowa “see” jest subtelnie inne niż “see” w “I see what you mean” lub “I’ll see this project to its end”. I oczywiście znaczenie zaimków takich jak “he”, “it”, “you” i tak dalej jest całkowicie zależne od zdania i mogą zmieniać się wielokrotnie w jednym zdaniu.</p>
<p>Oczywiście inteligentna przestrzeń osadzania zapewniłaby inną reprezentację wektorową dla słowa w zależności od innych otaczających go słów. W tym miejscu pojawia się samo-atencja. Celem samo-uwagi jest modulowanie reprezentacji tokena poprzez wykorzystanie reprezentacji powiązanych tokenów w sekwencji. W ten sposób powstają reprezentacje tokenów świadome kontekstu. Rozważmy przykładowe zdanie: “The train left the station on time”. Rozważmy teraz jedno słowo w zdaniu: <em>station</em>. O jakiej stacji mówimy? Czy może to być stacja radiowa? Może Międzynarodowa Stacja Kosmiczna? Rozważmy to algorytmicznie za pomocą samo-atencji (patrz <a href="#fig-attention2" class="quarto-xref">Rysunek&nbsp;<span>7.6</span></a>)</p>
<div id="fig-attention2" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-attention2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-10 o 14.08.20.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-attention2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.6: Samo-atencja. Wskaźniki uwagi są obliczane między “station” a każdym innym słowem w sekwencji, a następnie są używane do ważenia sumy wektorów słów, które stają się nowym wektorem “station”.
</figcaption></figure>
</div>
<p>Krok 1 polega na obliczeniu wskaźników trafności między wektorem dla “station” a każdym innym słowem w zdaniu. Są to nasze “wskaźniki uwagi”. Zamierzamy zastosować iloczyn skalarny pomiędzy dwoma wektorami słów jako miary siły ich związku. Jest to bardzo wydajna obliczeniowo funkcja odległości i była już standardowym sposobem powiązania ze sobą dwóch osadzeń słów na długo przed transformerami. W praktyce wyniki te będą również przechodzić przez funkcję skalowania i softmax, ale na razie jest to tylko szczegół implementacji.</p>
<p>Krok 2 polega na obliczeniu sumy wszystkich wektorów słów w zdaniu, ważonych przez nasze wskaźniki atencji. Słowa blisko związane ze słowem “station” będą miały większy udział w sumie (w tym samo słowo “station”), podczas gdy słowa nieistotne nie wniosą prawie nic. Wynikowy wektor jest naszą nową reprezentacją dla “station”, reprezentacją, która uwzględnia otaczający kontekst. W szczególności zawiera ona część wektora “train”, wyjaśniając, że w rzeczywistości jest to “train station”.</p>
<p>Powtarzamy ten proces dla każdego słowa w zdaniu, tworząc nową sekwencję wektorów kodujących zdanie. Zobaczmy to w pseudokodzie R:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb117"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">self_attention</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_sequence</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">sequence_len</span>, <span class="va">embedding_size</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html">%&lt;-%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">input_sequence</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">output</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">input_sequence</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">sequence_len</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>    <span class="va">pivot_vector</span> <span class="op">&lt;-</span> <span class="va">input_sequence</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span></span>
<span></span>
<span>    <span class="va">scores</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">sequence_len</span>, <span class="kw">function</span><span class="op">(</span><span class="va">j</span><span class="op">)</span></span>
<span>      <span class="va">pivot_vector</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">input_sequence</span><span class="op">[</span><span class="va">j</span>, <span class="op">]</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">scores</span> <span class="op">&lt;-</span> <span class="fu">softmax</span><span class="op">(</span><span class="va">scores</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">embedding_size</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">broadcast_scores</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">scores</span><span class="op">)</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">embedding_size</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span>    <span class="va">new_pivot_representation</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colSums</a></span><span class="op">(</span><span class="va">input_sequence</span> <span class="op">*</span> <span class="va">broadcast_scores</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">output</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">new_pivot_representation</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">output</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">softmax</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>   <span class="va">e</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span>   <span class="va">e</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">e</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb118"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">sequence_length</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span><span class="va">embed_dim</span> <span class="op">&lt;-</span> <span class="fl">256</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">sequence_length</span>, <span class="va">embed_dim</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Oczywiście, w praktyce można użyć implementacji zwektoryzowanej. Keras ma wbudowaną warstwę do obsługi tego - <code><a href="https://rdrr.io/pkg/keras/man/layer_multi_head_attention.html">layer_multi_head_attention()</a></code>. Oto jak można jej użyć:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb119"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">num_heads</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="va">embed_dim</span> <span class="op">&lt;-</span> <span class="fl">256</span></span>
<span></span>
<span><span class="va">mha_layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_multi_head_attention.html">layer_multi_head_attention</a></span><span class="op">(</span>num_heads <span class="op">=</span> <span class="va">num_heads</span>,</span>
<span>                                        key_dim <span class="op">=</span> <span class="va">embed_dim</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu">mha_layer</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">inputs</span>, <span class="va">inputs</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Czytając to, prawdopodobnie zastanawiasz się: dlaczego przekazujemy dane wejściowe do warstwy trzy razy? Wydaje się to zbędne. Czym są te “wielokrotne głowy”? Oba te pytania mają proste odpowiedzi.</p>
</section><section id="uogólnienie-samo-atencji" class="level3" data-number="7.7.2"><h3 data-number="7.7.2" class="anchored" data-anchor-id="uogólnienie-samo-atencji">
<span class="header-section-number">7.7.2</span> Uogólnienie samo-atencji</h3>
<p>Do tej pory rozważaliśmy tylko jedną sekwencję wejściową. Jednak architektura transformera została pierwotnie opracowana dla tłumaczenia maszynowego, gdzie mamy do czynienia z dwiema sekwencjami wejściowymi: sekwencją źródłową, którą aktualnie tłumaczysz (np. “How’s the weather today?”) i sekwencją docelową, na którą ją konwertujesz (np. “¿Qué tiempo hace hoy?”). Transformer jest modelem dziłającym od sekwencji do sekwencji. Został zaprojektowany do konwersji jednej sekwencji na inną.</p>
<p>Teraz cofnijmy się o krok. Mechanizm samo-uwagi, tak jak go przedstawiliśmy, wykonuje następujące czynności, schematycznie:</p>
<div id="fig-attention3" class="quarto-figure quarto-figure-center quarto-float anchored" width="500" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-attention3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-10 o 14.23.50.png" id="fig-attention3" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" width="500">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-attention3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.7
</figcaption></figure>
</div>
<p>Oznacza to, że “dla każdego tokena w wejściach (A) obliczamy, jak bardzo token jest powiązany z każdym tokenem w wejściach (B) i używamy tych wyników do ważenia sumy tokenów z wejść (C)”. Co najważniejsze, nie wymgamy, aby A, B i C odnosiły się do tej samej sekwencji wejściowej. W ogólnym przypadku można to zrobić z trzema różnymi sekwencjami. Nazwiemy je “zapytaniem” (ang. <em>query</em>), “kluczami” (ang. <em>key</em>) i “wartościami” (ang. <em>value</em>). Operacja ta zamienia się w “dla każdego elementu w zapytaniu oblicz, jak bardzo element jest powiązany z każdym kluczem i użyj tych wyników do ważenia sumy wartości”:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb120"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="va">values</span> <span class="op">*</span> <span class="fu">pairwise_scores</span><span class="op">(</span> <span class="va">query</span>, <span class="va">keys</span> <span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Terminologia ta pochodzi z wyszukiwarek i systemów rekomendacji (patrz <a href="#fig-attention4" class="quarto-xref">Rysunek&nbsp;<span>7.8</span></a>). Wyobraźmy sobie, że wpisujemy zapytanie, aby pobrać zdjęcie ze swojej kolekcji, “dogs on the beach”. Wewnętrznie, każde z naszych zdjęć w bazie danych jest opisane przez zestaw słów kluczowych - “cat”, “dog”, “party” i tak dalej. Nazwiemy je “kluczami”. Wyszukiwarka rozpocznie od porównania zapytania z kluczami w bazie danych. “dog” daje dopasowanie 1 dla naszego wyszukiwania, a “cat” daje dopasowanie 0. Następnie algorytm szereguje te klucze według siły dopasowania - trafności - i zwraca zdjęcia powiązane z <span class="math inline">\(N\)</span> najlepszymi dopasowaniami, w kolejności trafności.</p>
<div id="fig-attention4" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-attention4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-10 o 14.30.59.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="500">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-attention4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.8: Pobieranie obrazów z bazy danych. “Zapytanie” jest porównywane z zestawem “kluczy”, a wyniki dopasowania są wykorzystywane do uszeregowania “wartości” (obrazów).
</figcaption></figure>
</div>
<p>Chcąc wyrazić dokładnie wskaźniki atencji wzorem matematycznym, napisalibyśmy:</p>
<p><span class="math display">\[
\operatorname{AS}(Q,K,V)=\operatorname{Softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V,
\]</span></p>
<p>gdzie <span class="math inline">\(Q,K,V\)</span> oznaczają odpowiednio query, key i value, <span class="math inline">\(d_k\)</span> oznacza długość reprezentacji tokenu w osadzeniu.</p>
<p>Koncepcyjnie, to właśnie te czynności wykonuje warstwa atencji w transformerach. Mamy sekwencję referencyjną, która opisuje coś, czego szukamy: zapytanie. Mamy zbiór wiedzy, z którego próbujemy wydobyć informacje: wartości. Każda wartość ma przypisany klucz, który opisuje wartość w formacie, który można łatwo porównać z zapytaniem. Wystarczy dopasować zapytanie do kluczy. Następnie zwracana jest ważona suma wartości.</p>
<p>W praktyce klucze i wartości to często ta sama sekwencja. Na przykład w tłumaczeniu maszynowym zapytanie byłoby sekwencją docelową, a sekwencja źródłowa odgrywałaby rolę zarówno kluczy, jak i wartości: dla każdego elementu celu (takiego jak “tiempo”) chcemy wrócić do źródła (“How’s the weather today?”) i zidentyfikować różne bity, które są z nim powiązane (“tiempo” i “weather” powinny mieć silne dopasowanie). Oczywiście, jeśli wykonujemy tylko klasyfikację sekwencji, to zapytanie, klucze i wartości są takie same: porównujemy sekwencję z samą sobą, aby wzbogacić każdy token o kontekst z całej sekwencji.</p>
<p>To wyjaśnia, dlaczego musieliśmy przekazać dane wejściowe trzy razy do naszej warstwy <code><a href="https://rdrr.io/pkg/keras/man/layer_multi_head_attention.html">layer_multi_head_attention()</a></code>. Ale po co atencja typu <em>multi-head</em>?</p>
</section><section id="atencja-typu-multi-head" class="level3" data-number="7.7.3"><h3 data-number="7.7.3" class="anchored" data-anchor-id="atencja-typu-multi-head">
<span class="header-section-number">7.7.3</span> Atencja typu <em>multi-head</em>
</h3>
<p><em>Multi-head attention</em> to dodatkowe ulepszenie mechanizmu samo-uwagi, wprowadzone w “Attention Is All You Need”. Przydomek <em>multi-head</em> odnosi się do faktu, że przestrzeń wyjściowa warstwy samo-uwagi jest podzielona na zestaw niezależnych podprzestrzeni, uczonych oddzielnie: początkowe zapytanie, klucz i wartość są wysyłane przez trzy niezależne zestawy gęstych projekcji, co skutkuje trzema oddzielnymi wektorami. Każdy wektor jest przetwarzany przez warstwę atencji, a trzy wyjścia są łączone z powrotem w jedną sekwencję wyjściową. Każda taka podprzestrzeń nazywana jest “głową”. Pełny obraz został przedstawiony na <span class="citation" data-cites="ig-attention5">(<a href="references.html#ref-ig-attention5" role="doc-biblioref"><strong>ig-attention5?</strong></a>)</span>.</p>
<div id="fig-attention5" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-attention5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-10 o 14.41.55.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-attention5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.9: <em>Multi-head attention</em>
</figcaption></figure>
</div>
<p>Obecność gęstych projekcji, których można uczyć, pozwala warstwie faktycznie się czegoś nauczyć, w przeciwieństwie do bycia czysto bezstanową transformacją, która wymagałaby dodatkowych warstw przed lub po niej, aby była użyteczna. Ponadto posiadanie niezależnych “głów” pomaga warstwie uczyć się różnych grup cech dla każdego tokena, gdzie cechy w jednej grupie są ze sobą skorelowane, ale są w większości niezależne od cech w innej grupie.</p>
<p>Jest to zasadniczo podobne do tego, co robią konwolucje separowalne. W konwolucji separowalnej przestrzeń wyjściowa konwolucji jest podzielona na wiele podprzestrzeni (po jednej na kanał wejściowy), które są uczone niezależnie. Artykuł “Attention Is All You Need” został napisany w czasie, gdy wykazano, że idea faktoryzacji przestrzeni cech na niezależne podprzestrzenie zapewnia ogromne korzyści dla komputerowych modeli wizyjnych, zarówno w przypadku konwolucji separowalnych, jak i w przypadku blisko spokrewnionego podejścia, konwolucji grupowych. <em>Multi-head attention</em> jest po prostu zastosowaniem tego samego pomysłu do samo-atencji.</p>
</section><section id="enkoder-transformera" class="level3" data-number="7.7.4"><h3 data-number="7.7.4" class="anchored" data-anchor-id="enkoder-transformera">
<span class="header-section-number">7.7.4</span> Enkoder transformera</h3>
<p>Jeśli dodanie dodatkowych gęstych projekcji jest tak przydatne, dlaczego nie zastosujemy jednej lub dwóch do wyjścia mechanizmu uwagi? Nasz model zaczyna realizować wiele funkcji, więc możemy chcieć dodać połączenia resztkowe, aby upewnić się, że po drodze nie utracimy żadnych cennych informacji. Dodatkowo aby przyspieszyć proces uczenia można dodać warstwy normalizacji.</p>
<p>Taki proces myślowy, który, rozwijał się w umysłach twórców architektury Transformer. Dzielenie danych wyjściowych na wiele niezależnych przestrzeni, dodawanie połączeń resztkowych, dodawanie warstw normalizacji - wszystko to są standardowe wzorce architektury, które warto wykorzystać w każdym złożonym modelu.</p>
<div id="fig-tr1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-tr1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-11 o 10.51.31.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tr1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.10: Transformer-Encoder łączy <code><a href="https://rdrr.io/pkg/keras/man/layer_multi_head_attention.html">layer_multi_head_attention()</a></code> z gęstą projekcją i dodaje normalizację oraz połączenia resztkowe.
</figcaption></figure>
</div>
<p>Oryginalna architektura Transformer składa się z dwóch części: kodera transformera, który przetwarza sekwencję źródłową, oraz dekodera transformera, który wykorzystuje sekwencję źródłową do wygenerowania przetłumaczonej wersji. Co najważniejsze, część kodera może być używana do klasyfikacji tekstu. Jest to bardzo ogólny moduł, który przyjmuje sekwencję i uczy się przekształcać ją w bardziej użyteczną reprezentację. Zaimplementujmy koder Transformer (taki jak na <a href="#fig-tr1" class="quarto-xref">Rysunek&nbsp;<span>7.10</span></a>) i wypróbujemy go w zadaniu klasyfikacji sentymentu recenzji filmowej.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb121"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">layer_transformer_encoder</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/new-classes.html">new_layer_class</a></span><span class="op">(</span></span>
<span>  classname <span class="op">=</span> <span class="st">"TransformerEncoder"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">embed_dim</span>, <span class="va">dense_dim</span>, <span class="va">num_heads</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">embed_dim</span> <span class="op">&lt;-</span> <span class="va">embed_dim</span> <span class="co"># rozmiar tokenów wejściowych</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">dense_dim</span> <span class="op">&lt;-</span> <span class="va">dense_dim</span> <span class="co"># liczba neuronów w sieci gęstej</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">num_heads</span> <span class="op">&lt;-</span> <span class="va">num_heads</span> <span class="co"># liczba głów w warstwie atencji</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">attention</span> <span class="op">&lt;-</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_multi_head_attention.html">layer_multi_head_attention</a></span><span class="op">(</span>num_heads <span class="op">=</span> <span class="va">num_heads</span>,</span>
<span>                                 key_dim <span class="op">=</span> <span class="va">embed_dim</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">dense_proj</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">dense_dim</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">embed_dim</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">layernorm_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_layer_normalization.html">layer_layer_normalization</a></span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">layernorm_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_layer_normalization.html">layer_layer_normalization</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">mask</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span> <span class="co"># określenie wywołania</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html">is.null</a></span><span class="op">(</span><span class="va">mask</span><span class="op">)</span><span class="op">)</span> <span class="co"># dostosowanie rozmiaru maski z 2D do 3D lub 4D</span></span>
<span>      <span class="va">mask</span> <span class="op">&lt;-</span> <span class="va">mask</span><span class="op">[</span>, <span class="va">tf</span><span class="op">$</span><span class="va">newaxis</span>, <span class="op">]</span></span>
<span></span>
<span>    <span class="va">inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="op">{</span> <span class="va">self</span><span class="op">$</span><span class="fu">attention</span><span class="op">(</span><span class="va">.</span>, <span class="va">.</span>, attention_mask <span class="op">=</span> <span class="va">mask</span><span class="op">)</span> <span class="op">+</span> <span class="va">.</span> <span class="op">}</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># połączenie rezydualne</span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">layernorm_1</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="op">{</span> <span class="va">self</span><span class="op">$</span><span class="fu">dense_proj</span><span class="op">(</span><span class="va">.</span><span class="op">)</span> <span class="op">+</span> <span class="va">.</span> <span class="op">}</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># połączenie projekcji gęstej z rezydualną</span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">layernorm_2</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  get_config <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span> <span class="co"># implementacja serializacji potrzebna do zapisu modelu</span></span>
<span>    <span class="va">config</span> <span class="op">&lt;-</span> <span class="va">super</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="kw">for</span><span class="op">(</span><span class="va">name</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"embed_dim"</span>, <span class="st">"num_heads"</span>, <span class="st">"dense_dim"</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">config</span><span class="op">[[</span><span class="va">name</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">[[</span><span class="va">name</span><span class="op">]</span><span class="op">]</span></span>
<span>    <span class="va">config</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Wskazówka
</div>
</div>
<div class="callout-body-container callout-body">
<p>Podczas pisania niestandardowych warstw należy zaimplementować metodę <code><a href="https://rdrr.io/pkg/keras/man/get_config.html">get_config()</a></code>. Umożliwia to ponowne utworzenie warstwy z jej konfiguracji, co jest przydatne podczas zapisywania i ładowania modelu. Metoda powinna zwracać nazwaną listę R, która zawiera wartości argumentów konstruktora użytych do utworzenia warstwy.</p>
<p>Wszystkie warstwy Keras mogą być serializowane i deserializowane w następujący sposób:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode cell-code" id="cb122"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>config <span class="ot">&lt;-</span> layer<span class="sc">$</span><span class="fu">get_config</span>()</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>new_layer <span class="ot">&lt;-</span> <span class="fu">do.call</span>(layer_<span class="sc">&lt;</span>type<span class="sc">&gt;</span>, config)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>gdzie <code>layer_&lt;type&gt;</code> jest oryginalnym konstruktorem warstwy. Na przykład:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb123"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">config</span> <span class="op">&lt;-</span> <span class="va">layer</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">new_layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">layer_dense</span>, <span class="va">config</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Można również uzyskać dostęp do rozpakowanego oryginalnego konstruktora warstwy z dowolnej istniejącej warstwy bezpośrednio za pomocą specjalnego symbolu <code>__class__</code> (choć rzadko trzeba to robić):</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb124"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">layer</span><span class="op">$</span><span class="va">`__class__`</span></span>
<span><span class="va">new_layer</span> <span class="op">&lt;-</span> <span class="va">layer</span><span class="op">$</span><span class="va">`__class__`</span><span class="op">$</span><span class="fu">from_config</span><span class="op">(</span><span class="va">config</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Zdefiniowanie metody <code><a href="https://rdrr.io/pkg/keras/man/get_config.html">get_config()</a></code> w niestandardowych klasach warstw umożliwia określenie przepływu pracy. Na przykład:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb125"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu">layer_transformer_encoder</span><span class="op">(</span>embed_dim <span class="op">=</span> <span class="fl">256</span>, dense_dim <span class="op">=</span> <span class="fl">32</span>,</span>
<span>                                   num_heads <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">config</span> <span class="op">&lt;-</span> <span class="va">layer</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">new_layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">layer_transformer_encoder</span>, <span class="va">config</span><span class="op">)</span></span>
<span><span class="co"># -- lub --</span></span>
<span><span class="va">new_layer</span> <span class="op">&lt;-</span> <span class="va">layer</span><span class="op">$</span><span class="va">`__class__`</span><span class="op">$</span><span class="fu">from_config</span><span class="op">(</span><span class="va">config</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Podczas zapisywania modelu zawierającego niestandardowe warstwy, zapisany plik będzie zawierał te konfiguracje. Podczas ładowania modelu z pliku należy dostarczyć niestandardowe klasy warstw do procesu ładowania, aby mógł on zrozumieć obiekty konfiguracyjne:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb126"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">save_model_tf</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">filename</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="va">filename</span>,</span>
<span>                       custom_objects <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">layer_transformer_encoder</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Zwróćmy uwagę, że jeśli lista dostarczona do <code>custom_objects</code> jest nazwana, to nazwy są dopasowywane do argumentu <code>classname</code>, który został podany podczas konstruowania niestandardowego obiektu:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb127"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span></span>
<span>  <span class="va">filename</span>,</span>
<span>  custom_objects <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>TransformerEncoder <span class="op">=</span> <span class="va">layer_transformer_encoder</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
<p>Zauważyliśmy już pewnie, że warstwy normalizacji, których tu używamy, nie są <code><a href="https://rdrr.io/pkg/keras/man/layer_batch_normalization.html">layer_batch_normalization()</a></code>, jak te, których używaliśmy wcześniej w modelach do obrazów. To dlatego, że <code><a href="https://rdrr.io/pkg/keras/man/layer_batch_normalization.html">layer_batch_normalization()</a></code> nie działa dobrze w przypadku danych sekwencyjnych. Zamiast tego używamy <code><a href="https://rdrr.io/pkg/keras/man/layer_layer_normalization.html">layer_layer_normalization()</a></code>, która normalizuje każdą sekwencję niezależnie od innych sekwencji w partii. Tak to wygląda w pseudokodzie R:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb128"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">layer_normalization</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">batch_of_sequences</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">batch_size</span>, <span class="va">sequence_length</span>, <span class="va">embedding_dim</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html">%&lt;-%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">batch_of_sequences</span><span class="op">)</span></span>
<span>  <span class="va">means</span> <span class="op">&lt;-</span> <span class="va">variances</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="fl">0</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">batch_of_sequences</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">b</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">batch_size</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="kw">for</span> <span class="op">(</span><span class="va">s</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">sequence_length</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span> <span class="co"># obliczanie statystyk po ostatniej osi osadzeń</span></span>
<span>      <span class="va">embedding</span> <span class="op">&lt;-</span> <span class="va">batch_of_sequences</span><span class="op">[</span><span class="va">b</span>, <span class="va">s</span>, <span class="op">]</span></span>
<span>      <span class="va">means</span><span class="op">[</span><span class="va">b</span>, <span class="va">s</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">embedding</span><span class="op">)</span></span>
<span>      <span class="va">variances</span><span class="op">[</span><span class="va">b</span>, <span class="va">s</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">embedding</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">(</span><span class="va">batch_of_sequences</span> <span class="op">-</span> <span class="va">means</span><span class="op">)</span> <span class="op">/</span> <span class="va">variances</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Można to porównać z klasyczną <code><a href="https://rdrr.io/pkg/keras/man/layer_batch_normalization.html">layer_batch_normalization()</a></code>:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb129"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">batch_normalization</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">batch_of_images</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">batch_size</span>, <span class="va">height</span>, <span class="va">width</span>, <span class="va">channels</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html">%&lt;-%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">batch_of_images</span><span class="op">)</span></span>
<span>  <span class="va">means</span> <span class="op">&lt;-</span> <span class="va">variances</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="fl">0</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">batch_of_images</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">ch</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">channels</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span> <span class="co"># statystyki liczone są po partiach</span></span>
<span>    <span class="va">channel</span> <span class="op">&lt;-</span> <span class="va">batch_of_images</span><span class="op">[</span>, , , <span class="va">ch</span><span class="op">]</span> <span class="co"># dla każdego kanału liczone oddzielnie</span></span>
<span>    <span class="va">means</span><span class="op">[</span>, , , <span class="va">ch</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">channel</span><span class="op">)</span></span>
<span>    <span class="va">variances</span><span class="op">[</span>, , , <span class="va">ch</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">channel</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="op">(</span><span class="va">batch_of_images</span> <span class="op">-</span> <span class="va">means</span><span class="op">)</span> <span class="op">/</span> <span class="va">variances</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Funkcja <code>batch_normalization()</code> zbiera informacje z wielu próbek w celu uzyskania statystyk średnich i wariancji cech, a funkcja <code><a href="https://rdrr.io/pkg/keras/man/layer_normalization.html">layer_normalization()</a></code> gromadzi dane w każdej sekwencji osobno, co jest bardziej właściwe dla danych sekwencyjnych.</p>
<p>Teraz wykorzystamy zbudowany transformer do naszego zadania:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb130"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">vocab_size</span> <span class="op">&lt;-</span> <span class="fl">20000</span></span>
<span><span class="va">embed_dim</span> <span class="op">&lt;-</span> <span class="fl">256</span></span>
<span><span class="va">num_heads</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">dense_dim</span> <span class="op">&lt;-</span> <span class="fl">32</span></span>
<span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span><span class="va">vocab_size</span>, <span class="va">embed_dim</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">layer_transformer_encoder</span><span class="op">(</span><span class="va">embed_dim</span>, <span class="va">dense_dim</span>, <span class="va">num_heads</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_global_average_pooling_1d.html">layer_global_average_pooling_1d</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>                  loss <span class="op">=</span> <span class="st">"binary_crossentropy"</span>,</span>
<span>                  metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span><span class="va">model</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Model: "model_5"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 input_7 (InputLayer)               [(None, None)]                  0           
 embedding_5 (Embedding)            (None, None, 256)               5120000     
 transformer_encoder (TransformerE  (None, None, 256)               543776      
 ncoder)                                                                        
 global_average_pooling1d (GlobalA  (None, 256)                     0           
 veragePooling1D)                                                               
 dropout_4 (Dropout)                (None, 256)                     0           
 dense_4 (Dense)                    (None, 1)                       257         
================================================================================
Total params: 5664033 (21.61 MB)
Trainable params: 5664033 (21.61 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb132"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">callbacks</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span><span class="st">"models/transformer_encoder.keras"</span>,</span>
<span>                                           save_best_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb133"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  <span class="va">int_train_ds</span>,</span>
<span>  validation_data <span class="op">=</span> <span class="va">int_val_ds</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  callbacks <span class="op">=</span> <span class="va">callbacks</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb134"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/transformer_encoder.keras"</span>,</span>
<span>                       custom_objects <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">layer_transformer_encoder</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Test acc: %.3f"</span>, <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">int_test_ds</span><span class="op">)</span><span class="op">[</span><span class="st">"accuracy"</span><span class="op">]</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>782/782 - 149s - loss: 0.2902 - accuracy: 0.8876 - 149s/epoch - 190ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Test acc: 0.888"</code></pre>
</div>
</div>
<p>Osiągamy dopasowanie na poziomie 88,8% dla zbioru testowego. W tym momencie powinniśmy zacząć odczuwać lekki niepokój. Coś tu nie gra. Co jest nie tak?</p>
<p>Ten rozdział rzekomo dotyczy “modeli sekwencji”. Zaczęliśmy od podkreślenia znaczenia kolejności słów. Powiedzieliśmy, że transformer to architektura przetwarzania sekwencji, pierwotnie opracowana na potrzeby tłumaczenia maszynowego. A jednak… koder transformera, który właśnie zobaczyliśmy w akcji, wcale nie był modelem sekwencyjnym. Składa się on z gęstych warstw, które przetwarzają tokeny sekwencji niezależnie od siebie, oraz warstwy uwagi, która traktuje tokeny jako zestaw. Możesz zmienić kolejność tokenów w sekwencji, a otrzymamy dokładnie takie same wyniki wzajemnej uwagi i dokładnie takie same reprezentacje kontekstu. Gdybyśmy całkowicie wymieszali słowa w każdej recenzji filmu, model by tego nie zauważył i nadal uzyskałbyś dokładnie taką samą dokładność. Samoatencja jest mechanizmem przetwarzania zbiorów, skoncentrowanym na relacjach między parami elementów sekwencji (patrz <a href="#tbl-features" class="quarto-xref">Tabela&nbsp;<span>7.1</span></a>) - jest ślepa na to, czy elementy te występują na początku, na końcu czy w środku sekwencji. Dlaczego więc mówimy, że Transformer jest modelem sekwencji? I w jaki sposób może on być dobry dla tłumaczenia maszynowego, jeśli nie bierze pod uwagę kolejności słów?</p>
<p>Wskazaliśmy rozwiązanie wcześniej w tym rozdziale. Mimochodem wspominaliśmy, że transformer jest podejściem hybrydowym, które jest technicznie niezależne od kolejności, ale ręcznie wprowadza informacje o kolejności do przetwarzanych reprezentacji. To jest brakujący składnik! Nazywa się to kodowaniem pozycyjnym. Przyjrzyjmy się temu.</p>
<div id="tbl-features" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-features-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tab.&nbsp;7.1: Cechy modeli wykorzystywanych do NLP
</figcaption><div aria-describedby="tbl-features-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead><tr class="header">
<th></th>
<th>Świadomość kolejności słów</th>
<th>Świadomość kontekstu</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Bag-of-unigrams</td>
<td>Nie</td>
<td>Nie</td>
</tr>
<tr class="even">
<td>Bag-of-bigrams</td>
<td>Bardzo ograniczona</td>
<td>Nie</td>
</tr>
<tr class="odd">
<td>RNN</td>
<td>Tak</td>
<td>Nie</td>
</tr>
<tr class="even">
<td>Self-attention</td>
<td>Nie</td>
<td>Tak</td>
</tr>
<tr class="odd">
<td>Transformer</td>
<td>Tak</td>
<td>Tak</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section><section id="kodowanie-pozycyjne" class="level3" data-number="7.7.5"><h3 data-number="7.7.5" class="anchored" data-anchor-id="kodowanie-pozycyjne">
<span class="header-section-number">7.7.5</span> Kodowanie pozycyjne</h3>
<p>Idea kodowania pozycyjnego jest bardzo prosta. Aby zapewnić modelowi dostęp do informacji o kolejności słów, zamierzamy dodać pozycję słowa w zdaniu do każdego osadzenia słowa. Nasze wejściowe osadzenia słów będą miały dwa komponenty: zwykły wektor słów, który reprezentuje słowo niezależnie od konkretnego kontekstu, oraz wektor pozycji, który reprezentuje pozycję słowa w bieżącym zdaniu.</p>
<p>Najprostszym schematem, jaki można wymyślić, byłoby połączenie pozycji słowa z jego wektorem osadzania. Dodalibyśmy oś “pozycja” do wektora i wypełnili ją wartością 0 dla pierwszego słowa w sekwencji, 1 dla drugiego i tak dalej. Może to jednak nie być idealne rozwiązanie, ponieważ pozycje mogą być potencjalnie bardzo dużymi liczbami całkowitymi, co zakłóci zakres wartości w wektorze osadzania. Jak wiadomo, sieci neuronowe nie lubią bardzo dużych wartości wejściowych ani dyskretnych rozkładów danych wejściowych.</p>
<p>W oryginalnym artykule “Attention Is All You Need” zastosowano interesującą sztuczkę do kodowania pozycji słów: dodano do osadzania słów wektor zawierający wartości z zakresu [-1, 1], które zmieniały się cyklicznie w zależności od pozycji (wykorzystano do tego funkcje cosinusowe). Ta sztuczka pozwala jednoznacznie scharakteryzować dowolną liczbę całkowitą w dużym zakresie za pomocą wektora małych wartości. To sprytne, ale nie tego zamierzamy użyć w naszym przypadku. Zrobimy coś prostszego i bardziej efektywnego: nauczymy się wektorów osadzania pozycji w ten sam sposób, w jaki uczymy się osadzać indeksy słów. Następnie dodamy nasze osadzenia pozycji do odpowiednich osadzeń słów, aby uzyskać osadzenie słów uwzględniające pozycję. Technika ta nazywana jest “osadzaniem pozycyjnym”.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb137"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">layer_positional_embedding</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/new-classes.html">new_layer_class</a></span><span class="op">(</span></span>
<span>  classname <span class="op">=</span> <span class="st">"PositionalEmbedding"</span>,</span>
<span></span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">sequence_length</span>, <span class="va">input_dim</span>, <span class="va">output_dim</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">token_embeddings</span> <span class="op">&lt;-</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span>input_dim <span class="op">=</span> <span class="va">input_dim</span>,</span>
<span>                      output_dim <span class="op">=</span> <span class="va">output_dim</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">position_embeddings</span> <span class="op">&lt;-</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span>input_dim <span class="op">=</span> <span class="va">sequence_length</span>,</span>
<span>                      output_dim <span class="op">=</span> <span class="va">output_dim</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">sequence_length</span> <span class="op">&lt;-</span> <span class="va">sequence_length</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">input_dim</span> <span class="op">&lt;-</span> <span class="va">input_dim</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">output_dim</span> <span class="op">&lt;-</span> <span class="va">output_dim</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">length</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">shape</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span>    <span class="va">positions</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">range</span><span class="op">(</span>start <span class="op">=</span> <span class="fl">0L</span>, limit <span class="op">=</span> <span class="va">length</span>, delta <span class="op">=</span> <span class="fl">1L</span><span class="op">)</span></span>
<span>    <span class="va">embedded_tokens</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">token_embeddings</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span>    <span class="va">embedded_positions</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">position_embeddings</span><span class="op">(</span><span class="va">positions</span><span class="op">)</span></span>
<span>    <span class="va">embedded_tokens</span> <span class="op">+</span> <span class="va">embedded_positions</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  compute_mask <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">mask</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">inputs</span> <span class="op">!=</span> <span class="fl">0</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  get_config <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">config</span> <span class="op">&lt;-</span> <span class="va">super</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="kw">for</span><span class="op">(</span><span class="va">name</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"output_dim"</span>, <span class="st">"sequence_length"</span>, <span class="st">"input_dim"</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">config</span><span class="op">[[</span><span class="va">name</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">[[</span><span class="va">name</span><span class="op">]</span><span class="op">]</span></span>
<span>    <span class="va">config</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span> </span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Można teraz użyć funkcji <code>layer_positional_embedding()</code> tak jak zwykłej <code><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding()</a></code>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb138"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">vocab_size</span> <span class="op">&lt;-</span> <span class="fl">20000</span></span>
<span><span class="va">sequence_length</span> <span class="op">&lt;-</span> <span class="fl">600</span></span>
<span><span class="va">embed_dim</span> <span class="op">&lt;-</span> <span class="fl">256</span></span>
<span><span class="va">num_heads</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">dense_dim</span> <span class="op">&lt;-</span> <span class="fl">32</span></span>
<span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">layer_positional_embedding</span><span class="op">(</span><span class="va">sequence_length</span>, <span class="va">vocab_size</span>, <span class="va">embed_dim</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">layer_transformer_encoder</span><span class="op">(</span><span class="va">embed_dim</span>, <span class="va">dense_dim</span>, <span class="va">num_heads</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_global_average_pooling_1d.html">layer_global_average_pooling_1d</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>          loss <span class="op">=</span> <span class="st">"binary_crossentropy"</span>,</span>
<span>          metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Model: "model_6"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 input_8 (InputLayer)               [(None, None)]                  0           
 positional_embedding (PositionalE  (None, None, 256)               5273600     
 mbedding)                                                                      
 transformer_encoder_1 (Transforme  (None, None, 256)               543776      
 rEncoder)                                                                      
 global_average_pooling1d_1 (Globa  (None, 256)                     0           
 lAveragePooling1D)                                                             
 dropout_5 (Dropout)                (None, 256)                     0           
 dense_9 (Dense)                    (None, 1)                       257         
================================================================================
Total params: 5817633 (22.19 MB)
Trainable params: 5817633 (22.19 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb140"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">callbacks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span><span class="st">"models/full_transformer_encoder.keras"</span>,</span>
<span>                            save_best_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb141"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>  <span class="va">int_train_ds</span>,</span>
<span>  validation_data <span class="op">=</span> <span class="va">int_val_ds</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  callbacks <span class="op">=</span> <span class="va">callbacks</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb142"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span></span>
<span>  <span class="st">"models/full_transformer_encoder.keras"</span>,</span>
<span>  custom_objects <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">layer_transformer_encoder</span>,</span>
<span>                        <span class="va">layer_positional_embedding</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span></span>
<span>  <span class="st">"Test acc: %.3f\n"</span>, <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">int_test_ds</span><span class="op">)</span><span class="op">[</span><span class="st">"accuracy"</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>782/782 - 160s - loss: 0.2802 - accuracy: 0.8857 - 160s/epoch - 205ms/step
Test acc: 0.886</code></pre>
</div>
</div>
<p>Osiągnęliśmy dokładność testową na poziomie 88,6% - to nieco gorzej niż w przypadku transformera bez osadzeń pozycyjnych. Jest on jednak wciąż nieco gorszy od podejścia opartego na <em>bag-of-words</em>.</p>
</section></section><section id="wskazówki-praktyczne-dotyczące-wyboru-modelu" class="level2" data-number="7.8"><h2 data-number="7.8" class="anchored" data-anchor-id="wskazówki-praktyczne-dotyczące-wyboru-modelu">
<span class="header-section-number">7.8</span> Wskazówki praktyczne dotyczące wyboru modelu</h2>
<p>Czasami można usłyszeć, że metody <em>bag-of-words</em> są przestarzałe i że modele sekwencji oparte na transformatach są najlepszym rozwiązaniem, niezależnie od zadania lub zbioru danych. Zdecydowanie tak nie jest. Mały stos gęstych warstw na szczycie <em>bag-of-bigrams</em> pozostaje całkowicie poprawnym i odpowiednim podejściem w wielu przypadkach. W rzeczywistości, spośród różnych technik, które wypróbowaliśmy na zbiorze danych IMDB w tym rozdziale, jak dotąd najlepiej sprawdzał się <em>bag-of-bigrams</em>! Kiedy więc należy preferować jedno podejście nad drugim?</p>
<p>W 2017 roku zespół pod kierownictwem Cholleta przeprowadził systematyczną analizę wydajności różnych technik klasyfikacji tekstu w wielu różnych typach zbiorów danych tekstowych i odkrył niezwykłą i zaskakującą zasadę podejmowania decyzji, czy wybrać model <em>bag-of-words</em>, czy model sekwencji (<a href="http://mng.bz/AOzK" class="uri">http://mng.bz/AOzK</a>) - swego rodzaju złotą proporcję. Okazuje się, że zabierając się do nowego zadania klasyfikacji tekstu, należy zwrócić szczególną uwagę na stosunek liczby próbek w danych treningowych do średniej liczby słów na próbkę (patrz <a href="#fig-rule" class="quarto-xref">Rysunek&nbsp;<span>7.11</span></a>). Jeśli stosunek ten jest niewielki - mniejszy niż 1500 - wówczas model <em>bag-of-bigrams</em> będzie działał lepiej (i jako bonus, będzie znacznie szybszy do trenowania). Jeśli współczynnik ten jest wyższy niż 1500, należy wybrać model sekwencyjny. Innymi słowy, modele sekwencyjne działają najlepiej, gdy dostępnych jest wiele danych szkoleniowych i gdy każda próbka jest stosunkowo krótka.</p>
<div id="fig-rule" class="quarto-figure quarto-figure-center quarto-float anchored" width="600" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-rule-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-11 o 14.24.42.png" id="fig-rule" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-rule-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.11
</figcaption></figure>
</div>
<p>Tak więc, jeśli klasyfikujemy dokumenty o długości 1000 słów i mamy ich 100 000 (stosunek 100), powinniśmy wybrać model bigramowy. Jeśli klasyfikujemy tweety o średniej długości 40 słów i mamy ich 50 000 (stosunek 1250), powinniśmy również wybrać model bigramowy. Ale jeśli zwiększymy rozmiar zbioru danych do 500 000 tweetów (stosunek 12 500), wybierzmy wówczas transformery. A co z zadaniem klasyfikacji recenzji filmów IMDB? Mieliśmy 20 000 próbek treningowych i średnią liczbę słów wynoszącą 233, więc nasza zasada kciuka wskazuje na model bigramowy, co potwierdza to, co znaleźliśmy w praktyce.</p>
<p>Intuicyjnie ma to sens: dane wejściowe modelu sekwencji reprezentują bogatszą i bardziej złożoną przestrzeń, a zatem potrzeba więcej danych, aby ją odwzorować; tymczasem zwykły zestaw terminów jest przestrzenią tak prostą, że można na niej trenować regresję logistyczną przy użyciu zaledwie kilkuset lub tysięcy próbek. Ponadto, im krótsza jest próbka, tym mniej model może sobie pozwolić na odrzucenie jakichkolwiek zawartych w niej informacji - w szczególności kolejność słów staje się ważniejsza, a odrzucenie jej może powodować niejednoznaczność. Zdania “ten film jest bombą” i “ten film był bombą” mają bardzo zbliżone reprezentacje unigramów, co może zmylić model <em>bag-of-words</em>, ale model sekwencji może stwierdzić, który z nich jest negatywny, a który pozytywny. Przy dłuższej próbce statystyki słów stałyby się bardziej wiarygodne, a temat lub sentyment byłyby bardziej widoczne na podstawie samego histogramu słów.</p>
<p>Należy pamiętać, że ta heurystyczna reguła została opracowana specjalnie dla klasyfikacji tekstu. Niekoniecznie musi się ona sprawdzać w innych zadaniach NLP - na przykład, jeśli chodzi o tłumaczenie maszynowe, Transformer wyróżnia się szczególnie w przypadku bardzo długich sekwencji, w porównaniu do sieci RNN. Nasza heurystyka jest również tylko praktyczną zasadą, a nie naukowym prawem, więc spodziewaj się, że będzie działać przez większość czasu, ale niekoniecznie za każdym razem.</p>
</section><section id="tłumaczenia-typu-sequence-to-sequence" class="level2 page-columns page-full" data-number="7.9"><h2 data-number="7.9" class="anchored" data-anchor-id="tłumaczenia-typu-sequence-to-sequence">
<span class="header-section-number">7.9</span> Tłumaczenia typu sequence-to-sequence</h2>
<p>Posiadamy już wszystkie narzędzia, których będziemy potrzebować, aby poradzić sobie z większością zadań przetwarzania języka naturalnego. Jednakże, widzieliśmy te narzędzia w akcji tylko w jednym problemie: klasyfikacji tekstu. Jest to niezwykle popularny przypadek użycia, ale NLP to znacznie więcej niż klasyfikacja. W tym podrozdziale poszerzymy swoją wiedzę, poznając modele <em>sequence-to-sequence</em>.</p>
<p>Model sekwencja-sekwencja przyjmuje jedną sekwencję jako dane wejściowe (często zdanie lub akapit) i tłumaczy ją na drugą sekwencję. Jest to zadanie leżące u podstaw wielu najbardziej udanych zastosowań NLP:</p>
<ul>
<li>Tłumaczenie maszynowe - konwersja akapitu w języku źródłowym na jego odpowiednik w języku docelowym.</li>
<li>Podsumowanie tekstu - konwersja długiego dokumentu na krótszą wersję, która zachowuje najważniejsze informacje.</li>
<li>Odpowiadanie na pytania - konwersja pytania wejściowego na odpowiedź.</li>
<li>Chatboty - konwertowanie monitu dialogowego na odpowiedź na ten monit lub konwertowanie historii konwersacji na następną odpowiedź w konwersacji.</li>
<li>Generowanie tekstu - konwertowanie monitu tekstowego na akapit, który uzupełnia monit.</li>
<li>I tak dalej.</li>
</ul>
<div id="fig-seq-to-seq" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seq-to-seq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-11 o 14.36.45.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seq-to-seq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.12: Uczenie sekwencyjne. Sekwencja źródłowa jest przetwarzana przez koder, a następnie przesyłana do dekodera. Dekoder analizuje dotychczasową sekwencję docelową i przewiduje przesunięcie sekwencji docelowej o jeden krok w przyszłość. Podczas wnioskowania generujemy jeden token docelowy na raz i przekazujemy go z powrotem do dekodera.
</figcaption></figure>
</div>
<p>Ogólny szablon modeli sekwencja-sekwencja został opisany na <a href="#fig-seq-to-seq" class="quarto-xref">Rysunek&nbsp;<span>7.12</span></a>. Podczas szkolenia:</p>
<ul>
<li>Model kodera zamienia sekwencję źródłową w reprezentację pośrednią.</li>
<li>Dekoder jest szkolony, aby przewidzieć następny token <span class="math inline">\(i\)</span> w sekwencji docelowej, patrząc zarówno na poprzednie tokeny (od 1 do <span class="math inline">\(i - 1\)</span>), jak i zakodowaną sekwencję źródłową.</li>
</ul>
<p>Podczas wnioskowania nie mamy dostępu do sekwencji docelowej - próbujemy przewidzieć ją od zera. Będziemy musieli generować ją po jednym tokenie na raz:</p>
<ol type="1">
<li>Otrzymujemy zakodowaną sekwencję źródłową z kodera.</li>
<li>Dekoder zaczyna od patrzenia na zakodowaną sekwencję źródłową, a także początkowy token “seed” (taki jak ciąg “[start]”) i używa go do przewidzenia pierwszego prawdziwego tokena w sekwencji.</li>
<li>Przewidywana sekwencja jest przekazywana z powrotem do dekodera, który generuje następny token i tak dalej, aż do wygenerowania tokenu zatrzymania (takiego jak ciąg “[end]”).</li>
</ol>
<p>Zasadę działania takiego modelu przedstawimy na przykładzie.</p>
<section id="przykład-tłumaczenia-maszynowego" class="level3" data-number="7.9.1"><h3 data-number="7.9.1" class="anchored" data-anchor-id="przykład-tłumaczenia-maszynowego">
<span class="header-section-number">7.9.1</span> Przykład tłumaczenia maszynowego</h3>
<p>Zademonstrujemy modelowanie sekwencja do sekwencji, w zadaniu tłumaczenia maszynowego. Tłumaczenie maszynowe jest dokładnie tym, do czego transformer został opracowany! Zaczniemy od rekurencyjnego modelu sekwencji, a następnie wykorzystamy pełną architekturę transformera. Będziemy pracować z zestawem danych tłumaczeń z angielskiego na hiszpański dostępnym na stronie <a href="http://www.manythings.org/anki/." class="uri">http://www.manythings.org/anki/.</a> Pobierzmy go:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb144"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span><span class="op">(</span><span class="st">"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip"</span>,</span>
<span>              destfile <span class="op">=</span> <span class="st">"data/spa-eng.zip"</span><span class="op">)</span></span>
<span><span class="fu">zip</span><span class="fu">::</span><span class="fu"><a href="https://r-lib.github.io/zip/reference/unzip.html">unzip</a></span><span class="op">(</span><span class="st">"data/spa-eng.zip"</span>, exdir <span class="op">=</span> <span class="st">"data/"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Plik tekstowy zawiera jeden przykład w wierszu: zdanie w języku angielskim, po którym następuje znak tabulacji, a następnie odpowiadające mu zdanie w języku hiszpańskim. Użyjmy <code><a href="https://readr.tidyverse.org/reference/read_delim.html">readr::read_tsv()</a></code>, ponieważ mamy wartości oddzielone tabulatorami:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb145"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">text_file</span> <span class="op">&lt;-</span> <span class="st">"data/spa-eng/spa.txt"</span></span>
<span><span class="va">text_pairs</span> <span class="op">&lt;-</span> <span class="va">text_file</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">readr</span><span class="fu">::</span><span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_tsv</a></span><span class="op">(</span>col_names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"english"</span>, <span class="st">"spanish"</span><span class="op">)</span>,</span>
<span>                  col_types <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"cc"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/with.html">within</a></span><span class="op">(</span><span class="va">spanish</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/compound.html">%&lt;&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"[start]"</span>, <span class="va">.</span>, <span class="st">"[end]"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Nasz przykładowy tekst wygląda teraz tak:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb146"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">text_pairs</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">text_pairs</span><span class="op">)</span>, <span class="fl">1</span><span class="op">)</span>, <span class="op">]</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>tibble [1 × 2] (S3: tbl_df/tbl/data.frame)
 $ english: chr "Where's the nearest church?"
 $ spanish: chr "[start] ¿Dónde está la iglesia más cercana? [end]"</code></pre>
</div>
</div>
<p>Przetasujmy je i podzielmy na zwykłe zestawy treningowe, walidacyjne i testowe:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb148"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">num_test_samples</span> <span class="op">&lt;-</span> <span class="va">num_val_samples</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fl">0.15</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">text_pairs</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">num_train_samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">text_pairs</span><span class="op">)</span> <span class="op">-</span> <span class="va">num_val_samples</span> <span class="op">-</span> <span class="va">num_test_samples</span></span>
<span></span>
<span><span class="va">pair_group</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"train"</span>, <span class="va">num_train_samples</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"test"</span>, <span class="va">num_test_samples</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"val"</span>, <span class="va">num_val_samples</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train_pairs</span> <span class="op">&lt;-</span> <span class="va">text_pairs</span><span class="op">[</span><span class="va">pair_group</span> <span class="op">==</span> <span class="st">"train"</span>, <span class="op">]</span></span>
<span><span class="va">test_pairs</span> <span class="op">&lt;-</span> <span class="va">text_pairs</span><span class="op">[</span><span class="va">pair_group</span> <span class="op">==</span> <span class="st">"test"</span>, <span class="op">]</span></span>
<span><span class="va">val_pairs</span> <span class="op">&lt;-</span> <span class="va">text_pairs</span><span class="op">[</span><span class="va">pair_group</span> <span class="op">==</span> <span class="st">"val"</span>, <span class="op">]</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Następnie przygotujmy dwie oddzielne warstwy <code>TextVectorization</code>: jedną dla języka angielskiego i jedną dla hiszpańskiego. Będziemy musieli dostosować sposób wstępnego przetwarzania ciągów znaków:</p>
<ul>
<li>Musimy zachować wstawione przez nas tokeny “<code>[start]</code>” i “<code>[end]</code>”. Domyślnie znaki <code>[</code> i <code>]</code> zostaną usunięte, ale chcemy je zachować, abyśmy mogli odróżnić słowo “start” od tokenu startowego “[start]”.</li>
<li>Interpunkcja różni się w zależności od języka! W hiszpańskiej warstwie wektoryzacji tekstu, jeśli zamierzamy usunąć znaki interpunkcyjne, musimy również usunąć znak <code>¿</code>.</li>
</ul>
<p>Zauważmy, że w przypadku modelu tłumaczenia innego niż <em>toy-model</em>, traktowalibyśmy znaki interpunkcyjne jako oddzielne tokeny, zamiast je usuwać, ponieważ chcielibyśmy być w stanie generować poprawnie interpunkcyjne zdania. W naszym przypadku, dla uproszczenia, pozbędziemy się całej interpunkcji.</p>
<p>Przygotowujemy niestandardową funkcję standaryzacji ciągów znaków dla hiszpańskiej warstwy <code>TextVectorization</code> - zachowuje ona <code>[</code> i <code>]</code>, ale usuwa <code>¿</code>, <code>¡</code> i wszystkie inne znaki z klasy <code>[:punct:]</code>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb149"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">punctuation_regex</span> <span class="op">&lt;-</span> <span class="st">"[^[:^punct:][\\]]|[¡¿]"</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow">tensorflow</a></span><span class="op">)</span></span>
<span><span class="va">custom_standardization</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_string</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">input_string</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="va">tf</span><span class="op">$</span><span class="va">strings</span><span class="op">$</span><span class="fu">lower</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="va">tf</span><span class="op">$</span><span class="va">strings</span><span class="op">$</span><span class="fu">regex_replace</span><span class="op">(</span><span class="va">punctuation_regex</span>, <span class="st">""</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">input_string</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span><span class="st">"[start] ¡corre! [end]"</span><span class="op">)</span></span>
<span><span class="fu">custom_standardization</span><span class="op">(</span><span class="va">input_string</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(b'[start] corre [end]', shape=(), dtype=string)</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Adnotacja
</div>
</div>
<div class="callout-body-container callout-body">
<p>Wyrażenia regularne TensorFlow różnią się nieznacznie w stosunku do silnika wyrażeń regularnych R. Więcej szczegółów można znaleźć pod adresem <a href="https://github.com/google/re2/wiki/Syntax." class="uri">https://github.com/google/re2/wiki/Syntax.</a></p>
</div>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb151"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">vocab_size</span> <span class="op">&lt;-</span> <span class="fl">15000</span></span>
<span><span class="va">sequence_length</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span></span>
<span><span class="va">source_vectorization</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span></span>
<span>  max_tokens <span class="op">=</span> <span class="va">vocab_size</span>,</span>
<span>  output_mode <span class="op">=</span> <span class="st">"int"</span>,</span>
<span>  output_sequence_length <span class="op">=</span> <span class="va">sequence_length</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">target_vectorization</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span></span>
<span>  max_tokens <span class="op">=</span> <span class="va">vocab_size</span>,</span>
<span>  output_mode <span class="op">=</span> <span class="st">"int"</span>,</span>
<span>  output_sequence_length <span class="op">=</span> <span class="va">sequence_length</span> <span class="op">+</span> <span class="fl">1</span>,</span>
<span>  standardize <span class="op">=</span> <span class="va">custom_standardization</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/adapt.html">adapt</a></span><span class="op">(</span><span class="va">source_vectorization</span>, <span class="va">train_pairs</span><span class="op">$</span><span class="va">english</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/adapt.html">adapt</a></span><span class="op">(</span><span class="va">target_vectorization</span>, <span class="va">train_pairs</span><span class="op">$</span><span class="va">spanish</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Na koniec możemy przekształcić nasze dane w potok TF Dataset. Chcemy, aby zwracał on parę (<code>inputs, target</code>), gdzie <code>inputs</code> jest nazwaną listą z dwoma wpisami, angielskim zdaniem (wejście kodera) i hiszpańskim zdaniem (wejście dekodera), a <code>target</code> jest hiszpańskim zdaniem przesuniętym o jeden krok do przodu.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb152"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">format_pair</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">pair</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">eng</span> <span class="op">&lt;-</span> <span class="fu">source_vectorization</span><span class="op">(</span><span class="va">pair</span><span class="op">$</span><span class="va">english</span><span class="op">)</span></span>
<span>  <span class="va">spa</span> <span class="op">&lt;-</span> <span class="fu">target_vectorization</span><span class="op">(</span><span class="va">pair</span><span class="op">$</span><span class="va">spanish</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>english <span class="op">=</span> <span class="va">eng</span>,</span>
<span>                 spanish <span class="op">=</span> <span class="va">spa</span><span class="op">[</span><span class="cn">NA</span><span class="op">:</span><span class="op">-</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">targets</span> <span class="op">&lt;-</span> <span class="va">spa</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="cn">NA</span><span class="op">]</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">targets</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span><span class="va">batch_size</span> <span class="op">&lt;-</span> <span class="fl">64</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tfdatasets">tfdatasets</a></span><span class="op">)</span></span>
<span><span class="va">make_dataset</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">pairs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/tensor_slices_dataset.html">tensor_slices_dataset</a></span><span class="op">(</span><span class="va">pairs</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html">dataset_map</a></span><span class="op">(</span><span class="va">format_pair</span>, num_parallel_calls <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html">dataset_cache</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_shuffle.html">dataset_shuffle</a></span><span class="op">(</span><span class="fl">2048</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html">dataset_batch</a></span><span class="op">(</span><span class="va">batch_size</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_prefetch.html">dataset_prefetch</a></span><span class="op">(</span><span class="fl">16</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">train_ds</span> <span class="op">&lt;-</span>  <span class="fu">make_dataset</span><span class="op">(</span><span class="va">train_pairs</span><span class="op">)</span></span>
<span><span class="va">val_ds</span> <span class="op">&lt;-</span> <span class="fu">make_dataset</span><span class="op">(</span><span class="va">val_pairs</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Oto jak wyglądają dane wyjściowe naszego zestawu danych:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb153"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">targets</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html">%&lt;-%</a></span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/iterate.html">iter_next</a></span><span class="op">(</span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/iterate.html">as_iterator</a></span><span class="op">(</span><span class="va">train_ds</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>List of 2
 $ english:&lt;tf.Tensor: shape=(64, 20), dtype=int64, numpy=…&gt;
 $ spanish:&lt;tf.Tensor: shape=(64, 20), dtype=int64, numpy=…&gt;</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb155"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">targets</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Tensor: shape=(64, 20), dtype=int64, numpy=…&gt;</code></pre>
</div>
</div>
<p>Dane są teraz gotowe - czas zbudować kilka modeli. Zaczniemy od rekurencyjnego modelu sekwencja-sekwencja, zanim przejdziemy do transformera.</p>
</section><section id="uczenie-sekwencyjne-z-wykorzystaniem-sieci-rnn" class="level3 page-columns page-full" data-number="7.9.2"><h3 data-number="7.9.2" class="anchored" data-anchor-id="uczenie-sekwencyjne-z-wykorzystaniem-sieci-rnn">
<span class="header-section-number">7.9.2</span> Uczenie sekwencyjne z wykorzystaniem sieci RNN</h3>
<p>Rekurencyjne sieci neuronowe zdominowały uczenie sekwencyjne w latach 2015-2017, zanim zostały wyprzedzone przez transformery. Były one podstawą wielu rzeczywistych systemów tłumaczenia maszynowego. Google Translate około 2017 roku był zasilany przez stos siedmiu dużych warstw LSTM. Dziś również warto zapoznać się z tym podejściem, ponieważ stanowi ono łatwy punkt wejścia do zrozumienia modeli sekwencja-sekwencja.</p>
<p>Najprostszym, naiwnym sposobem wykorzystania RNN do przekształcenia sekwencji w inną sekwencję jest zachowanie danych wyjściowych RNN w każdym kroku czasowym. W języku <code>keras</code> wyglądałoby to następująco:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb157"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">sequence_length</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span>input_dim <span class="op">=</span> <span class="va">vocab_size</span>, output_dim <span class="op">=</span> <span class="fl">128</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_lstm.html">layer_lstm</a></span><span class="op">(</span><span class="fl">32</span>, return_sequences <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">vocab_size</span>, activation <span class="op">=</span> <span class="st">"softmax"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Podejście to ma jednak dwa główne problemy:</p>
<ul>
<li>Sekwencja docelowa musi być zawsze tej samej długości co sekwencja źródłowa. W praktyce rzadko ma to miejsce. Z technicznego punktu widzenia nie jest to istotne, ponieważ zawsze można uzupełnić sekwencję źródłową lub docelową, aby ich długości się zgadzały.</li>
<li>Ze względu na charakter przetwarzania zadania przez sieć RNN krok po kroku, model będzie patrzył tylko na tokeny <span class="math inline">\(1\ldots N\)</span> w sekwencji źródłowej, aby przewidzieć token <span class="math inline">\(N\)</span> w sekwencji docelowej. To ograniczenie sprawia, że ta konfiguracja nie nadaje się do większości zadań, w szczególności do tłumaczenia. Rozważmy tłumaczenie “The weather is nice today” na francuski - byłoby to “Il fait beau aujourd’hui”. Musiałbyś być w stanie przewidzieć “Il” z samego “The”, “Il fait” z samego “The weather” i tak dalej, co jest po prostu niemożliwe.</li>
</ul>
<p>Jeśli jesteśmy tłumaczami, zaczynamy od przeczytania całego zdania źródłowego, zanim zaczniemy je tłumaczyć. Jest to szczególnie ważne, jeśli mamy do czynienia z językami, które mają bardzo różną kolejność słów, jak angielski i japoński. I dokładnie to robią standardowe modele sekwencja-sekwencja.</p>
<p>W prawidłowej konfiguracji sekwencja-sekwencja (patrz <a href="#fig-rnn1" class="quarto-xref">Rysunek&nbsp;<span>7.13</span></a>), najpierw należy użyć RNN (kodera), aby przekształcić całą sekwencję źródłową w pojedynczy wektor (lub zestaw wektorów). Może to być ostatnie wyjście RNN lub alternatywnie jego końcowe wektory stanu wewnętrznego. Następnie należy użyć tego wektora (lub wektorów) jako stanu początkowego innej sieci RNN (dekodera), która przyjrzy się elementom <span class="math inline">\(1\ldots N\)</span> w sekwencji docelowej i spróbuje przewidzieć krok <span class="math inline">\(N+1\)</span> w sekwencji docelowej.</p>
<div id="fig-rnn1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-rnn1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-14 o 20.24.00.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnn1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.13: Model RNN sekwencja-sekwencja. Koder RNN jest używany do tworzenia wektora, który koduje całą sekwencję źródłową, która jest używana jako stan początkowy dla dekodera RNN.
</figcaption></figure>
</div>
<p>Zaimplementujmy to w Keras za pomocą koderów i dekoderów opartych na GRU. Wybór GRU zamiast LSTM nieco upraszcza sprawę, ponieważ GRU ma tylko jeden wektor stanu, podczas gdy LSTM ma ich wiele. Zacznijmy od kodera.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb158"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">embed_dim</span> <span class="op">&lt;-</span> <span class="fl">256</span></span>
<span><span class="va">latent_dim</span> <span class="op">&lt;-</span> <span class="fl">1024</span></span>
<span></span>
<span><span class="va">source</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span>, name <span class="op">=</span> <span class="st">"english"</span><span class="op">)</span></span>
<span><span class="va">encoded_source</span> <span class="op">&lt;-</span> <span class="va">source</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span><span class="va">vocab_size</span>, <span class="va">embed_dim</span>, mask_zero <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/bidirectional.html">bidirectional</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_gru.html">layer_gru</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">latent_dim</span><span class="op">)</span>, merge_mode <span class="op">=</span> <span class="st">"sum"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Następnie dodajmy dekoder - prostą warstwę GRU, która jako stan początkowy przyjmuje zakodowane zdanie źródłowe. Na wierzchu dodajemy <code><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense()</a></code>, która tworzy dla każdego kroku wyjściowego rozkład prawdopodobieństwa w hiszpańskim słownictwie.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb159"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">decoder_gru</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_gru.html">layer_gru</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">latent_dim</span>, return_sequences <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">past_target</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span>, name <span class="op">=</span> <span class="st">"spanish"</span><span class="op">)</span></span>
<span><span class="va">target_next_step</span> <span class="op">&lt;-</span> <span class="va">past_target</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_embedding.html">layer_embedding</a></span><span class="op">(</span><span class="va">vocab_size</span>, <span class="va">embed_dim</span>, mask_zero <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">decoder_gru</span><span class="op">(</span>initial_state <span class="op">=</span> <span class="va">encoded_source</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">vocab_size</span>, activation <span class="op">=</span> <span class="st">"softmax"</span><span class="op">)</span></span>
<span><span class="va">seq2seq_rnn</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span>inputs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">source</span>, <span class="va">past_target</span><span class="op">)</span>,</span>
<span>                           outputs <span class="op">=</span> <span class="va">target_next_step</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Podczas treningu dekoder przyjmuje jako dane wejściowe całą sekwencję docelową, ale dzięki krokowej naturze RNN, patrzy tylko na tokeny <span class="math inline">\(1\ldots N\)</span> na wejściu, aby przewidzieć token <span class="math inline">\(N\)</span> na wyjściu (co odpowiada następnemu tokenowi w sekwencji, ponieważ wyjście ma być przesunięte o jeden krok). Oznacza to, że używamy tylko informacji z przeszłości do przewidywania przyszłości, tak jak powinniśmy; w przeciwnym razie oszukiwalibyśmy, a nasz model nie działałby w czasie wnioskowania.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb160"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">seq2seq_rnn</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>                        loss <span class="op">=</span> <span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span>                        metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">seq2seq_rnn</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">train_ds</span>, epochs <span class="op">=</span> <span class="fl">15</span>, validation_data <span class="op">=</span> <span class="va">val_ds</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Wybraliśmy <em>accuracy</em> jako niezbyt fortunny sposób monitorowania wydajności zestawu walidacyjnego podczas treningu. Średnio model przewiduje następne słowo w hiszpańskim zdaniu poprawnie w 63,2% przypadków. Jednak w praktyce dokładność następnego tokenu nie jest optymalną miarą dla modeli tłumaczenia maszynowego, w szczególności dlatego, że zakłada, że prawidłowe tokeny docelowe od <span class="math inline">\(0\)</span> do <span class="math inline">\(N\)</span> są już znane podczas przewidywania tokenu <span class="math inline">\(N+1\)</span>. W rzeczywistości podczas wnioskowania generujemy zdanie docelowe od zera i nie możemy polegać na tym, że wcześniej wygenerowane tokeny są w 100% poprawne. Jeśli pracujemy nad rzeczywistym systemem tłumaczenia maszynowego, prawdopodobnie użyjemy metryki BLEU<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> do oceny swoich modeli - metryki, która analizuje całe wygenerowane sekwencje i wydaje się dobrze korelować z ludzkim postrzeganiem jakości tłumaczenia.</p>
<div class="no-row-height column-margin column-container"><p><sup>6</sup>&nbsp;BLEU (ang. <em>BiLingual Evaluation Understudy</em>) to wskaźnik służący do automatycznej oceny tekstu przetłumaczonego maszynowo. Wynik BLEU to liczba od zera do jednego, która mierzy podobieństwo tekstu przetłumaczonego maszynowo do zestawu wysokiej jakości tłumaczeń referencyjnych. Wartość 0 oznacza, że tekst przetłumaczony maszynowo nie pokrywa się z tłumaczeniem referencyjnym (niska jakość), podczas gdy wartość 1 oznacza, że tekst idealnie pokrywa się z tłumaczeniem referencyjnym (wysoka jakość).</p></div><p>Na koniec użyjmy naszego modelu do wnioskowania. Wybierzemy kilka zdań z zestawu testowego i sprawdzimy, jak nasz model je tłumaczy. Zaczniemy od tokenu początkowego “<code>[start]</code>” i wprowadzimy go do modelu dekodera wraz z zakodowanym angielskim zdaniem źródłowym. Pobierzemy predykcję następnego tokena i ponownie wprowadzimy ją do dekodera, próbkując jeden nowy token docelowy w każdej iteracji, aż dojdziemy do “<code>[end]</code>” lub osiągniemy maksymalną długość zdania.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb161"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">spa_vocab</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_text_vectorization.html">get_vocabulary</a></span><span class="op">(</span><span class="va">target_vectorization</span><span class="op">)</span></span>
<span><span class="va">max_decoded_sentence_length</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span></span>
<span><span class="va">decode_sequence</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_sentence</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">tokenized_input_sentence</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">source_vectorization</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="va">input_sentence</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">decoded_sentence</span> <span class="op">&lt;-</span> <span class="st">"[start]"</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">max_decoded_sentence_length</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">tokenized_target_sentence</span> <span class="op">&lt;-</span></span>
<span>      <span class="fu">target_vectorization</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="va">decoded_sentence</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">next_token_predictions</span> <span class="op">&lt;-</span> <span class="va">seq2seq_rnn</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">tokenized_input_sentence</span>,</span>
<span>                   <span class="va">tokenized_target_sentence</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">sampled_token_index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">next_token_predictions</span><span class="op">[</span><span class="fl">1</span>, <span class="va">i</span>, <span class="op">]</span><span class="op">)</span></span>
<span>    <span class="va">sampled_token</span> <span class="op">&lt;-</span> <span class="va">spa_vocab</span><span class="op">[</span><span class="va">sampled_token_index</span><span class="op">]</span></span>
<span>    <span class="va">decoded_sentence</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="va">decoded_sentence</span>, <span class="va">sampled_token</span><span class="op">)</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">sampled_token</span> <span class="op">==</span> <span class="st">"[end]"</span><span class="op">)</span></span>
<span>      <span class="kw">break</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="va">decoded_sentence</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">input_sentence</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">test_pairs</span><span class="op">$</span><span class="va">english</span>, <span class="fl">1</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">"-"</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">input_sentence</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu">decode_sequence</span><span class="op">(</span><span class="va">input_sentence</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] "-"
[1] "He has a bath every morning."
1/1 - 1s - 1s/epoch - 1s/step
1/1 - 0s - 40ms/epoch - 40ms/step
1/1 - 0s - 34ms/epoch - 34ms/step
1/1 - 0s - 31ms/epoch - 31ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 32ms/epoch - 32ms/step
1/1 - 0s - 34ms/epoch - 34ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 33ms/epoch - 33ms/step
1/1 - 0s - 31ms/epoch - 31ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 31ms/epoch - 31ms/step
1/1 - 0s - 32ms/epoch - 32ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
[1] "[start] tapa tateti bebido acabo frito precaución identificar acordaré estaríamos disculpes lavara vereda solos juntarse tarea experto picar podrida pesadas encuentra"
[1] "-"
[1] "Yesterday night, I shared a cab with Paris Hilton."
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 32ms/epoch - 32ms/step
1/1 - 0s - 31ms/epoch - 31ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
[1] "[start] tapa tateti bebido acabo frito precaución identificar acordaré estaríamos disculpes lavara vereda solos juntarse tarea experto picar podrida pesadas encuentra"
[1] "-"
[1] "Tom asked Mary what kind of movies she liked."
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 33ms/epoch - 33ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 26ms/epoch - 26ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
[1] "[start] tapa tateti bebido acabo frito precaución identificar acordaré estaríamos disculpes lavara vereda solos juntarse tarea experto picar podrida pesadas encuentra"
[1] "-"
[1] "I've got a touch of the flu."
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 31ms/epoch - 31ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 31ms/epoch - 31ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 26ms/epoch - 26ms/step
1/1 - 0s - 26ms/epoch - 26ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
[1] "[start] tapa tateti bebido acabo frito precaución identificar acordaré estaríamos disculpes lavara vereda solos juntarse tarea experto picar podrida pesadas encuentra"
[1] "-"
[1] "Tom said he didn't want anything to eat."
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 30ms/epoch - 30ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 27ms/epoch - 27ms/step
1/1 - 0s - 28ms/epoch - 28ms/step
1/1 - 0s - 29ms/epoch - 29ms/step
1/1 - 0s - 31ms/epoch - 31ms/step
[1] "[start] tapa tateti bebido acabo frito precaución identificar acordaré estaríamos disculpes lavara vereda solos juntarse tarea experto picar podrida pesadas encuentra"</code></pre>
</div>
</div>
<p><code>decode_sequence()</code> działa dobrze, choć być może nieco wolniej niż byśmy chcieli. Jednym z łatwych sposobów na przyspieszenie działania takiego kodu jest użycie funkcji <code><a href="https://rdrr.io/pkg/tensorflow/man/tf_function.html">tf_function()</a></code>. Przepiszmy funkcję <code>decode_sentence()</code> tak, aby była kompilowana przez <code><a href="https://rdrr.io/pkg/tensorflow/man/tf_function.html">tf_function()</a></code>. Oznacza to, że zamiast używać natywnych funkcji R, takich jak <code><a href="https://rdrr.io/r/base/seq.html">seq()</a></code>, <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> i <code><a href="https://rdrr.io/r/base/which.min.html">which.max()</a></code>, użyjemy odpowiedników TensorFlow, takich jak <code>tf$range()</code>, wywołując bezpośrednio <code>model()</code> i <code>tf$argmax()</code>.</p>
<p>Ponieważ <code>tf$range()</code> i <code>tf$argmax()</code> zwracają wartość równą 0, ustawimy lokalną opcję funkcji: <code>option(tensorflow.extract.style = "python")</code>. Zmieni to zachowanie <code>[</code> dla tensorów, aby również startowały od 0.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb163"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tf_decode_sequence</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/tf_function.html">tf_function</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">input_sentence</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>  <span class="fu">withr</span><span class="fu">::</span><span class="fu"><a href="https://withr.r-lib.org/reference/with_options.html">local_options</a></span><span class="op">(</span>tensorflow.extract.style <span class="op">=</span> <span class="st">"python"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">tokenized_input_sentence</span> <span class="op">&lt;-</span> <span class="va">input_sentence</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu">source_vectorization</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">spa_vocab</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span><span class="va">spa_vocab</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">decoded_sentence</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span><span class="st">"[start]"</span>, shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="va">tf</span><span class="op">$</span><span class="fu">range</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">max_decoded_sentence_length</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>    <span class="va">tokenized_target_sentence</span> <span class="op">&lt;-</span> <span class="va">decoded_sentence</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="fu">target_vectorization</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">next_token_predictions</span> <span class="op">&lt;-</span></span>
<span>      <span class="fu">seq2seq_rnn</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">tokenized_input_sentence</span>,</span>
<span>                       <span class="va">tokenized_target_sentence</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">sampled_token_index</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">argmax</span><span class="op">(</span><span class="va">next_token_predictions</span><span class="op">[</span><span class="fl">0</span>, <span class="va">i</span>, <span class="op">]</span><span class="op">)</span></span>
<span>    <span class="va">sampled_token</span> <span class="op">&lt;-</span> <span class="va">spa_vocab</span><span class="op">[</span><span class="va">sampled_token_index</span><span class="op">]</span></span>
<span>    <span class="va">decoded_sentence</span> <span class="op">&lt;-</span></span>
<span>      <span class="va">tf</span><span class="op">$</span><span class="va">strings</span><span class="op">$</span><span class="fu">join</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">decoded_sentence</span>, <span class="va">sampled_token</span><span class="op">)</span>,</span>
<span>                      separator <span class="op">=</span> <span class="st">" "</span><span class="op">)</span></span>
<span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">sampled_token</span> <span class="op">==</span> <span class="st">"[end]"</span><span class="op">)</span></span>
<span>      <span class="kw">break</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">decoded_sentence</span></span>
<span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">input_sentence</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">test_pairs</span><span class="op">$</span><span class="va">english</span>, <span class="fl">1</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"-\n"</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">input_sentence</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">input_sentence</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>          <span class="fu">tf_decode_sequence</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>-
I heard someone whistle. 
[start] tapa tateti bebido acabo frito precaución identificar acordaré estaríamos disculpes lavara vereda solos juntarse tarea experto picar podrida pesadas encuentra 
-
He came several times. 
[start] tapa tateti bebido acabo frito precaución identificar acordaré estaríamos disculpes lavara vereda solos juntarse tarea experto picar podrida pesadas encuentra 
-
I'll meet you tomorrow. 
[start] tapa tateti bebido acabo frito precaución identificar acordaré estaríamos disculpes lavara vereda solos juntarse tarea experto picar podrida pesadas encuentra 
-
I'd rather go for a walk than see the movie. 
[start] tapa tateti bebido acabo frito precaución identificar acordaré estaríamos disculpes lavara vereda solos juntarse tarea experto picar podrida pesadas encuentra 
-
Not every student has a dictionary. 
[start] tapa tateti bebido acabo frito precaución identificar acordaré estaríamos disculpes lavara vereda solos juntarse tarea experto picar podrida pesadas encuentra </code></pre>
</div>
</div>
<p>Nasza funkcja <code>tf_decode_sentence()</code> jest około 10 razy szybsza od wersji natywnej.</p>
<p>Należy zauważyć, że ta konfiguracja wnioskowania, choć bardzo prosta, jest raczej nieefektywna, ponieważ ponownie przetwarzamy całe zdanie źródłowe i całe wygenerowane zdanie docelowe za każdym razem, gdy próbkujemy nowe słowo. W praktycznym zastosowaniu koder i dekoder byłyby traktowane jako dwa oddzielne modele, a dekoder wykonywałby tylko jeden krok w każdej iteracji próbkowania tokenów, ponownie wykorzystując swój poprzedni stan wewnętrzny.</p>
<p>Oto wyniki naszego tłumaczenia. Nasz model działa przyzwoicie jak na model typu <em>toy</em>, choć nadal popełnia wiele podstawowych błędów.</p>
<p>Istnieje wiele sposobów na ulepszenie “zabawkowego” modelu: moglibyśmy użyć głębokiego stosu warstw rekurencyjnych zarówno dla kodera, jak i dekodera (należy pamiętać, że w przypadku dekodera zarządzanie stanem jest nieco bardziej skomplikowane). Moglibyśmy użyć LSTM zamiast GRU. I tak dalej. Poza takimi poprawkami, podejście RNN do uczenia sekwencyjnego ma jednak kilka fundamentalnych ograniczeń:</p>
<ul>
<li><p>Reprezentacja sekwencji źródłowej musi być przechowywana w całości w wektorze (wektorach) stanu kodera, co nakłada znaczne ograniczenia na rozmiar i złożoność zdań, które można przetłumaczyć. To trochę tak, jakby człowiek tłumaczył zdanie w całości z pamięci, nie patrząc dwa razy na zdanie źródłowe podczas tworzenia tłumaczenia.</p></li>
<li><p>RNN mają problem z radzeniem sobie z bardzo długimi sekwencjami, ponieważ mają tendencję do stopniowego zapominania o przeszłości - do czasu osiągnięcia setnego tokena w dowolnej sekwencji, niewiele informacji pozostaje o początku sekwencji. Oznacza to, że modele oparte na RNN nie są w stanie utrzymać długoterminowego kontekstu, który może być niezbędny do tłumaczenia długich dokumentów.</p></li>
</ul>
<p>Ograniczenia te sprawiły, że społeczność zajmująca się uczeniem maszynowym przyjęła architekturę transformer do rozwiązywania problemów typu sekwencja-sekwencja. Przyjrzyjmy się temu.</p>
</section><section id="uczenie-się-sekwencyjne-z-transformerem" class="level3 page-columns page-full" data-number="7.9.3"><h3 data-number="7.9.3" class="anchored" data-anchor-id="uczenie-się-sekwencyjne-z-transformerem">
<span class="header-section-number">7.9.3</span> Uczenie się sekwencyjne z transformerem</h3>
<p>Uczenie sekwencyjne to zadanie, w którym transformer naprawdę błyszczy. Atencja neuronowa umożliwia modelom transformer właściwe przetwarzanie sekwencji, które są znacznie dłuższe i bardziej złożone niż te, z którymi radzą sobie sieci RNN.</p>
<p>Jako człowiek tłumaczący z angielskiego na hiszpański, nie czytamy angielskiego zdania po jednym słowie na raz, tylko zachowujemy jego znaczenie w pamięci, a następnie generujemy hiszpańskie zdanie po jednym słowie na raz. Może to zadziałać w przypadku zdania składającego się z pięciu słów, ale jest mało prawdopodobne, by zadziałało w przypadku całego akapitu. Zamiast tego, prawdopodobnie będziemy chcieli przeskakiwać między zdaniem źródłowym a tłumaczeniem i zwracać uwagę na różne słowa w źródle podczas zapisywania różnych części tłumaczenia.</p>
<p>Dokładnie to można osiągnąć za pomocą atencji neuronowej i transformerów. Znamy już koder transformera, który wykorzystuje samo-atencję (w odmianie z wieloma głowami) do tworzenia reprezentacji kontekstowych każdego tokena w sekwencji wejściowej. W transformatorze sekwencja-sekwencja, koder transformera naturalnie odgrywałby rolę kodera, który odczytuje sekwencję źródłową i tworzy jej zakodowaną reprezentację. Jednak w przeciwieństwie do naszego poprzedniego kodera RNN, koder transformer utrzymuje zakodowaną reprezentację w formacie sekwencji: jest to sekwencja wektorów osadzania z uwzględnieniem kontekstu.</p>
<p>Druga część modelu to dekoder transformera. Podobnie jak dekoder RNN, odczytuje on tokeny <span class="math inline">\(1\ldots N\)</span> w sekwencji docelowej i próbuje przewidzieć token <span class="math inline">\(N + 1\)</span>. Co najważniejsze, robiąc to, wykorzystuje atencję neuronową, aby zidentyfikować, które tokeny w zakodowanym zdaniu źródłowym są najbardziej powiązane z tokenem docelowym, który obecnie próbuje przewidzieć. Przypomnijmy model atencji posiadał query, key i value. W dekoderze transformerowym sekwencja docelowa służy jako query, które jest używane do zwracania większej uwagi na różne części sekwencji źródłowej (sekwencja źródłowa odgrywa role zarówno key, jak i value).</p>
<section id="dekoder-transformerowy" class="level4 page-columns page-full" data-number="7.9.3.1"><h4 data-number="7.9.3.1" class="anchored" data-anchor-id="dekoder-transformerowy">
<span class="header-section-number">7.9.3.1</span> Dekoder transformerowy</h4>
<p><a href="#fig-trans1" class="quarto-xref">Rysunek&nbsp;<span>7.14</span></a> przedstawia pełny transformator sekwencja do sekwencji. Przyjrzyjmy się wewnętrznym elementom dekodera. Rozpoznamy, że wygląda on bardzo podobnie do kodera transformera, z wyjątkiem tego, że dodatkowy blok atencji jest wstawiony pomiędzy blok samo-atencji zastosowany do sekwencji docelowej i gęstych warstw bloku wyjściowego.</p>
<div id="fig-trans1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-trans1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2024-02-14 o 20.56.12.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-trans1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rys.&nbsp;7.14: <code>TransformerDecoder</code> jest podobny do <code>TransformerEncoder</code>, z wyjątkiem tego, że zawiera dodatkowy blok atencji, w którym key i value są sekwencją źródłową zakodowaną przez <code>TransformerEncoder</code>. Razem, koder i dekoder tworzą transformator end-to-end.
</figcaption></figure>
</div>
<p>Zaimplementujmy to. Podobnie jak w przypadku <code>TransformerEncoder</code>, będziemy tworzyć nową klasę warstw.</p>
<p>Metoda <code><a href="https://rdrr.io/r/base/call.html">call()</a></code> jest prostym odwzorowaniem połączeń diagramu z <a href="#fig-trans1" class="quarto-xref">Rysunek&nbsp;<span>7.14</span></a>. Jest jednak dodatkowy szczegół, który musimy wziąć pod uwagę - przyczynowe wypełnianie (ang. <em>casual padding</em>). Wypełnianie przyczynowe jest absolutnie krytyczne dla pomyślnego uczenia transformatora sekwencja do sekwencji. W przeciwieństwie do RNN, który patrzy na swoje dane wejściowe po jednym kroku na raz, a zatem będzie miał dostęp tylko do kroków <span class="math inline">\(1\ldots N\)</span>, aby wygenerować krok wyjściowy <span class="math inline">\(N\)</span> (który jest tokenem <span class="math inline">\(N+1\)</span> w sekwencji docelowej), natomiast <code>TransformerDecoder</code> jest niezależny od kolejności: patrzy na całą sekwencję docelową naraz. Gdyby pozwolić mu na wykorzystanie całego wejścia, po prostu nauczyłby się kopiować krok wejściowy <span class="math inline">\(N+1\)</span> do lokalizacji <span class="math inline">\(N\)</span> na wyjściu. W ten sposób model osiągnąłby idealną dokładność treningu, ale oczywiście podczas wnioskowania byłby całkowicie bezużyteczny, ponieważ kroki wejściowe poza <span class="math inline">\(N\)</span> nie są dostępne.</p>
<p>Rozwiązanie jest proste - zamaskujemy górną połowę macierzy atencji parami, aby uniemożliwić modelowi zwracanie uwagi na informacje z przyszłości - informacje tylko z tokenów <span class="math inline">\(1\ldots N\)</span> w sekwencji docelowej powinny być używane podczas generowania tokena docelowego <span class="math inline">\(N+1\)</span>. Aby to zrobić, dodamy metodę <code>get_causal_attention_mask(inputs)</code> do naszego <code>TransformerDecoder</code>, aby pobrać maskę uwagi, którą możemy przekazać do naszych warstw <code>MultiHeadAttention</code>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb165"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">layer_transformer_decoder</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/new-classes.html">new_layer_class</a></span><span class="op">(</span></span>
<span>  classname <span class="op">=</span> <span class="st">"TransformerDecoder"</span>,</span>
<span></span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">embed_dim</span>, <span class="va">dense_dim</span>, <span class="va">num_heads</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">embed_dim</span> <span class="op">&lt;-</span> <span class="va">embed_dim</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">dense_dim</span> <span class="op">&lt;-</span> <span class="va">dense_dim</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">num_heads</span> <span class="op">&lt;-</span> <span class="va">num_heads</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">attention_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_multi_head_attention.html">layer_multi_head_attention</a></span><span class="op">(</span>num_heads <span class="op">=</span> <span class="va">num_heads</span>,</span>
<span>                                                   key_dim <span class="op">=</span> <span class="va">embed_dim</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">attention_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_multi_head_attention.html">layer_multi_head_attention</a></span><span class="op">(</span>num_heads <span class="op">=</span> <span class="va">num_heads</span>,</span>
<span>                                                   key_dim <span class="op">=</span> <span class="va">embed_dim</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">dense_proj</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">dense_dim</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">embed_dim</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">layernorm_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_layer_normalization.html">layer_layer_normalization</a></span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">layernorm_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_layer_normalization.html">layer_layer_normalization</a></span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">layernorm_3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_layer_normalization.html">layer_layer_normalization</a></span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">supports_masking</span> <span class="op">&lt;-</span> <span class="cn">TRUE</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  get_config <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">config</span> <span class="op">&lt;-</span> <span class="va">super</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="kw">for</span> <span class="op">(</span><span class="va">name</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"embed_dim"</span>, <span class="st">"num_heads"</span>, <span class="st">"dense_dim"</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">config</span><span class="op">[[</span><span class="va">name</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">[[</span><span class="va">name</span><span class="op">]</span><span class="op">]</span></span>
<span>    <span class="va">config</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  get_causal_attention_mask <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">batch_size</span>, <span class="va">sequence_length</span>, <span class="va">encoding_length</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html">%&lt;-%</a></span></span>
<span>      <span class="va">tf</span><span class="op">$</span><span class="fu">unstack</span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">shape</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">range</span><span class="op">(</span><span class="va">sequence_length</span><span class="op">)</span></span>
<span>    <span class="va">i</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span>, <span class="va">tf</span><span class="op">$</span><span class="va">newaxis</span><span class="op">]</span></span>
<span>    <span class="va">j</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="va">tf</span><span class="op">$</span><span class="va">newaxis</span>, <span class="op">]</span></span>
<span>    <span class="va">mask</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">cast</span><span class="op">(</span><span class="va">i</span> <span class="op">&gt;=</span> <span class="va">j</span>, <span class="st">"int32"</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">tf</span><span class="op">$</span><span class="fu">tile</span><span class="op">(</span><span class="va">mask</span><span class="op">[</span><span class="va">tf</span><span class="op">$</span><span class="va">newaxis</span>, , <span class="op">]</span>,</span>
<span>            <span class="va">tf</span><span class="op">$</span><span class="fu">stack</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">batch_size</span>, <span class="fl">1L</span>, <span class="fl">1L</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">encoder_outputs</span>, <span class="va">mask</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>    <span class="va">causal_mask</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">get_causal_attention_mask</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html">is.null</a></span><span class="op">(</span><span class="va">mask</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">mask</span> <span class="op">&lt;-</span> <span class="va">causal_mask</span></span>
<span>    <span class="kw">else</span></span>
<span>      <span class="va">mask</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/compound.html">%&lt;&gt;%</a></span> <span class="op">{</span> <span class="va">tf</span><span class="op">$</span><span class="fu">minimum</span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">cast</span><span class="op">(</span><span class="va">.</span><span class="op">[</span>, <span class="va">tf</span><span class="op">$</span><span class="va">newaxis</span>, <span class="op">]</span>, <span class="st">"int32"</span><span class="op">)</span>,</span>
<span>                             <span class="va">causal_mask</span><span class="op">)</span> <span class="op">}</span></span>
<span></span>
<span>    <span class="va">inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="op">{</span> <span class="va">self</span><span class="op">$</span><span class="fu">attention_1</span><span class="op">(</span>query <span class="op">=</span> <span class="va">.</span>, value <span class="op">=</span> <span class="va">.</span>, key <span class="op">=</span> <span class="va">.</span>,</span>
<span>                         attention_mask <span class="op">=</span> <span class="va">causal_mask</span><span class="op">)</span> <span class="op">+</span> <span class="va">.</span> <span class="op">}</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">layernorm_1</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span></span>
<span>      <span class="op">{</span> <span class="va">self</span><span class="op">$</span><span class="fu">attention_2</span><span class="op">(</span>query <span class="op">=</span> <span class="va">.</span>,</span>
<span>                         value <span class="op">=</span> <span class="va">encoder_outputs</span>,</span>
<span>                         key <span class="op">=</span> <span class="va">encoder_outputs</span>,</span>
<span>                         attention_mask <span class="op">=</span> <span class="va">mask</span><span class="op">)</span> <span class="op">+</span> <span class="va">.</span> <span class="op">}</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">layernorm_2</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span></span>
<span>      <span class="op">{</span> <span class="va">self</span><span class="op">$</span><span class="fu">dense_proj</span><span class="op">(</span><span class="va">.</span><span class="op">)</span> <span class="op">+</span> <span class="va">.</span> <span class="op">}</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">layernorm_3</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Będziemy trenować model transformator typu <em>end-to-end</em>. Mapuje on sekwencję źródłową i docelową do sekwencji docelowej o jeden krok w przyszłości. W prosty sposób łączy elementy, które zbudowaliśmy do tej pory: warstwy <code>PositionalEmbedding</code>, <code>TransformerEncoder</code> i <code>TransformerDecoder</code>. Zwróćmy uwagę, że zarówno <code>TransformerEncoder</code>, jak i <code>TransformerDecoder</code> są niezmienne pod względem kształtu<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>, więc możemy połączyć wiele z nich, aby stworzyć bardziej wydajny koder lub dekoder. W naszym przykładzie będziemy trzymać się pojedynczej instancji każdego z nich.</p>
<div class="no-row-height column-margin column-container"><p><sup>7</sup>&nbsp;wejście i wyjście jest tych samych rozmiarów</p></div><div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb166"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">embed_dim</span> <span class="op">&lt;-</span> <span class="fl">256</span></span>
<span><span class="va">dense_dim</span> <span class="op">&lt;-</span> <span class="fl">2048</span></span>
<span><span class="va">num_heads</span> <span class="op">&lt;-</span> <span class="fl">8</span></span>
<span></span>
<span><span class="va">encoder_inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span>, name <span class="op">=</span> <span class="st">"english"</span><span class="op">)</span></span>
<span><span class="va">encoder_outputs</span> <span class="op">&lt;-</span> <span class="va">encoder_inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">layer_positional_embedding</span><span class="op">(</span><span class="va">sequence_length</span>, <span class="va">vocab_size</span>, <span class="va">embed_dim</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">layer_transformer_encoder</span><span class="op">(</span><span class="va">embed_dim</span>, <span class="va">dense_dim</span>, <span class="va">num_heads</span><span class="op">)</span></span>
<span></span>
<span><span class="va">transformer_decoder</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">layer_transformer_decoder</span><span class="op">(</span><span class="cn">NULL</span>, <span class="va">embed_dim</span>, <span class="va">dense_dim</span>, <span class="va">num_heads</span><span class="op">)</span></span>
<span></span>
<span><span class="va">decoder_inputs</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span>, name <span class="op">=</span> <span class="st">"spanish"</span><span class="op">)</span></span>
<span><span class="va">decoder_outputs</span> <span class="op">&lt;-</span> <span class="va">decoder_inputs</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">layer_positional_embedding</span><span class="op">(</span><span class="va">sequence_length</span>, <span class="va">vocab_size</span>, <span class="va">embed_dim</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">transformer_decoder</span><span class="op">(</span><span class="va">.</span>, <span class="va">encoder_outputs</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">vocab_size</span>, activation<span class="op">=</span><span class="st">"softmax"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">transformer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">encoder_inputs</span>, <span class="va">decoder_inputs</span><span class="op">)</span>,</span>
<span>                           <span class="va">decoder_outputs</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb167"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">transformer</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>          loss <span class="op">=</span> <span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span>          metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">transformer</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">train_ds</span>, epochs <span class="op">=</span> <span class="fl">30</span>, validation_data <span class="op">=</span> <span class="va">val_ds</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">save_model_tf</a></span><span class="op">(</span><span class="va">transformer</span>, filepath <span class="op">=</span> <span class="st">"models/end_to_end_transformer.keras"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Osiągamy dokładność 65,3%, czyli istotnie lepiej niż z modelu opartego na GRU.</p>
<p>Na koniec spróbujmy użyć naszego modelu do przetłumaczenia nigdy wcześniej nie widzianych angielskich zdań z zestawu testowego. Konfiguracja jest identyczna z tą, której użyliśmy do modelu RNN typu sekwencja-sekwencja. Zastąpimy tylko <code>seq2seq_rnn</code> transformatorem i usuniemy dodatkowego tokena, który skonfigurowaliśmy do dodania w warstwie <code>target_vectorization()</code>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb168"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">transformer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span></span>
<span>  <span class="st">"models/end_to_end_transformer.keras"</span>,</span>
<span>  custom_objects <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>    <span class="va">layer_positional_embedding</span>,</span>
<span>    <span class="va">layer_transformer_decoder</span>,</span>
<span>    <span class="va">layer_transformer_encoder</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb169"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tf_decode_sequence</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/tf_function.html">tf_function</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">input_sentence</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">withr</span><span class="fu">::</span><span class="fu"><a href="https://withr.r-lib.org/reference/with_options.html">local_options</a></span><span class="op">(</span>tensorflow.extract.style <span class="op">=</span> <span class="st">"python"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">tokenized_input_sentence</span> <span class="op">&lt;-</span> <span class="va">input_sentence</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu">source_vectorization</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="va">spa_vocab</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span><span class="va">spa_vocab</span><span class="op">)</span></span>
<span>  <span class="va">decoded_sentence</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span><span class="st">"[start]"</span>, shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="va">tf</span><span class="op">$</span><span class="fu">range</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">max_decoded_sentence_length</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>    <span class="va">tokenized_target_sentence</span> <span class="op">&lt;-</span></span>
<span>      <span class="fu">target_vectorization</span><span class="op">(</span><span class="va">decoded_sentence</span><span class="op">)</span><span class="op">[</span>,<span class="cn">NA</span><span class="op">:</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span></span>
<span>    <span class="va">next_token_predictions</span> <span class="op">&lt;-</span></span>
<span>      <span class="fu">transformer</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">tokenized_input_sentence</span>,</span>
<span>                       <span class="va">tokenized_target_sentence</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">sampled_token_index</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">argmax</span><span class="op">(</span><span class="va">next_token_predictions</span><span class="op">[</span><span class="fl">0</span>, <span class="va">i</span>, <span class="op">]</span><span class="op">)</span></span>
<span>    <span class="va">sampled_token</span> <span class="op">&lt;-</span> <span class="va">spa_vocab</span><span class="op">[</span><span class="va">sampled_token_index</span><span class="op">]</span></span>
<span>    <span class="va">decoded_sentence</span> <span class="op">&lt;-</span></span>
<span>      <span class="va">tf</span><span class="op">$</span><span class="va">strings</span><span class="op">$</span><span class="fu">join</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">decoded_sentence</span>, <span class="va">sampled_token</span><span class="op">)</span>,</span>
<span>                      separator <span class="op">=</span> <span class="st">" "</span><span class="op">)</span></span>
<span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">sampled_token</span> <span class="op">==</span> <span class="st">"[end]"</span><span class="op">)</span></span>
<span>      <span class="kw">break</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">decoded_sentence</span></span>
<span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">20</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">input_sentence</span>, <span class="va">correct_translation</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html">%&lt;-%</a></span></span>
<span>      <span class="va">test_pairs</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample.int</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">test_pairs</span><span class="op">)</span>, <span class="fl">1</span><span class="op">)</span>, <span class="op">]</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"-\n"</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">input_sentence</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">correct_translation</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">input_sentence</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>          <span class="fu">tf_decode_sequence</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>-
Tom didn't know how to treat his employees right. 
[start] Tom no supo comportarse correctamente con sus empleados. [end] 
[start] tom pueden que se quieras bien en el raro de quiere [end] 
-
School starts Monday. 
[start] La escuela comienza el lunes. [end] 
[start] morir dicho a mi [UNK] [end] 
-
I went there to meet him. 
[start] Fui ahí para reunirme con él. [end] 
[start] yo te lo [UNK] en bien [end] 
-
Do you feel like going to the theater? 
[start] ¿Tienes ganas de ir al teatro? [end] 
[start] te gusta puedo lo treinta el la [UNK] [end] 
-
The Japanese attacked Pearl Harbor on December 7, 1941. 
[start] Los japoneses atacaron Pearl Harbor el 7 de diciembre de 1941. [end] 
[start] el respira recordar de que mi opciones [UNK] [UNK] [UNK] [UNK] [end] 
-
They say that she'll get married soon. 
[start] Dicen que ella va a casarse pronto. [end] 
[start] el hay podría a somos la vivir casa [UNK] a Él john [end] 
-
Steven Spielberg is a film director. 
[start] Steven Spielberg es un director de cine. [end] 
[start] [UNK] se debemos un [UNK] [end] 
-
I'm sorry if my words hurt you. 
[start] Lo lamento si mis palabras te hieren. [end] 
[start] me bolsa casa te he [UNK] [end] 
-
I've lost my ticket. 
[start] He perdido mi billete. [end] 
[start] no sus venga tengo [end] 
-
He likes this guitar. 
[start] A él le gusta esta guitarra. [end] 
[start] eso mientras se mía en el grandes de tengo [end] 
-
Tom is eating a cake. 
[start] Tom se está comiendo una torta. [end] 
[start] tom su tengo es la la que paró somos un [UNK] [end] 
-
Follow Tom. 
[start] Síganlo a Tomás. [end] 
[start] menudo las pregunto de tom [end] 
-
Tell me what you think about Tom. 
[start] Dime lo que piensas de Tom. [end] 
[start] ahora es lo que dos tengo tom [end] 
-
They believe in a life after death. 
[start] Ellos creen en la vida después de la muerte. [end] 
[start] en un gente en médico eso tú [end] 
-
Japan today is not what it was even ten years ago. 
[start] Japón hoy no es lo que era ni hace 10 años. [end] 
[start] se secreto no cómo que favor acá él [end] 
-
I came to give you back the books I borrowed. 
[start] Vine para devolverte los libros que tomé prestados. [end] 
[start] quiero [UNK] que su [end] 
-
Tom can't seem to find a decent job. 
[start] Tom parece no poder encontrar un trabajo decente. [end] 
[start] no puede plantas lo que no dar es un platos [end] 
-
Tom is a man of his word. 
[start] Tom es un hombre de palabra. [end] 
[start] tom es un nuevo de Él árbol puedes [end] 
-
You do not have a good memory. 
[start] Tú no tienes una buena memoria. [end] 
[start] no me culpable que del realmente [end] 
-
He can't be an honest man. 
[start] No puede ser un hombre honrado. [end] 
[start] no puede pero cuando sin habría [end] </code></pre>
</div>
</div>
<p>Na tym kończy się ten rozdział o przetwarzaniu języka naturalnego. W ramach niego przeszliśmy od podstaw do w rozwiązania współcześnie używanego, czyli Transformera, który może tłumaczyć zdania z angielskiego na hiszpański.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-bengioNeuralProbabilisticLanguage" class="csl-entry" role="listitem">
Bengio, Yoshua, Réjean Ducharme, Pascal Vincent, i Christian Jauvin. b.d. <span>„A Neural Probabilistic Language Model”</span>.
</div>
<div id="ref-vaswaniAttentionAllYou2023" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, i Illia Polosukhin. b.d. <span>„Attention Is All You Need”</span>. <a href="https://doi.org/10.48550/arXiv.1706.03762">https://doi.org/10.48550/arXiv.1706.03762</a>.
</div>
</div>
</section></section></section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Skopiowano!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Skopiowano!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./rnn.html" class="pagination-link  aria-label=" dla="" danych="" sekwencyjnych="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">DNN dla danych sekwencyjnych</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="Literatura">
        <span class="nav-page-text">Literatura</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Zaawansowane metody uczenia maszynowego, Dariusz Majerek</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/dax44/AMLM/issues/new" class="toc-action"><i class="bi bi-github"></i>Zgłoś problem</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Książka została napisana w <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>


</body></html>