[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zaawansowane metody uczenia maszynowego",
    "section": "",
    "text": "WstÄ™p\nKsiÄ…Å¼ka ta jest napisana na potrzeby prowadzenia zajÄ™Ä‡ na kierunku InÅ¼ynieria i analiza danych z przedmiotu Zaawansowane metody uczenia maszynowego. Jest swego rodzaju autorskim podejÅ›ciem do tematu, przedstawiajÄ…cym wybrane metody uczenia maszynowego, ktÃ³re rzadziej wystÄ™pujÄ… w opracowaniach na temat uczenia maszynowego.\nUczenie maszynowe stanowi obszar intensywnego rozwoju, ktÃ³ry obejmuje szereg technik umoÅ¼liwiajÄ…cych bardziej skomplikowane i wydajne modele predykcyjne. WÅ›rÃ³d tych metod warto wyrÃ³Å¼niÄ‡ gÅ‚Ä™bokie sieci neuronowe, zwÅ‚aszcza konwolucyjne sieci neuronowe (CNN) i rekurencyjne sieci neuronowe (RNN). CNN sÄ… wykorzystywane w zadaniach przetwarzania obrazÃ³w, gdzie potrafiÄ… efektywnie ekstrahowaÄ‡ hierarchiczne cechy z danych wejÅ›ciowych, natomiast RNN sÄ… efektywne w analizie sekwencji danych, takich jak jÄ™zyk naturalny. Ponadto, metody uczenia maszynowego obejmujÄ… techniki transferu wiedzy, uczenie ze wzmocnieniem, generatywne modele, takie jak generatywne sieci przeciwdziedzinowe (GAN), czy teÅ¼ autokodery. Te nowoczesne podejÅ›cia umoÅ¼liwiajÄ… modelom uczÄ…cym siÄ™ wykonywanie bardziej zÅ‚oÅ¼onych zadaÅ„, a takÅ¼e adaptacjÄ™ do rÃ³Å¼norodnych danych wejÅ›ciowych, co sprawia, Å¼e sÄ… one stosowane w obszarach takich jak rozpoznawanie obrazÃ³w, przetwarzanie jÄ™zyka naturalnego, czy nawet w autonomicznych systemach decyzyjnych.\nPonadto, zaawansowane metody uczenia maszynowego obejmujÄ… takÅ¼e techniki regularyzacji, optymalizacji i inÅ¼ynieriÄ™ cech. Regularyzacja ma na celu zapobieganie przeuczeniu poprzez kontrolowanie zÅ‚oÅ¼onoÅ›ci modelu, natomiast optymalizacja skupia siÄ™ na dostosowywaniu wag modelu w celu minimalizacji funkcji straty. InÅ¼ynieria cech polega na rÄ™cznym lub automatycznym dostosowywaniu danych wejÅ›ciowych w celu uzyskania lepszych wynikÃ³w modelu. DziÄ™ki tym zaawansowanym metodom, uczenie maszynowe staje siÄ™ coraz bardziej potÄ™Å¼nym narzÄ™dziem w analizie danych i podejmowaniu skomplikowanych decyzji w rÃ³Å¼nych dziedzinach.\nModele predykcyjne dla wielu wyjÅ›Ä‡, czyli tzw. multi-target regression and classification, stanowiÄ… kolejny istotny obszar w dziedzinie uczenia maszynowego. W przypadku multi-target regression, celem jest przewidywanie wielu wartoÅ›ci wyjÅ›ciowych dla danego zestawu wejÅ›ciowego, co czÄ™sto spotyka siÄ™ w zÅ‚oÅ¼onych problemach predykcyjnych, takich jak prognozowanie wielu parametrÃ³w jednoczeÅ›nie. Z kolei w przypadku multi-target classification, model ma za zadanie przypisanie jednego lub wiÄ™cej klas dla kaÅ¼dego przykÅ‚adu wejÅ›ciowego. Te modele sÄ… powszechnie stosowane w rÃ³Å¼nych dziedzinach, takich jak bioinformatyka, finanse czy przemysÅ‚, gdzie jednoczesne przewidywanie wielu zmiennych jest kluczowe dla skutecznego rozwiÄ…zania problemu. WdroÅ¼enie takich zaawansowanych modeli predykcyjnych wymaga starannej obrÃ³bki danych, odpowiedniego dostosowania architektury modelu oraz precyzyjnej oceny wynikÃ³w, co sprawia, Å¼e sÄ… one istotnym narzÄ™dziem w obszarze analizy danych i podejmowania decyzji.\nModele jÄ™zykowe stanowiÄ… jeszcze jeden kluczowy obszar w dziedzinie uczenia maszynowego, skoncentrowany na zrozumieniu i generowaniu ludzkiego jÄ™zyka naturalnego. GÅ‚Ä™bokie sieci neuronowe, zwÅ‚aszcza rekurencyjne sieci neuronowe (RNN) i transformery, zostaÅ‚y skutecznie wykorzystane do tworzenia modeli jÄ™zykowych o zdolnoÅ›ciach przetwarzania i generowania tekstu na poziomie zbliÅ¼onym do ludzkiego. Te modele zdolne sÄ… do zrozumienia kontekstu, analizy gramatyki, a takÅ¼e generowania spÃ³jnych i sensownych odpowiedzi. Wykorzystywane sÄ… w rÃ³Å¼norodnych zastosowaniach, takich jak tÅ‚umaczenie maszynowe, generowanie tekstu, czy analiza nastroju w tekÅ›cie. Ponadto, pre-trenowane modele jÄ™zykowe, takie jak BERT czy GPT (Generative Pre-trained Transformer), zdobywajÄ… popularnoÅ›Ä‡, umoÅ¼liwiajÄ…c dostosowanie ich do rÃ³Å¼nych zadaÅ„ poprzez fine-tuning. W miarÄ™ postÄ™pu badaÅ„ i rozwoju w tej dziedzinie, modele jÄ™zykowe stajÄ… siÄ™ coraz bardziej zaawansowane, co przyczynia siÄ™ do doskonalenia komunikacji miÄ™dzy maszynami a ludÅºmi oraz do rozwijania nowych moÅ¼liwoÅ›ci w dziedzinie przetwarzania jÄ™zyka naturalnego.\nWspomniane powyÅ¼ej metody i modele bÄ™dÄ… stanowiÄ‡ treÅ›Ä‡ wykÅ‚adÃ³w z wspomnianego na wstÄ™pie przedmiotu.",
    "crumbs": [
      "WstÄ™p"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1Â  Wprowadzenie",
    "section": "",
    "text": "Witam w Å›wiecie zaawansowanych metod uczenia maszynowego ğŸ¤–, prezentowanej w niniejszej publikacji. KsiÄ…Å¼ka ta skupia siÄ™ na trzech gÅ‚Ã³wnych obszarach, zaczynajÄ…c od wielowymiarowych problemÃ³w predykcyjnych, przechodzÄ…c przez kompleksowe modele gÅ‚Ä™bokich sieci neuronowych, a koÅ„czÄ…c na zaawansowanych modelach jÄ™zykowych. Koncepcyjnie rozpoczniemy od omÃ³wienia multiple target regression and classification, gdzie przedstawimy skomplikowane zadania predykcyjne wymagajÄ…ce jednoczesnej prognozy wielu zmiennych. Przeanalizujemy praktyczne zastosowania tych modeli w obszarach, takich jak nauki spoÅ‚eczne, biologia i finanse.\nNastÄ™pnie poÅ›wiÄ™cimy uwagÄ™ gÅ‚Ä™bokim sieciom neuronowym, gÅ‚Ã³wnemu filarowi nowoczesnej sztucznej inteligencji. OmÃ³wimy ewolucjÄ™ od konwolucyjnych sieci neuronowych (CNN) do rekurencyjnych sieci neuronowych (RNN), zwracajÄ…c uwagÄ™ na ich zdolnoÅ›Ä‡ do efektywnego przetwarzania obrazÃ³w, sekwencji danych i rozwiÄ…zania bardziej zÅ‚oÅ¼onych problemÃ³w. W ramach tego obszaru, przyjrzymy siÄ™ rÃ³wnieÅ¼ technikom transferu wiedzy, uczenia ze wzmocnieniem oraz generatywnym modelom, takim jak generatywne sieci przeciwdziedzinowe (GAN), ktÃ³re poszerzajÄ… granice moÅ¼liwoÅ›ci maszynowego uczenia siÄ™.\n\n\n\nTrzeci kluczowy obszar, ktÃ³ry bÄ™dzie przedmiotem analizy, to modele jÄ™zykowe. RozwaÅ¼ania rozpoczniemy od gÅ‚Ä™bokich sieci neuronowych, a nastÄ™pnie skoncentrujemy siÄ™ na transformatorach, ktÃ³re rewolucjonizujÄ… przetwarzanie jÄ™zyka naturalnego ğŸ‘…. Przedstawimy praktyczne zastosowania tych modeli, zwÅ‚aszcza w tÅ‚umaczeniu maszynowym, generowaniu tekstu i analizie sentymentu. Ponadto, omÃ³wimy pre-trenowane modele jÄ™zykowe, takie jak BERT czy GPT, jako kluczowe narzÄ™dzia adaptacyjne, zdolne do fine-tuningu w zaleÅ¼noÅ›ci od konkretnego zadania.\nKaÅ¼dy podejmowany temat bÄ™dzie wzbogacony o implementacjÄ™ analizowanych metod w realnych scenariuszach. OmÃ³wimy kroki od obrÃ³bki danych, przez dostosowywanie architektury modelu, aÅ¼ po ocenÄ™ wynikÃ³w. W tym kontekÅ›cie poruszymy takÅ¼e aspekty etyczne i wyzwania zwiÄ…zane z zastosowaniem zaawansowanych modeli uczenia maszynowego.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_target_models.html",
    "href": "multi_target_models.html",
    "title": "2Â  Modele z wieloma wyjÅ›ciami",
    "section": "",
    "text": "2.1 Typy modeli z wieloma zmiennymi wynikowymi\nWÅ›rÃ³d nadzorowanych modeli uczenia maszynowego z wieloma zmiennymi wynikowymi moÅ¼na wymieniÄ‡ zarÃ³wno te dedykowane do klasyfikacji, jak i regresji. Modele te sÄ… znane jako modele z wieloma wyjÅ›ciami (klasyfikacyjne) lub modele z wieloma wyjÅ›ciami (regresyjne), w zaleÅ¼noÅ›ci od rodzaju problemu, ktÃ³ry rozwiÄ…zujÄ….",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Modele z wieloma wyjÅ›ciami</span>"
    ]
  },
  {
    "objectID": "multi_target_models.html#typy-modeli-z-wieloma-zmiennymi-wynikowymi",
    "href": "multi_target_models.html#typy-modeli-z-wieloma-zmiennymi-wynikowymi",
    "title": "2Â  Modele z wieloma wyjÅ›ciami",
    "section": "",
    "text": "Modele z wieloma wyjÅ›ciami (klasyfikacyjne)\nW przypadku klasyfikacji, gdy mamy wiele kategorii (klas) jako zmiennÄ… wynikowÄ…, modele te sÄ… nazywane modelami z wieloma wyjÅ›ciami. PrzykÅ‚ady obejmujÄ… algorytmy takie jak regresja logistyczna, metoda k najbliÅ¼szych sÄ…siadÃ³w (k-NN) czy algorytmy drzew decyzyjnych, ktÃ³re zostaÅ‚y dostosowane do obsÅ‚ugi wielu klas.\nPrzykÅ‚adowe zadanie: ZaÅ‚Ã³Å¼my, Å¼e mamy zbiÃ³r danych dotyczÄ…cy rÃ³Å¼nych rodzajÃ³w owocÃ³w (np. jabÅ‚ek, pomaraÅ„czy, bananÃ³w) i chcemy stworzyÄ‡ model, ktÃ³ry jednoczeÅ›nie przewiduje gatunek owocu oraz kolor owocu. Mamy wiÄ™c dwie zmienne wynikowe: gatunek (klasyfikacja wieloklasowa) i kolor (klasyfikacja wieloklasowa).\nModele z wieloma wyjÅ›ciami (regresyjne).\nW przypadku regresji, gdzie zmiennÄ… wynikowÄ… jest wektor wartoÅ›ci numerycznych, modele te sÄ… nazywane modelami z wieloma wyjÅ›ciami. PrzykÅ‚ady obejmujÄ… algorytmy regresji liniowej lub nieliniowej, algorytmy oparte na drzewach decyzyjnych, czy teÅ¼ bardziej zaawansowane modele, takie jak sieci neuronowe.\nPrzykÅ‚adowe zadanie: ZakÅ‚adamy, Å¼e mamy zbiÃ³r danych zawierajÄ…cy informacje o pracownikach, takie jak doÅ›wiadczenie zawodowe, poziom wyksztaÅ‚cenia, liczba godzin pracy tygodniowo itp. Chcemy stworzyÄ‡ model, ktÃ³ry jednoczeÅ›nie przewiduje zarobki pracownikÃ³w oraz ich poziom satysfakcji zawodowej.\nModele wielozadaniowe.\nModele wielozadaniowe to rodzaj nadzorowanego uczenia maszynowego, w ktÃ³rym model jest trenowany jednoczeÅ›nie do rozwiÄ…zania kilku zadaÅ„. Te zadania mogÄ… obejmowaÄ‡ zarÃ³wno klasyfikacjÄ™, jak i regresjÄ™. DziÄ™ki wspÃ³lnemu trenowaniu modelu na wielu zadaniach, moÅ¼na uzyskaÄ‡ korzyÅ›ci w postaci wspÃ³lnego wykorzystywania wiedzy miÄ™dzy zadaniami.\nPrzykÅ‚adowe zadanie: ZaÅ‚Ã³Å¼my, Å¼e mamy zbiÃ³r danych dotyczÄ…cy zakupÃ³w klientÃ³w w sklepie internetowym. Dla kaÅ¼dego klienta mamy informacje o rÃ³Å¼nych aspektach zakupÃ³w, takich jak czas dostawy, Å‚atwoÅ›Ä‡ obsÅ‚ugi strony, jakoÅ›Ä‡ produktÃ³w itp. Chcemy stworzyÄ‡ model, ktÃ³ry jednoczeÅ›nie przewiduje dwie zmienne wynikowe: jakoÅ›Ä‡ obsÅ‚ugi klienta (skala jakoÅ›ciowa, np. â€œNiskaâ€, â€œÅšredniaâ€, â€œWysokaâ€) oraz caÅ‚kowity wydatek klienta (zmienna iloÅ›ciowa, np. kwota zakupÃ³w).\nModele hierarchiczne.\nW niektÃ³rych przypadkach, szczegÃ³lnie gdy mamy hierarchiÄ™ zmiennych wynikowych, modele te mogÄ… byÄ‡ budowane w sposÃ³b hierarchiczny. PrzykÅ‚adowo, w problemie klasyfikacji obrazÃ³w z hierarchiÄ… kategorii (na przykÅ‚ad rozpoznawanie gatunkÃ³w zwierzÄ…t), model moÅ¼e byÄ‡ zaprojektowany do rozpoznawania zarÃ³wno ogÃ³lnych, jak i bardziej szczegÃ³Å‚owych kategorii.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Modele z wieloma wyjÅ›ciami</span>"
    ]
  },
  {
    "objectID": "multi_target_models.html#rÃ³Å¼nie-podejÅ›cia-do-modelowania-z-wieloma-wyjÅ›ciami",
    "href": "multi_target_models.html#rÃ³Å¼nie-podejÅ›cia-do-modelowania-z-wieloma-wyjÅ›ciami",
    "title": "2Â  Modele z wieloma wyjÅ›ciami",
    "section": "2.2 RÃ³Å¼nie podejÅ›cia do modelowania z wieloma wyjÅ›ciami",
    "text": "2.2 RÃ³Å¼nie podejÅ›cia do modelowania z wieloma wyjÅ›ciami\nIstniejÄ… dwa ogÃ³lne podejÅ›cia do rozwiÄ…zywania problemÃ³w wieloetykietowych: transformacja problemu i adaptacja algorytmu. Transformacja problemu polega na manipulowaniu zbiorem danych w taki sposÃ³b, Å¼e problem wieloetykietowy staje siÄ™ jednym lub kilkoma problemami jednoetykietowymi (Tawiah i Sheng 2013). Adaptacja algorytmu polega na tym, Å¼e sam algorytm jest w stanie poradziÄ‡ sobie bezpoÅ›rednio z problemem wieloetykietowym. Okazuje siÄ™, Å¼e wiele, choÄ‡ nie wszystkie, metody adaptacji algorytmÃ³w metod adaptacji algorytmÃ³w w rzeczywistoÅ›ci wykorzystuje transformacjÄ™ problemu (Tsoumakas i Katakis 2007).\n\n2.2.1 Transformacja problemu\nTechniki te przewidujÄ… stworzenie indywidualnego modelu dla kaÅ¼dego celu, a nastÄ™pnie poÅ‚Ä…czenie oddzielnych modeli w celu uzyskania ogÃ³lnej prognozy. Metody transformacji problemÃ³w okazaÅ‚y siÄ™ lepsze od metod adaptacji algorytmÃ³w pod wzglÄ™dem dokÅ‚adnoÅ›ci (Spyromitros-Xioufis i in. 2016). Co wiÄ™cej, podstawowa zasada sprawia, Å¼e metody transformacji problemu sÄ… niezaleÅ¼ne od algorytmu. W konsekwencji, moÅ¼na je Å‚atwo dostosowaÄ‡ do danego problemu poprzez zastosowanie odpowiednich bazowych metod uczÄ…cych. Punkt ten ma rÃ³wnieÅ¼ szczegÃ³lne znaczenie dla modeli typu ensemble, ktÃ³re Å‚Ä…czÄ… oszacowania z wielu potencjalnie rÃ³Å¼nych algorytmÃ³w w ostatecznÄ… prognozÄ™. Niedawno Spyromitros-Xioufis i in. (2016) zaproponowali rozszerzenie znanych metod transformacji klasyfikacji wieloetykietowej, aby poradziÄ‡ sobie z problemem regresji wielowynikowej i modelowaÄ‡ zaleÅ¼noÅ›ci miÄ™dzy celami. W szczegÃ³lnoÅ›ci wprowadzili oni dwa nowe podejÅ›cia do regresji wielocelowej, skÅ‚adanie regresorÃ³w wielocelowych i Å‚aÅ„cuchy regresorÃ³w, inspirowane popularnymi i skutecznymi podejÅ›ciami do klasyfikacji wieloznaczeniowej.\nPodstawowÄ… koncepcjÄ… w metodach transformacji problemÃ³w jest wykorzystanie poprzednich modeli do nowego przewidywania poprzez rozszerzonÄ… przestrzeÅ„ cech (Borchani i in. 2015). Stacked generalization to podejÅ›cie do meta-uczenia, ktÃ³re wykorzystuje dane wyjÅ›ciowe wczeÅ›niej wyuczonych modeli do uczenia siÄ™ nowego modelu. W zwiÄ…zku z tym poczÄ…tkowe dane wyjÅ›ciowe modelu sÄ… traktowane jako nowe cechy i sÄ… ukÅ‚adane w stos do poczÄ…tkowego wektora cech przed ponownym uczeniem. W oryginalnym sformuÅ‚owaniu przewidziano tylko dwuetapowÄ… procedurÄ™, tj. poczÄ…tkowe modele wyuczone z poczÄ…tkowego wektora cech odpowiadajÄ… odpowiednio modelom i danym poziomu 0, a powiÄ™kszony wektor cech i ponownie wyuczony model sÄ… okreÅ›lane odpowiednio jako dane poziomu 1 i generalizator. JednakÅ¼e, rozsÄ…dnie rzecz biorÄ…c, ten proces ukÅ‚adania pojedynczego celu (ang. Single-target Stacking - STS) moÅ¼e byÄ‡ rÃ³wnieÅ¼ przeprowadzany w wielu iteracjach. Aby wdroÅ¼yÄ‡ tÄ™ zasadÄ™ dla problemÃ³w z wieloma celami, w ktÃ³rych kodowane sÄ… rÃ³wnieÅ¼ moÅ¼liwe korelacje miÄ™dzy zmiennymi docelowymi, wprowadzono koncepcjÄ™ ukÅ‚adania wielu celÃ³w (ang. Multi-target Stacking - MTS) (Borchani i in. 2015). Analogicznie do STS, szkolenie modelu MTS moÅ¼na uznaÄ‡ za procedurÄ™ dwuetapowÄ…. W pierwszym etapie uczone sÄ… niezaleÅ¼ne modele dla kaÅ¼dej zmiennej docelowej. NastÄ™pnie uczone sÄ… meta-modele dla kaÅ¼dej zmiennej docelowej z rozszerzonymi wektorami cech, ktÃ³re zawierajÄ… poczÄ…tkowe wektory cech, a takÅ¼e oszacowania poziomu 0 pozostaÅ‚ych zmiennych docelowych. Podobne pomysÅ‚y byÅ‚y rÃ³wnieÅ¼ stosowane w kontekÅ›cie modeli zespoÅ‚owych, tj. uczenia siÄ™ kilku modeli poziomu 0 dla kaÅ¼dej zmiennej docelowej, ktÃ³re sÄ… Å‚Ä…czone w procedurze uogÃ³lniania poziomu 1 dla wielu zmiennych docelowych (Santana i in. 2020).\n\n2.2.1.1 Single-target stacking\nMetoda ta jest stosowana przede wszystkim z zadaniach regresyjnych z wieloma wyjÅ›ciami. RozwaÅ¼my zbiÃ³r danych \\(D = \\left\\{\\left(\\mathbf{x}^{(1)}, \\mathbf{y}^{(1)}\\right), \\ldots, \\left(\\mathbf{x}^{(N)}, \\mathbf{y}^{(N)}\\right)\\right\\}\\), skÅ‚adajÄ…cy siÄ™ z \\(N\\) obserwacji, ktÃ³re sÄ… realizacjami zmiennych losowych \\(X_1,\\ldots,X_m, Y_1,\\ldots,Y_d\\). Zatem kaÅ¼de wejÅ›cie do modelu jest charakteryzowane przez \\(m\\) zmiennych \\(\\mathbf{x}{(l)}=\\left(x_1^{(l)},\\ldots, x_j^{(l)}, \\ldots, x_m^{(l)} \\right)\\) oraz \\(d\\) odpowiadajÄ…cych im wyjÅ›Ä‡ \\(\\mathbf{y}{(l)}=\\left(y_1^{(l)},\\ldots, y_i^{(l)}, \\ldots, y_d^{(l)} \\right)\\), gdzie \\(l\\in\\{1,\\ldots,N\\}, j\\in\\{1,\\ldots,m\\}, i\\in\\{1,\\ldots,d\\}\\). Naszym celem w zadaniu regresyjnym (MTR - Multi-target Regression) jest nauczenie takiego modelu \\(h\\), ktÃ³ry przeksztaÅ‚ca \\(\\mathbf{x}\\) w \\(\\mathbf{y}\\).\nW podejÅ›ciu STS w pierwszym kroku budowanych jest \\(d\\) niezaleÅ¼nych modeli przewidujÄ…cych pojedyncze wyjÅ›cie. Po tej czynnoÅ›ci meta-model jest trenowany na zbiorze \\(D_i'\\), ktÃ³ry jest wzbogaconym zbiorem \\(D_i\\) o predykcje zmiennej \\(Y_i\\), czyli\n\\[\nD_i'=\\left\\{\\left(\\mathbf{x}'^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}'^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}'^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_i^{(l)} \\right)\\). W zaleÅ¼noÅ›ci czy rozpatrujemy algorytm STS niekumulatywny, czy kumulatywny, drugi krok iteracji wyglÄ…da nieco inaczej:\n\nniekumulatywny\n\\[\n\\bar{D}_i''=\\left\\{\\left(\\mathbf{x}''^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}''^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}''^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_i'^{(l)} \\right)\\)\nkumulatywny\n\\[\n\\bar{\\bar{D}}_i''=\\left\\{\\left(\\mathbf{x}''^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}''^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}''^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_i^{(l)},\\hat{y}_i'^{(l)} \\right)\\).\n\n\n\n\nSingle-target stacking\n\n\n\n\n2.2.1.2 Multi-target stacking\nW przeciwieÅ„stwie do STS, MTS zostaÅ‚ zaprojektowany do dzielenia siÄ™ wiedzÄ… w skorelowanych zmiennych docelowych w ramach procedury Å‚Ä…czenia w stosy. Podobnie, najpierw uczone sÄ… modele pojedynczego celu. NastÄ™pnie tworzony jest zestaw meta-modeli, ktÃ³re zawierajÄ… model dla kaÅ¼dej zmiennej docelowej \\(Y_i,\\) \\(i \\in \\{1, \\ldots, d\\}\\). W ten sposÃ³b uwzglÄ™dniane sÄ… szacunki dotyczÄ…ce pozostaÅ‚ych zmiennych docelowych z pierwszego etapu, tj. model jest uczony z przeksztaÅ‚conego zbioru\n\\[\nD_i'=\\left\\{\\left(\\mathbf{x}'^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}'^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}'^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_1^{(l)},\\ldots,\\hat{y}_d^{(l)} \\right)\\). W metodzie MTS istniejÄ… rÃ³wnieÅ¼ dwa sposoby skÅ‚adania kolejnych iteracji. PrzebiegajÄ… one w podobny sposÃ³b jak w przypadku STS.\n\n\n\nMulti-target stacking\n\n\nIstnieje jeszcze trzecia metoda powszechnie stosowana do predykcji wielowyniowej zwana Regressor Chains lub Classifier Chains w zaleÅ¼noÅ›ci od celu zadania. IdÄ™ dziaÅ‚ania tej metody przedstawiÄ™ na przykÅ‚adzie modelu regresyjnego.\n\n\n2.2.1.3 Regressor Chains\nRC opierajÄ… siÄ™ na idei dopasowywania modeli pojedynczego celu wzdÅ‚uÅ¼ wybranej permutacji, tj. Å‚aÅ„cucha. Najpierw losowana jest permutacja w odniesieniu do zmiennych docelowych. Proces ten moÅ¼na przeprowadziÄ‡ w sposÃ³b losowy (Spyromitros-Xioufis i in. 2016) lub uporzÄ…dkowany (Melki i in. 2017). Wybrana permutacja jest wykorzystywana do zbudowania oddzielnego modelu regresji dla zmiennych docelowych zgodnie z kolejnoÅ›ciÄ… permutacji. Aby wykorzystaÄ‡ tÄ™ strukturÄ™ do MTR, rzeczywiste wartoÅ›ci zmiennych docelowych sÄ… dostarczane do kolejnych modeli podczas uczenia siÄ™ wzdÅ‚uÅ¼ Å‚aÅ„cucha. Na podstawie peÅ‚nego Å‚aÅ„cucha lub wybranego zestawu \\(C = (Y_1,\\ldots,Y_d)\\), pierwszy model jest ograniczony do ustalenia predykcji dla \\(Y_1\\). NastÄ™pnie, kolejno dla \\(Y_i\\) uczone sÄ… modele na podstawie zbioru\n\\[\nD_i'=\\left\\{\\left(\\mathbf{x}'^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}'^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}'^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, y_1^{(l)},\\ldots, y_{i-1}^{(l)} \\right)\\). Ten algorytm ma rÃ³wnieÅ¼ dwie odmiany (niekumulatywnÄ… i kumulatywnÄ…) w zaleÅ¼noÅ›ci od ksztaÅ‚tu kolejnych iteracji.\n\n\n\nRegressor chains\n\n\nPoniewaÅ¼, jak moÅ¼na siÄ™ spodziewaÄ‡ wyniki modelowania w znaczny sposÃ³b zaleÅ¼Ä… od wylosowanej permutacji, to w metodzie zaproponowanej przez Melki i in. (2017) aby uniknÄ…Ä‡ tego efektu buduje siÄ™ \\(k\\) modeli dla rÃ³Å¼nych permutacji i Å‚Ä…czy siÄ™ wyniki w podobny sposÃ³b jak w lasach losowych.\n\n\n\n\n\n\n\n\n\nAdnotacja\n\n\n\nSÅ‚owo komentarza jeÅ›li chodzi o dostÄ™pnoÅ›Ä‡ tych metod w jÄ™zykach programowania. Niestety wspomniane metody w R nie sÄ… zaimplementowane w sposÃ³b, ktÃ³ry pozwalaÅ‚by na bezpieczne uÅ¼ywanie przygotowanych rozwiÄ…zaÅ„. Istnieje kilka wzmianek (na dzieÅ„ dzisiejszy, czyli poczÄ…tek 2024 roku) na ten temat. TwÃ³rcy dwÃ³ch gÅ‚Ã³wnych frameworkÃ³w do uczenia maszynowego, czyli mlr3 oraz tidymodels przygotowujÄ… implementacje tych metod. Dodatkowo istnieje rozwiÄ…zanie w wersji eksperymentalnej mtr-toolkit, ktÃ³re pozwala na wykonanie modelowania z wieloma wyjÅ›ciami, ktÃ³rym moÅ¼na siÄ™ posiÅ‚kowaÄ‡. Na potrzeby klasyfikacji istnieje rÃ³wnieÅ¼ pakiet mldr i ultim, ktÃ³re pozwalajÄ… na uczenie modeli klasyfikacyjnymi z wieloma wyjÅ›ciami.\nNiestety w przypadku Python-a nie jest duÅ¼o lepiej. Wprawdzie w pakiecie scikit-learn istniejÄ… implementacje pozwalajÄ…ce na predykcje wielowyjÅ›ciowe w obu typach zadaÅ„ poprzez MultiOutputRegressor i MultiOutputClassifier, ale dokonujÄ… one predykcji naiwnej poprzez zÅ‚oÅ¼enie w listÄ™ wynikÃ³w pojedynczych modeli dla kaÅ¼dej zmiennej. Nieco lepiej sprawa wyglÄ…da w przypadku metod Å‚aÅ„cuchowych, poniewaÅ¼ zarÃ³wno dla klasyfikacji, jak i regresji sÄ… metody to realizujÄ…ce (ClassifierChain i RegressorChain).\n\n\n\n\n\n2.2.2 Adaptacja algorytmu\nProstota podejÅ›cia transformacji problemu sprawia, Å¼e jest ono odpowiednie dla problemÃ³w, w ktÃ³rych jego wady majÄ… niewielki lub Å¼aden wpÅ‚yw - jednak dla zÅ‚oÅ¼onych problemÃ³w podejÅ›cie adaptacji algorytmu moÅ¼e okazaÄ‡ siÄ™ bardziej efektywne. Dodatkowo, dowody empiryczne sugerujÄ…, Å¼e uczenie siÄ™ powiÄ…zanych zadaÅ„ jednoczeÅ›nie, a nie niezaleÅ¼nie, moÅ¼e poprawiÄ‡ wyniki predykcyjne (Evgeniou i Pontil 2004). Z drugiej strony, jeÅ›li zadania sÄ… bardzo odmienne, wydajnoÅ›Ä‡ predykcyjna moÅ¼e ucierpieÄ‡, gdy zadania sÄ… uczone razem, a nie niezaleÅ¼nie (Faddoul i in. 2010). W zwiÄ…zku z tym moÅ¼emy wyciÄ…gnÄ…Ä‡ nastÄ™pujÄ…ce wnioski:\n\njeÅ›li zadania, ktÃ³rych nasz predyktor ma siÄ™ nauczyÄ‡, sÄ… powiÄ…zane, powinniÅ›my dÄ…Å¼yÄ‡ do znalezienia odpowiedniej metody adaptacji algorytmu;\njeÅ›li zadania, ktÃ³rych chcemy siÄ™ nauczyÄ‡, nie sÄ… powiÄ…zane, powinniÅ›my zamiast tego dÄ…Å¼yÄ‡ do znalezienia odpowiedniej metody transformacji problemu.\n\nWreszcie, powinniÅ›my wziÄ…Ä‡ pod uwagÄ™ rozmiar problemu i zdaÄ‡ sobie sprawÄ™, Å¼e gdy zadania sÄ… niepowiÄ…zane, istnieje potencjalny kompromis miÄ™dzy efektywnoÅ›ciÄ… czasowÄ… a wydajnoÅ›ciÄ… predykcyjnÄ… przy wyborze metody transformacji problemu lub metody adaptacji algorytmu. W przypadku niepowiÄ…zanych ze sobÄ… zadaÅ„, metody transformacji problemu mogÄ… zwiÄ™kszaÄ‡ skutecznoÅ›Ä‡ predykcyjnÄ…, ale zmniejszaÄ‡ wydajnoÅ›Ä‡ czasowÄ… w przypadku duÅ¼ych problemÃ³w i odwrotnie.\nNiestety tej metody nie da siÄ™ zastosowaÄ‡ do kaÅ¼dego typu modelu. Rodzina modeli, ktÃ³rych adaptacja jest wykonana caÅ‚y czas roÅ›nie. Adaptacja modelu polega na przeksztaÅ‚ceniu go do postaci, w ktÃ³rej da siÄ™ wykonaÄ‡ predykcjÄ™ dla wielu wyjÅ›Ä‡. WÅ›rÃ³d modeli, ktÃ³rych wersje native multi-target istniejÄ… naleÅ¼y wymieniÄ‡:\n\nregresja wieloraka (Izenman 1975)\nkNN\ndrzewo decyzyjne (Struyf i DÅ¾eroski 2006)\nlas losowy (Kocev i in. 2013)\nbagging (Kocev i in. 2013)\ngradient boosting (Zhang i Jung, b.d.; Faddoul i in. 2012)\nSVM (Xu, Guo, i Wang 2013; Vazquez i Walter 2003)\nno i oczywiÅ›cie sieci neuronowe.\n\nNie sposÃ³b przedstawiÄ‡ w jaki sposÃ³b wprowadzone zostaÅ‚y zmiany we wszystkich algorytmach. SkupiÄ™ siÄ™ jednak na pokazaniu adaptacji drzew decyzyjnych do predykcji wielu wyjÅ›Ä‡ jednoczeÅ›nie, poniewaÅ¼ jest to meta-model modeli takich jak lasy losowe, bagging czy boosting.\n\n2.2.2.1 Adaptacja klasyfikacyjnego drzewa decyzyjnego\nFaddoul i in. (2012) zaproponowali zmodyfikowanÄ… wersjÄ™ algorytmu drzewa decyzyjnego C4.5 (Quinlan 1993), ktÃ³ra bezpoÅ›rednio obsÅ‚uguje problemy klasyfikacji wielowyjÅ›ciowej. Zmodyfikowana wersja (nazwana MT-DT) rÃ³Å¼ni siÄ™ od standardowej implementacji C4.5 w dwÃ³ch krytycznych aspektach: kryteriach podziaÅ‚u wÄ™zÅ‚Ã³w i procesie decyzyjnym. Faddoul i in. (2012) proponujÄ… trzy rÃ³Å¼ne podejÅ›cia do Å‚Ä…czenia wielu miar przyrostu informacji w jednÄ… miarÄ™: wspÃ³lny przyrost informacji, suma niewaÅ¼ona i maksymalny przyrost informacji. WspÃ³lny przyrost informacyjny jest definiowany przy uÅ¼yciu konkatenacji wszystkich poszczegÃ³lnych zadaÅ„, tj. wzglÄ™dnej rÃ³Å¼nicy w entropii mierzonej we wszystkich zadaniach decyzyjnych. Autorzy pokazujÄ…, Å¼e niewaÅ¼ona suma (RÃ³wnanieÂ 2.1) indywidualnych przyrostÃ³w informacyjnych wszystkich zadaÅ„ jest rÃ³wnowaÅ¼na wspÃ³lnemu przyrostowi informacyjnemu.\n\\[\nIG_U=\\sum_YIG_Y\n\\tag{2.1}\\]\nMaksymalny przyrost informacyjny, zgodnie z propozycjÄ… autorÃ³w jest definiowany po prostu jako maksymalny przyrost informacyjny wszystkich zadaÅ„:\n\\[\nIG_M=\\max_YIG_Y\n\\tag{2.2}\\]\nBadania eksperymentalne pokazaÅ‚y, Å¼e maksymalny przyrost informacyjny wykorzystany do budowania reguÅ‚ podziaÅ‚u, charakteryzuje siÄ™ wyÅ¼szym poziomem dopasowania modeli, niÅ¼ przy zastosowaniu \\(IG_U\\) i \\(IG_J\\).\nW przypadku klasyfikacji z jednÄ… etykietÄ…, algorytm indukcji drzewa decyzyjnego (taki jak C4.5) rekurencyjnie dzieli wÄ™zÅ‚y, dodajÄ…c (zazwyczaj dwa) elementy potomne, aÅ¼ moÅ¼liwe jest utworzenie liÅ›cia takiego, Å¼e znaczna wiÄ™kszoÅ›Ä‡ (lub nawet wszystkie) jego przykÅ‚adowych instancji naleÅ¼y do tej samej klasy. W przypadku wielu wyjÅ›Ä‡, indukcja drzewa niekoniecznie jest tak prosta. RozwaÅ¼my problem klasyfikacji wielowyjÅ›ciowej z dwoma wyjÅ›ciami binarnymi \\(\\nu_1\\) i \\(\\nu_2\\); moÅ¼liwe jest, Å¼e po \\(t\\) podziaÅ‚ach, wÄ™zeÅ‚ zawiera tylko wartoÅ›ci pozytywne dla \\(\\nu_1\\), ale mieszankÄ™ wartoÅ›ci pozytywnych i negatywnych dla \\(\\nu_2\\) - stÄ…d, podczas konstruowania drzew decyzyjnych dla wielu jednoczesnych zadaÅ„, naleÅ¼y pamiÄ™taÄ‡, Å¼e proces decyzyjny dla pewnego zadania moÅ¼e wymagaÄ‡ krÃ³tszej Å›cieÅ¼ki decyzyjnej niÅ¼ inne zadania w ramach tego samego problemu wielowyjÅ›ciowego. MT-DT radzi sobie z tym, sprawdzajÄ…c w kaÅ¼dym wÄ™Åºle, czy moÅ¼liwe jest utworzenie wÄ™zÅ‚a terminalnego dla ktÃ³regokolwiek z zadaÅ„ - w powyÅ¼szym przykÅ‚adzie spowodowaÅ‚oby to utworzenie drzewa, w ktÃ³rym wewnÄ™trzny wÄ™zeÅ‚ \\(t_1\\) jest oznaczony jako wÄ™zeÅ‚ zatrzymania dla \\(\\nu_1\\), oznaczony klasÄ… pozytywnÄ…. PoniewaÅ¼ celem jest prognozowanie dla obu wyjÅ›Ä‡ binarnych, \\(t_1\\) nie jest wÄ™zÅ‚em liÅ›cia - zamiast tego rekurencyjne dzielenie jest kontynuowane od \\(t_1\\), aÅ¼ do znalezienia wÄ™zÅ‚a \\(t_2\\) takiego, Å¼e \\(t_2\\) jest wystarczajÄ…co czysty w odniesieniu do \\(\\nu_2\\), aby moÅ¼na byÅ‚o utworzyÄ‡ reguÅ‚Ä™ klasyfikacji dla drugiego zadania binarnego. W tym momencie wÄ™zÅ‚y decyzyjne (wÄ™zÅ‚y wewnÄ™trzne lub liÅ›cie) zostaÅ‚y znalezione dla wszystkich wynikÃ³w (\\(\\nu_1\\) i \\(\\nu_2\\)), a algorytm indukcji drzewa rekurencyjnego moÅ¼e zostaÄ‡ zakoÅ„czony.\nNic dziwnego, Å¼e klasyfikacja przy uÅ¼yciu juÅ¼ zbudowanego modelu MT-DT przebiega wedÅ‚ug tej samej formuÅ‚y, co jego indukcja - podczas przechodzenia przez drzewo kaÅ¼dy wÄ™zeÅ‚ jest sprawdzany w celu ustalenia, czy moÅ¼na podjÄ…Ä‡ decyzjÄ™ dla ktÃ³regokolwiek z aktualnie nierozstrzygniÄ™tych zadaÅ„. W przykÅ‚adzie \\(\\nu_1\\), \\(\\nu_2\\), klasyfikacja zostanie dokonana dla \\(\\nu_1\\) w wÄ™Åºle \\(t_1\\), poniewaÅ¼ jest on oznaczony jako wÄ™zeÅ‚ zatrzymania dla \\(\\nu_1\\); nastÄ™pnie przejÅ›cie jest kontynuowane do momentu napotkania \\(t_2\\) i klasyfikacja moÅ¼e zostaÄ‡ dokonana dla \\(\\nu_2\\). W tym momencie wszystkie wyjÅ›cia zostaÅ‚y sklasyfikowane, a przechodzenie moÅ¼e siÄ™ zakoÅ„czyÄ‡, zwracajÄ…c dwie wartoÅ›ci w \\(t_1\\) i \\(t_2\\) jako klasyfikacje odpowiednio dla \\(\\nu_1\\) i \\(\\nu_2\\).\n\n\n2.2.2.2 Adaptacja regresyjnego drzewa decyzyjnego\nSegal (1992) zaproponowaÅ‚ rozwiÄ…zanie dla drzew regresyjnych o wielu wyjÅ›ciach (MRT), ktÃ³re sÄ… w stanie przewidywaÄ‡ wyniki dla wielu powiÄ…zanych zadaÅ„ regresyjnych; te wielowyjÅ›ciowe drzewa regresyjne sÄ… oparte na funkcji podziaÅ‚u najmniejszych kwadratÃ³w zaproponowanej w ramach CART (Breiman i in. 2017). W przypadku drzewa regresyjnego o jednej odpowiedzi celem jest minimalizacja nastÄ™pujÄ…cej funkcji celu:\n\\[\n\\phi(t) = SS(t)-SS(t_L)-SS(t_R)\n\\]\ngdzie \\(SS(t)\\) jest zdefiniowana nastÄ™pujÄ…co\n\\[\nSS(t) = \\sum_{i\\in t}(y_i-\\bar{y}(t))^2.\n\\]\nSegal (1992) dodaÅ‚ waÅ¼enie macierzÄ… kowariancji do bÅ‚Ä™du kwadratowego, co prowadzi algorytm drzewa do tworzenia wÄ™zÅ‚Ã³w potomnych, ktÃ³re reprezentujÄ… jednorodne klastry w odniesieniu do zestawu odpowiedzi wyjÅ›ciowych:\n\\[\nSS(t) = \\sum_{i\\in t}(y_i-\\bar{y}(t))'V^{-1}(t)(y_i-\\bar{y}(t)),\n\\]\ngdzie \\(V(t)\\) oznacza macierz kowariancji w wÄ™Åºle \\(t\\).\n\n\n2.2.2.3 Adaptacja drzew decyzyjnych do realizacji obu zadaÅ„\nJak wspomniano wczeÅ›niej, jednÄ… z kluczowych motywacji do podejmowania prÃ³b rozwiÄ…zywania problemÃ³w rozpoznawania wzorcÃ³w z wieloma wyjÅ›ciami przy uÅ¼yciu metod adaptacji algorytmÃ³w jest oczekiwanie, Å¼e pojedynczy model wytrenowany na zestawie powiÄ…zanych zadaÅ„ wykaÅ¼e poprawÄ™ wydajnoÅ›ci predykcyjnej w porÃ³wnaniu do zestawu indywidualnych modeli, z ktÃ³rych kaÅ¼dy zostaÅ‚ wytrenowany na pojedynczym zadaniu. Rodzi to pytanie: co jeÅ›li problem wielowynikowy zawiera zarÃ³wno zadania klasyfikacji, jak i regresji? JeÅ›li zadania sÄ… niepowiÄ…zane, rozwiÄ…zanie takiego wspÃ³lnego problemu klasyfikacyjno-regresyjnego nie musi byÄ‡ trudniejsze niÅ¼ szkolenie zestawu klasyfikatorÃ³w i regresorÃ³w dla poszczegÃ³lnych zadaÅ„; jeÅ›li jednak zadania sÄ… powiÄ…zane, oczekujemy, Å¼e metoda adaptacji algorytmu zapewni lepsze wyniki pod wzglÄ™dem wydajnoÅ›ci predykcyjnej.\nGlocker i in. (2012) zaproponowaÅ‚ algorytm indukcji drzewa, ktÃ³ry jednoczeÅ›nie rozwiÄ…zuje jedno zadanie klasyfikacji i jedno zadanie regresji. Podobnie jak MT-DT i MRT, wspÃ³lne drzewo klasyfikacyjno-regresyjne (JCRT) rozwiÄ…zuje wiele jednoczesnych zadaÅ„ predykcji poprzez modyfikacjÄ™ funkcji podziaÅ‚u wÄ™zÅ‚a w kroku indukcyjnym i oznaczenie wÄ™zÅ‚Ã³w koÅ„cowych odpowiednimi wartoÅ›ciami dla kaÅ¼dego zadania. Ze wzglÄ™du na charakter wspÃ³lnych problemÃ³w klasyfikacyjno-regresyjnych, zmodyfikowana funkcja podziaÅ‚u jest wymagana do jednoczesnego uwzglÄ™dnienia bÅ‚Ä™du zarÃ³wno czÄ™Å›ci klasyfikacyjnej, jak i regresyjnej. Funkcja podziaÅ‚u zaproponowana przez Glocker i in. (2012) wykorzystuje funkcjÄ™ entropii skÅ‚adajÄ…cÄ… siÄ™ z trzech czÄ™Å›ci:\n\npo pierwsze, entropia Shannona jest obliczana dla czÄ™Å›ci klasyfikacji;\npo drugie, waÅ¼ona entropia rÃ³Å¼nicowa jest obliczana dla czÄ™Å›ci regresji;\npo trzecie, ze wzglÄ™du na fakt, Å¼e entropia Shannona i entropia rÃ³Å¼nicowa istniejÄ… w rÃ³Å¼nych zakresach, stosuje siÄ™ krok normalizacji w celu poÅ‚Ä…czenia dwÃ³ch entropii. Entropia Shannona jest obliczana tak, jak opisano wczeÅ›niej:\n\n\\[\nH_c(t) = \\sum_{c\\in C}p(c|x)\\log p(c|x).\n\\]\nMiara entropii rÃ³Å¼niczkowej stosowana przez Glocker i in. (2012) dla regresyjnej czÄ™Å›ci problemu jest obliczana w podobny sposÃ³b, z dwiema kluczowymi rÃ³Å¼nicami:\n\nzamiast sumowania prawdopodobieÅ„stw wartoÅ›ci nominalnych, entropia jest definiowana przez rÃ³Å¼niczkÄ™ funkcji prawdopodobieÅ„stwa wyjÅ›cia o wartoÅ›ci rzeczywistej;\ndodatkowo funkcja prawdopodobieÅ„stwa jest waÅ¼ona w klasach:\n\n\\[\nH_{r|c}(t) = \\sum_{c\\in C}p(c|x)\\int_{r\\in \\mathbb{R}^n}-p(r|c,x)\\log p(r|c,x)dr.\n\\]\nNastÄ™pnie dokonywana jest normalizacja ze wzglÄ™du na oba zadania, gdzie punktem odniesienie jest entropia w korzeniu:\n\\[\nH(t) = \\frac12\\left(\\frac{H_c(t)}{H_c(t_0)}+\\frac{H_{r|c}(t)}{H_{r|c}(t_0)}\\right).\n\\]\n\n\n\n\n\n\nAdnotacja\n\n\n\nJedyne implementacje, ktÃ³re znalazÅ‚em dla obu jÄ™zykÃ³w programowania (R i Python) dotyczyÅ‚y lasÃ³w losowych. W R pakiet nazywa siÄ™ randomForestSRC, a w Pythonie morfist. PozwalajÄ… one zarÃ³wno na wykonywanie wielowyjÅ›ciowych zadaÅ„ klasyfikacyjnych i regresyjnych, jak rÃ³wnieÅ¼ zadaÅ„ mieszanych. OczywiÅ›cie wspomniane wyÅ¼ej typy zadaÅ„ moÅ¼na realizowaÄ‡ przy uÅ¼yciu sieci neuronowych w obu jÄ™zykach programowania.\n\n\n\n\n\n\nBorchani, Hanen, Gherardo Varando, Concha Bielza, i Pedro LarraÃ±aga. 2015. â€A Survey on Multi-Output Regressionâ€. WIREs Data Mining and Knowledge Discovery 5 (5): 216â€“33. https://doi.org/10.1002/widm.1157.\n\n\nBreiman, Leo, J. H. Friedman, Richard A. Olshen, i Charles J. Stone. 2017. Classification and Regression Trees. Routledge. http://search.ebscohost.com/login.aspx?direct=true&db=edsebk&AN=1619230&lang=pl&site=eds-live&scope=site.\n\n\nEvgeniou, Theodoros, i Massimiliano Pontil. 2004. â€Regularized multiâ€“task learningâ€. Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, sierpieÅ„. https://doi.org/10.1145/1014052.1014067.\n\n\nFaddoul, Jean Baptiste, Boris Chidlovskii, RÃ©mi Gilleron, i Fabien Torre. 2012. â€Learning multiple tasks with boosted decision treesâ€. W Proceedings of the 2012th European Conference on Machine Learning and Knowledge Discovery in Databases - Volume Part I, 681â€“96. ECMLPKDDâ€™12. Springer-Verlag.\n\n\nFaddoul, Jean Baptiste, Boris Chidlovskii, Fabien Torre, i Remi Gilleron. 2010. â€Boosting Multi-Task Weak Learners with Applications to Textual and Social Dataâ€. W 2010 Ninth International Conference on Machine Learning and Applications, 367â€“72. IEEE. https://doi.org/10.1109/ICMLA.2010.61.\n\n\nGlocker, Ben, Olivier Pauly, Ender Konukoglu, i Antonio Criminisi. 2012. â€Joint Classification-Regression Forests for Spatially Structured Multi-object Segmentationâ€. W Computer Vision â€“ ECCV 2012, zredagowane przez Andrew Fitzgibbon, Svetlana Lazebnik, Pietro Perona, Yoichi Sato, i Cordelia Schmid, 7575:870â€“81. Springer Berlin Heidelberg. http://link.springer.com/10.1007/978-3-642-33765-9_62.\n\n\nIzenman, Alan Julian. 1975. â€Reduced-rank regression for the multivariate linear modelâ€. Journal of multivariate analysis 5 (2): 248â€“64.\n\n\nKocev, Dragi, Celine Vens, Jan Struyf, i SaÅ¡o DÅ¾eroski. 2013. â€Tree ensembles for predicting structured outputsâ€. Pattern Recognition 46 (3): 817â€“33. https://doi.org/10.1016/j.patcog.2012.09.023.\n\n\nMelki, Gabriella, Alberto Cano, Vojislav Kecman, i SebastiÃ¡n Ventura. 2017. â€Multi-Target Support Vector Regression via Correlation Regressor Chainsâ€. Information Sciences 415â€“416 (listopad): 53â€“69. https://doi.org/10.1016/j.ins.2017.06.017.\n\n\nQuinlan, J Ross. 1993. C4. 5: Programs for Machine Learning. Morgan Kaufmann.\n\n\nSantana, Everton Jose, Felipe Rodrigues dos Santos, Saulo Martiello Mastelini, Fabio Luiz Melquiades, i Sylvio Barbon Jr. 2020. â€Improved Prediction of Soil Properties with Multi-Target Stacked Generalisation on EDXRF Spectraâ€. arXiv preprint arXiv:2002.04312. https://arxiv.org/abs/2002.04312.\n\n\nSegal, Mark Robert. 1992. â€Tree-Structured Methods for Longitudinal Dataâ€. Journal of the American Statistical Association 87 (418): 407â€“18. https://doi.org/10.2307/2290271.\n\n\nSpyromitros-Xioufis, Eleftherios, Grigorios Tsoumakas, William Groves, i Ioannis Vlahavas. 2016. â€Multi-Target Regression via Input Space Expansion: Treating Targets as Inputsâ€. Machine Learning 104 (1): 55â€“98. https://doi.org/10.1007/s10994-016-5546-z.\n\n\nStruyf, Jan, i SaÅ¡o DÅ¾eroski. 2006. â€Constraint Based Induction of Multi-objective Regression Treesâ€. W Knowledge Discovery in Inductive Databases, zredagowane przez Francesco Bonchi i Jean-FranÃ§ois Boulicaut, 222â€“33. Lecture Notes w Computer Science. Springer. https://doi.org/10.1007/11733492_13.\n\n\nTawiah, Clifford, i Victor Sheng. 2013. â€Empirical Comparison of Multi-Label Classification Algorithmsâ€. W Proceedings of the AAAI Conference on Artificial Intelligence, 27:1645â€“46.\n\n\nTsoumakas, Grigorios, i Ioannis Katakis. 2007. â€Multi-Label Classification: An Overviewâ€. International Journal of Data Warehousing and Mining (IJDWM) 3 (3): 1â€“13.\n\n\nVazquez, Emmanuel, i Eric Walter. 2003. â€Multi-Output Suppport Vector Regressionâ€. IFAC Proceedings Volumes, 13th IFAC Symposium on System Identification (SYSID 2003), Rotterdam, The Netherlands, 27-29 August, 2003, 36 (16): 1783â€“88. https://doi.org/10.1016/S1474-6670(17)35018-8.\n\n\nXu, Yitian, Rui Guo, i Laisheng Wang. 2013. â€A Twin Multi-Class Classification Support Vector Machineâ€. Cognitive Computation 5 (4): 580â€“88. https://doi.org/10.1007/s12559-012-9179-7.\n\n\nZhang, Zhendong, i Cheolkon Jung. b.d. â€GBDT-MO: Gradient Boosted Decision Trees for Multiple Outputsâ€. https://doi.org/10.48550/arXiv.1909.04373.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Modele z wieloma wyjÅ›ciami</span>"
    ]
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "3Â  PrzykÅ‚ady - metody klasyczne",
    "section": "",
    "text": "3.1 PrzykÅ‚ad 1\nNajpierw sformuÅ‚ujemy problem badawczy wymagajÄ…cy zastosowania modeli z wieloma wyjÅ›ciami.\nKod\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import make_regression\nKod\n# generowanie danych do zadania\nX, y = make_regression(n_samples=700, n_features=10, n_informative = 8, n_targets=3, random_state=4)\nKod\n# Å‚Ä…czenie ich w ramki danych\nX_df = pd.DataFrame(i for i in X)\nX_df.columns = [\"X\"+ str(i) for i in range(1,11)]\ny_df = pd.DataFrame(i for i in y)\ny_df.columns = [\"y\"+str(i) for i in range(1,4)]\n\ndf = pd.concat([X_df,y_df], axis=1)\ndf.head()\n\n\n\n\n\n\n\n\n\nX1\nX2\nX3\nX4\nX5\nX6\nX7\nX8\nX9\nX10\ny1\ny2\ny3\n\n\n\n\n0\n-0.547331\n0.426522\n-1.693585\n-0.740282\n0.277445\n-1.910679\n-0.320635\n1.449172\n-0.469619\n0.371273\n-92.924393\n-116.819352\n-32.117311\n\n\n1\n2.314630\n-0.936016\n-1.833034\n-0.394507\n-0.902981\n-1.089381\n1.005442\n-0.351289\n1.218223\n0.350258\n88.577211\n182.003040\n67.579488\n\n\n2\n-0.025423\n0.684189\n1.208964\n1.325672\n0.328946\n-0.354083\n-0.566556\n0.671359\n-0.560768\n0.327379\n115.652472\n63.462207\n43.519697\n\n\n3\n-0.044533\n0.603030\n-1.495716\n-0.507870\n-0.268485\n-0.140194\n-0.246658\n-0.758946\n2.567979\n1.808345\n-12.092227\n65.181041\n96.138770\n\n\n4\n2.083679\n0.318852\n-0.080982\n-1.284608\n0.281687\n0.792470\n-0.560598\n-1.368963\n0.718059\n-1.741815\n-18.573726\n-103.219393\n11.559200\nKod\ndf_X_boxplot = pd.melt(X_df)\nsns.boxplot(data = df_X_boxplot, x = \"variable\", y = \"value\")\nplt.show()\nKod\ndf_y_boxplot = pd.melt(y_df)\nsns.boxplot(data = df_y_boxplot, x = \"variable\", y = \"value\")\nplt.show()\nZarÃ³wno zmienne X, jak i y majÄ… zbliÅ¼one rozkÅ‚ady.\nKod\nsns.set_theme(style=\"white\")\ng = sns.PairGrid(y_df, diag_sharey=False)\ng.map_upper(sns.scatterplot, s=7)\ng.map_lower(sns.kdeplot)\ng.map_diag(sns.histplot)\nplt.show()\nJak widaÄ‡ z powyÅ¼szego wykresu zmienne y1,y2,y3 wykazujÄ… pewne wzajemne zaleÅ¼noÅ›ci, dlatego budowa oddzielnych modeli dla kaÅ¼dej ze zmiennych powinna dawaÄ‡ gorsze predykcje niÅ¼ modele wiÄ…Å¼Ä…ce wszystkie zmiennej w jednym modelu. MoÅ¼na teÅ¼ zauwaÅ¼yÄ‡, Å¼e rozkÅ‚ady sÄ… zbliÅ¼one do normalnego.\nKod\ncor = df.corr()\nplt.figure(figsize = (12,10))\nsns.heatmap(cor, \n            xticklabels=cor.columns.values,\n            yticklabels=cor.columns.values,\n            annot = True, fmt = '.2f')\nplt.show()\nJak widaÄ‡ z powyÅ¼szej macierzy korelacji, przynajmniej 8 spoÅ›rÃ³d 10 zmiennych X koreluje istotnie ze zmiennymi y.",
    "crumbs": [
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>PrzykÅ‚ady - metody klasyczne</span>"
    ]
  },
  {
    "objectID": "examples.html#przykÅ‚ad-1",
    "href": "examples.html#przykÅ‚ad-1",
    "title": "3Â  PrzykÅ‚ady - metody klasyczne",
    "section": "",
    "text": "PrzykÅ‚ad 3.1 Dane do zadania wygenerujemy za pomocÄ… funkcji make_regression() z pakietu sklern.dataset1. Wygenerujemy 700 obserwacji z 10 predyktorami i 3 zmiennymi zaleÅ¼nymi.\n1Â Nie znam R-owego odpowiednika",
    "crumbs": [
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>PrzykÅ‚ady - metody klasyczne</span>"
    ]
  },
  {
    "objectID": "examples.html#rozwiÄ…zanie",
    "href": "examples.html#rozwiÄ…zanie",
    "title": "3Â  PrzykÅ‚ady - metody klasyczne",
    "section": "3.2 RozwiÄ…zanie",
    "text": "3.2 RozwiÄ…zanie\nNa potrzeby porÃ³wnania rÃ³Å¼nych rozwiÄ…zaÅ„ zbudujemy nastÄ™pujÄ…ce konfiguracje modeli:\n\ntrzy lasy losowe dla kaÅ¼dej zmiennej y niezaleÅ¼nie;\nmodel lasu losowego z wykorzystaniem reguÅ‚y Regression Chains jako transformacji modelu;\nlas losowy dla trzech zmiennych wynikowych jednoczeÅ›nie (adaptacja modelu)\n\nRozwiÄ…zania te porÃ³wnamy pod wzglÄ™dem dopasowania.\n\n3.2.1 NiezaleÅ¼ne lasy losowe\nFunkcja MultiOutputRegressor naÅ‚oÅ¼ona na model lasu losowego takie rozwiÄ…zanie tworzy.\n\n\nKod\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.multioutput import RegressorChain\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)\n\n\n\n\nKod\nrf_meta = RandomForestRegressor(random_state=4)\nrf_indep = MultiOutputRegressor(rf_meta)\nprint(rf_indep)\n\n\nMultiOutputRegressor(estimator=RandomForestRegressor(random_state=4))\n\n\n\n\nKod\nrf_indep.fit(X_train, y_train)\nr2_indep= rf_indep.score(X_test, y_test)\npred_indep = rf_indep.predict(X_test)\nrmse_indep = mean_squared_error(y_test, pred_indep, squared = False)\n\nprint(f'R2 on test samples: {r2_indep:.2f}')\nprint(f'RMSE on test samples: {rmse_indep:.1f}')\n\n\nR2 on test samples: 0.82\nRMSE on test samples: 71.1\n\n\n\n\n3.2.2 Regressor Chains RF\n\n\nKod\nrf_chains = RegressorChain(rf_meta)\nprint(rf_chains)\n\n\nRegressorChain(base_estimator=RandomForestRegressor(random_state=4))\n\n\n\n\nKod\nrf_chains.fit(X_train, y_train)\nr2_chains= rf_chains.score(X_test, y_test)\npred_chains = rf_chains.predict(X_test)\nrmse_chains = mean_squared_error(y_test, pred_chains, squared = False)\n\nprint(f'R2 on test samples: {r2_chains:.2f}')\nprint(f'RMSE on test samples: {rmse_chains:.1f}')\n\n\nR2 on test samples: 0.80\nRMSE on test samples: 72.5\n\n\n\n\n3.2.3 Adaptacja modelu RF\n\n\nKod\nprint(rf_meta)\n\n\nRandomForestRegressor(random_state=4)\n\n\n\n\nKod\nrf_meta.fit(X_train, y_train)\nr2_meta= rf_meta.score(X_test, y_test)\npred_meta = rf_meta.predict(X_test)\nrmse_meta = mean_squared_error(y_test, pred_meta, squared = False)\n\nprint(f'R2 on test samples: {r2_meta:.2f}')\nprint(f'RMSE on test samples: {rmse_meta:.1f}')\n\n\nR2 on test samples: 0.77\nRMSE on test samples: 78.0\n\n\n\n\n3.2.4 Podsumowanie\nBiorÄ…c pod uwagÄ™ miary dopasowania najlepiej poradziÅ‚ sobie z tym zadaniem model skÅ‚adajÄ…cy siÄ™ z trzech niezaleÅ¼nych modeli RF, potem model RF w wersji Regressor Chains, a najgorzej (o dziwo) radzi sobie z predykcjÄ… model korzystajÄ…cy adaptacji drzew decyzyjnych do wersji wielowyjÅ›ciowej.",
    "crumbs": [
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>PrzykÅ‚ady - metody klasyczne</span>"
    ]
  },
  {
    "objectID": "examples.html#przykÅ‚ad-2",
    "href": "examples.html#przykÅ‚ad-2",
    "title": "3Â  PrzykÅ‚ady - metody klasyczne",
    "section": "3.3 PrzykÅ‚ad 2",
    "text": "3.3 PrzykÅ‚ad 2\nTym razem sformuÅ‚ujemy problem z wieloma wyjÅ›ciami ale klasyfikacyjny i rÃ³wnieÅ¼ dopasujemy trzy wersje modelu lasu losowego:\n\nlasy losowe dla kaÅ¼dej zmiennej y niezaleÅ¼nie;\nmodel lasu losowego z wykorzystaniem reguÅ‚y Classifier Chains jako transformacji modelu\nlas losowy dla wszystkich zmiennych wynikowych jednoczeÅ›nie (adaptacja modelu).\n\nAnalizowany problem bÄ™dzie prawdziwy i bÄ™dzie dotyczyÅ‚ klasyfikacji enzymÃ³w na podstawie cech charakterystycznych substratÃ³w. Pierwszych 31 zmiennych stanowi zmienne objaÅ›niajÄ…ce, a 6 pozostaÅ‚ych zmienne kodujÄ…ce przynaleÅ¼noÅ›Ä‡ do danej grupy enzymÃ³w.\n\n\nKod\ndt = pd.read_csv(\"data/original.csv\", index_col = \"id\")\ndt.head()\n\n\n\n\n\n\n\n\n\nBertzCT\nChi1\nChi1n\nChi1v\nChi2n\nChi2v\nChi3v\nChi4n\nEState_VSA1\nEState_VSA2\n...\nSlogP_VSA3\nVSA_EState9\nfr_COO\nfr_COO2\nEC1\nEC2\nEC3\nEC4\nEC5\nEC6\n\n\nid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC00009\n49.783540\n2.000000\n0.782574\n2.347723\n0.513277\n1.539831\n0.000000\n0.000000\n7.822697\n0.000000\n...\n4.565048\n16.923611\n0\n0\n1\n1\n1\n1\n0\n1\n\n\nC00013\n147.355172\n3.707107\n1.530297\n4.590890\n1.062804\n3.678309\n1.914534\n0.138556\n15.645394\n0.000000\n...\n13.440728\n20.899028\n0\n0\n1\n1\n1\n1\n0\n1\n\n\nC00014\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n6.150546\n...\n0.000000\n0.000000\n0\n0\n1\n1\n1\n1\n0\n1\n\n\nC00017\n172.720106\n4.947265\n2.081214\n2.081214\n1.157830\n1.157830\n0.489278\n0.180980\n12.514062\n12.451936\n...\n9.589074\n35.105740\n1\n1\n0\n1\n1\n0\n0\n0\n\n\nC00022\n72.039100\n2.642734\n1.381855\n1.381855\n0.861339\n0.861339\n0.301176\n0.000000\n11.752550\n0.000000\n...\n9.589074\n25.333333\n1\n1\n1\n1\n1\n1\n0\n1\n\n\n\n\n5 rows Ã— 37 columns\n\n\n\n\n\nKod\ndt.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1039 entries, C00009 to C22220\nData columns (total 37 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   BertzCT            1039 non-null   float64\n 1   Chi1               1039 non-null   float64\n 2   Chi1n              1039 non-null   float64\n 3   Chi1v              1039 non-null   float64\n 4   Chi2n              1039 non-null   float64\n 5   Chi2v              1039 non-null   float64\n 6   Chi3v              1039 non-null   float64\n 7   Chi4n              1039 non-null   float64\n 8   EState_VSA1        1039 non-null   float64\n 9   EState_VSA2        1039 non-null   float64\n 10  ExactMolWt         1039 non-null   float64\n 11  FpDensityMorgan1   1039 non-null   float64\n 12  FpDensityMorgan2   1039 non-null   float64\n 13  FpDensityMorgan3   1039 non-null   float64\n 14  HallKierAlpha      1039 non-null   float64\n 15  HeavyAtomMolWt     1039 non-null   float64\n 16  Kappa3             1039 non-null   float64\n 17  MaxAbsEStateIndex  1039 non-null   float64\n 18  MinEStateIndex     1039 non-null   float64\n 19  NumHeteroatoms     1039 non-null   int64  \n 20  PEOE_VSA10         1039 non-null   float64\n 21  PEOE_VSA14         1039 non-null   float64\n 22  PEOE_VSA6          1039 non-null   float64\n 23  PEOE_VSA7          1039 non-null   float64\n 24  PEOE_VSA8          1039 non-null   float64\n 25  SMR_VSA10          1039 non-null   float64\n 26  SMR_VSA5           1039 non-null   float64\n 27  SlogP_VSA3         1039 non-null   float64\n 28  VSA_EState9        1039 non-null   float64\n 29  fr_COO             1039 non-null   int64  \n 30  fr_COO2            1039 non-null   int64  \n 31  EC1                1039 non-null   int64  \n 32  EC2                1039 non-null   int64  \n 33  EC3                1039 non-null   int64  \n 34  EC4                1039 non-null   int64  \n 35  EC5                1039 non-null   int64  \n 36  EC6                1039 non-null   int64  \ndtypes: float64(28), int64(9)\nmemory usage: 308.5+ KB\n\n\nSprawdzimy na ile niezbalansowane sÄ… poszczegÃ³lne klasy wynikowe.\n\n\nKod\ndt_deps = dt.loc[:,'EC1':'EC6']\ndt_deps = dt_deps.melt()\ndt_deps = dt_deps[dt_deps.value == 1]\nsns.countplot(data = dt_deps, x = 'variable')\n\n\n\n\n\n\n\n\n\nNiestety nie wszystkie klasy wystÄ™pujÄ… jednakowo czÄ™sto i moÅ¼e pojawiÄ‡ siÄ™ zjawisko, Å¼e kombinacja enzymÃ³w bÄ™dzie wystÄ™powaÅ‚a bardzo rzadko (np. raz). Jak widaÄ‡ z poniÅ¼szej tabeli faktycznie tak siÄ™ dzieje. To nie pozwala przeprowadziÄ‡ uczenia. Dlatego musimy poÅ‚Ä…czyÄ‡ pewne klasy enzymÃ³w aby uniemoÅ¼liwiÄ‡ takÄ… sytuacjÄ™.\n\n\nKod\ndt.loc[:,'EC1':'EC6'].value_counts()\n\n\nEC1  EC2  EC3  EC4  EC5  EC6\n1    0    0    0    0    0      178\n0    1    0    0    0    0      136\n1    1    0    0    0    0      112\n0    1    1    0    0    0       90\n     0    1    0    0    0       69\n1    1    0    1    0    0       38\n          1    0    0    0       37\n     0    0    1    0    0       33\n0    0    0    1    0    0       30\n     1    0    1    0    0       27\n               0    1    0       21\n1    0    1    0    0    0       20\n     1    0    0    0    1       19\n               1    0    1       15\n0    0    0    0    1    0       15\n1    1    0    0    1    0       14\n     0    0    0    1    0       12\n0    0    1    1    0    0       12\n          0    0    0    1       11\n1    1    0    1    1    1       11\n0    1    0    0    0    1       10\n          1    1    0    0        9\n1    0    0    1    1    0        8\n     1    1    1    0    1        8\n     0    0    1    0    1        7\n     1    1    0    0    1        7\n     0    0    0    0    1        7\n0    1    1    0    1    0        7\n                    0    1        7\n1    1    1    1    1    0        6\n          0    1    1    0        6\n0    1    0    1    0    1        6\n1    1    1    0    1    0        5\n0    0    0    1    1    0        5\n     1    1    1    1    0        4\n1    1    0    0    1    1        4\n          1    1    0    0        4\n0    0    1    0    0    1        4\n                    1    0        3\n1    1    1    1    1    1        3\n     0    1    1    0    0        3\n               0    0    1        3\n0    1    0    1    1    0        2\n                         1        2\n     0    0    1    0    1        2\n1    0    0    0    1    1        1\n0    0    1    1    0    1        1\n               0    1    1        1\n1    0    1    1    0    1        1\n               0    1    0        1\n0    1    1    1    0    1        1\n     0    1    1    1    0        1\nName: count, dtype: int64\n\n\nUsuniemy zatem takie kombinacje, ktÃ³re wystÄ™pujÄ… bardzo rzadko w danych.\n\n\nKod\ncombinations = dt.loc[:,'EC1':'EC6'].value_counts().index.to_numpy()\nidx = dt.loc[:,'EC1':'EC6'].value_counts().to_numpy()\nbad_combinations = combinations[idx&lt;10]\nidx = []\nfor i in range(len(dt)):\n  idx.append(True)\n  for j in range(len(bad_combinations)):\n    if all(dt.iloc[i, 31:] == bad_combinations[j]):\n      idx[i]=False\n\ndt = dt.iloc[idx,:]\n\n\n\n\nKod\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import MultiOutputClassifier, ClassifierChain\ny = dt.iloc[:,31:].to_numpy()\nX = dt.iloc[:,:31].to_numpy()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 44)\n\n\n\n3.3.1 NiezaleÅ¼ne lasy losowe\n\n\nKod\nrf_meta = RandomForestClassifier(random_state=4)\nrf_indep = MultiOutputClassifier(rf_meta)\nprint(rf_indep)\n\nrf_indep.fit(X_train, y_train)\nacc_indep= rf_indep.score(X_test, y_test)\npred_indep = rf_indep.predict(X_test)\n\nprint(f'Accuracy on test samples: {acc_indep:.3f}')\n\n\nMultiOutputClassifier(estimator=RandomForestClassifier(random_state=4))\nAccuracy on test samples: 0.179\n\n\n\n\n3.3.2 Classifier Chains\n\n\nKod\nrf_chains = ClassifierChain(rf_meta)\nprint(rf_chains)\n\nrf_chains.fit(X_train, y_train)\nacc_chains= rf_chains.score(X_test, y_test)\npred_chains = rf_chains.predict(X_test)\n\nprint(f'Accuracy on test samples: {acc_chains:.3f}')\n\n\nClassifierChain(base_estimator=RandomForestClassifier(random_state=4))\nAccuracy on test samples: 0.190\n\n\n\n\n3.3.3 Adaptacja modelu RF\n\n\nKod\nrf_meta.fit(X_train, y_train)\nacc_meta= rf_meta.score(X_test, y_test)\npred_meta = rf_meta.predict(X_test)\n\nprint(f'Accuracy on test samples: {acc_meta:.3f}')\n\n\nAccuracy on test samples: 0.201\n\n\n\n\n3.3.4 Podsumowanie\nRÃ³wnieÅ¼ i tym razem nie widaÄ‡ wyraÅºnych rÃ³Å¼nic pomiÄ™dzy jakoÅ›ciÄ… dopasowania modeli. Model adaptowanego lasu losowego poradziÅ‚ sobie z zadanie najlepiej (19% poprawnoÅ›ci trafieÅ„), Classifier Chains daÅ‚ 18,7%, a niezaleÅ¼ne lasy losowe 17,2%.",
    "crumbs": [
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>PrzykÅ‚ady - metody klasyczne</span>"
    ]
  },
  {
    "objectID": "examples2.html",
    "href": "examples2.html",
    "title": "4Â  PrzykÅ‚ady NN",
    "section": "",
    "text": "4.1 PrzykÅ‚ad 1\nRozwiÄ…zanie przykÅ‚adu z poprzedniego rozdziaÅ‚u moÅ¼na dokonaÄ‡ z duÅ¼o lepszÄ… precyzjÄ… wykorzystujÄ…c sieci neuronowe. W tym przykÅ‚adzie po raz kolejny wygenerujemy dane do uczenia1, a nastÄ™pnie wytrenujemy sieÄ‡ (dosyÄ‡ pÅ‚ytkÄ…) MLP.\nKod\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization, ReLU, LeakyReLU, ELU\nfrom keras.callbacks import EarlyStopping\nimport keras\nKod\n# generowanie danych do zadania\nX, y = make_regression(n_samples=700, n_features=10, n_informative = 8, n_targets=3, random_state=4)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)\n\nn_neurons = [10,20,50]\nModel bÄ™dzie bardzo prosty, skÅ‚adajÄ…cy siÄ™ z tylko jednej warstwy ukrytej.\nKod\ndef get_model(n_inputs, n_outputs, n_neurons):\n  model = Sequential()\n  model.add(Dense(int(n_neurons), input_dim=n_inputs, activation='relu'))\n  model.add(Dense(n_outputs, activation='linear'))\n  model.compile(loss='mse', optimizer='adam')\n  return model\nW tym przykÅ‚adzie chciaÅ‚em rÃ³wnieÅ¼ pokazaÄ‡ jak wykonywaÄ‡ trenowanie sieci z uÅ¼yciem sprawdzianu krzyÅ¼owego, ktÃ³ry pomoÅ¼e nam ustaliÄ‡ optymalnÄ… liczÄ™ neuronÃ³w w warstwie ukrytej.\nKod\n# ocena dopasowania modelu z wykorzystaniem CV\ndef evaluate_model(X, y, n_neurons):\n    results = list()\n    n_inputs, n_outputs = X.shape[1], y.shape[1]\n    # definicja CV\n    cv = RepeatedKFold(n_splits=5, random_state=1)\n    # pÄ™tla po foldach\n    for train_ix, test_ix in cv.split(X):\n        # przygotowanie danych\n        X_tr, X_te = X[train_ix], X[test_ix]\n        y_tr, y_te = y[train_ix], y[test_ix]\n        # okreÅ›lenie modelu\n        model = get_model(n_inputs, n_outputs, n_neurons)\n        # dopasowanie modelu\n        model.fit(X_tr, y_tr, verbose=0, epochs=100)\n        # ocena dopasowania na foldzie testowym\n        mae = model.evaluate(X_te, y_te, verbose=0)\n        results.append(mae)\n    return results\nKod\nresults = []\nfor i in n_neurons:\n  # dopasuj i oceÅ„ model na zbiorze uczÄ…cym\n  results.append(np.mean(evaluate_model(X_train, y_train, i)))\nKod\nresults = np.load(\"./data/mlp_eval.npz\")\nresults = results['arr_0'].tolist()\nfor i in range(len(n_neurons)):\n  print(f\"Dla {n_neurons[i]} neuronÃ³w MAE: {results[i]:.0f}\")\n\n\nDla 10 neuronÃ³w MAE: 16409\nDla 20 neuronÃ³w MAE: 9806\nDla 50 neuronÃ³w MAE: 3779\nNajlepszy rezultat osiÄ…gamy dla 50 neuronÃ³w i taki parametr dobierzemy w ostatecznym modelu.\nKod\nkeras.utils.set_random_seed(44)\nmy_callbacks = [\n    EarlyStopping(patience=2)\n]\n\nmodel = get_model(X_train.shape[1], y_train.shape[1], 50)\nhistory = model.fit(X_train, y_train, \n                    verbose=0, epochs=1000, \n                    validation_split=0.2, callbacks=my_callbacks)\nProces uczenia przebiegaÅ‚ prawidÅ‚owo i osiÄ…gniÄ™to niski poziom funkcji straty.\nKod\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()\nWyniki dopasowania znacznie przekraczajÄ… wyniki uzyskane metodami z poprzedniego rozdziaÅ‚u.\nKod\ny_pred = model.predict(X_test, verbose=0)\nrmse_mlp = mean_squared_error(y_test, y_pred, squared=False)\nr2_mlp = r2_score(y_test, y_pred)\nprint(f\"R2 on test sample: {r2_mlp:.2f}\")\nprint(f\"RMSE on test sample: {rmse_mlp:.1f}\")\n\n\nR2 on test sample: 1.00\nRMSE on test sample: 0.0",
    "crumbs": [
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>PrzykÅ‚ady NN</span>"
    ]
  },
  {
    "objectID": "examples2.html#przykÅ‚ad-1",
    "href": "examples2.html#przykÅ‚ad-1",
    "title": "4Â  PrzykÅ‚ady NN",
    "section": "",
    "text": "1Â te same co z przykÅ‚adu regresyjnego z poprzedniego wykÅ‚adu",
    "crumbs": [
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>PrzykÅ‚ady NN</span>"
    ]
  },
  {
    "objectID": "examples2.html#przykÅ‚ad-2",
    "href": "examples2.html#przykÅ‚ad-2",
    "title": "4Â  PrzykÅ‚ady NN",
    "section": "4.2 PrzykÅ‚ad 2",
    "text": "4.2 PrzykÅ‚ad 2\nW tym przykÅ‚adzie jeszcze raz rozpatrzymy zadanie klasyfikacyjne z wieloma wyjÅ›ciami z poprzedniego rozdziaÅ‚u. Przeprowadzimy czynnoÅ›ci preprocessingu podobne jak w poprzednim rozdziale, dodajÄ…c jeszcze standaryzacjÄ™, ktÃ³ra dla sieci neuronowych jest bardzo waÅ¼na.\n\n\nKod\nfrom sklearn.preprocessing import StandardScaler\ndt = pd.read_csv(\"./data/original.csv\", index_col = \"id\")\ncombinations = dt.loc[:,'EC1':'EC6'].value_counts().index.to_numpy()\nidx = dt.loc[:,'EC1':'EC6'].value_counts().to_numpy()\nbad_combinations = combinations[idx&lt;10]\nidx = []\nfor i in range(len(dt)):\n  idx.append(True)\n  for j in range(len(bad_combinations)):\n    if all(dt.iloc[i, 31:] == bad_combinations[j]):\n      idx[i]=False\n\ndt = dt.iloc[idx,:]\n\ny = dt.iloc[:,31:].to_numpy()\nX = dt.iloc[:,:31].to_numpy()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 44)\n\nscaler = StandardScaler().fit(X_train)\nX_test = scaler.transform(X_test)\nX_train = scaler.transform(X_train)\n\n\nNastÄ™pnie przygotujemy model sieci neuronowej, ktÃ³ra pozwoli na wÅ‚aÅ›ciwe klasyfikacje obiektÃ³w.\n\n\nKod\nmodel = Sequential()\nmodel.add(Dense(15, input_dim=X_train.shape[1]))\nmodel.add(ReLU())\nmodel.add(Dropout(0.1))\nmodel.add(Dense(y_train.shape[1], activation='sigmoid'))\n\nopt = keras.optimizers.Nadam(0.001)\nmodel.compile(loss='binary_crossentropy', optimizer=opt)\nmodel.summary()\n\n\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_2 (Dense)             (None, 15)                480       \n                                                                 \n re_lu (ReLU)                (None, 15)                0         \n                                                                 \n dropout (Dropout)           (None, 15)                0         \n                                                                 \n dense_3 (Dense)             (None, 6)                 96        \n                                                                 \n=================================================================\nTotal params: 576 (2.25 KB)\nTrainable params: 576 (2.25 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\n\nKod\nkeras.utils.set_random_seed(44)\nmy_callbacks = [\n    EarlyStopping(patience=10)\n]\nhistory = model.fit(X_train, y_train, epochs=1000,  validation_split=0.4, verbose=0,\ncallbacks=my_callbacks)\n\n\n\n\nKod\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nKod\nfrom sklearn.metrics import accuracy_score\ny_pred = model.predict(X_test, verbose=0)\ny_class = y_pred.round()\nacc = accuracy_score(y_test, y_class)\nprint(f\"ACC on test sample: {acc:.3f}\")\n\n\nACC on test sample: 0.198\n\n\n\n4.2.1 Podsumowanie\nModel prostej sieci neuronowej nie poprawiÅ‚ znaczÄ…co jakoÅ›ci dopasowania w stosunku do modelu lasu losowego adaptowanego do zadania z wieloma wyjÅ›ciami.",
    "crumbs": [
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>PrzykÅ‚ady NN</span>"
    ]
  },
  {
    "objectID": "rnn.html",
    "href": "rnn.html",
    "title": "\n5Â  Rodzaje szeregÃ³w czasowych\n",
    "section": "",
    "text": "5.1 Zastosowanie sieci rekurencyjnych w szeregach czasowych\nW tym podrozdziale omÃ³wimy trzy zaawansowane techniki poprawy wydajnoÅ›ci i siÅ‚y generalizacji rekurencyjnych sieci neuronowych. Zademonstrujemy wszystkie trzy koncepcje na problemie prognozowania pogody, gdzie mamy dostÄ™p do szeregu obserwacji pochodzÄ…cych z czujnikÃ³w zainstalowanych na dachu budynku, takich jak temperatura, ciÅ›nienie powietrza i wilgotnoÅ›Ä‡, ktÃ³re uÅ¼yjemy do przewidywania, jaka bÄ™dzie temperatura 24 godziny po ostatniej obserwacji w bazie danych. Jest to doÅ›Ä‡ trudny problem, ktÃ³ry ilustruje wiele typowych trudnoÅ›ci napotykanych podczas pracy z szeregami czasowymi.\nOmÃ³wimy nastÄ™pujÄ…ce techniki:",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Rodzaje szeregÃ³w czasowych</span>"
    ]
  },
  {
    "objectID": "rnn.html#zastosowanie-sieci-rekurencyjnych-w-szeregach-czasowych",
    "href": "rnn.html#zastosowanie-sieci-rekurencyjnych-w-szeregach-czasowych",
    "title": "\n5Â  Rodzaje szeregÃ³w czasowych\n",
    "section": "",
    "text": "Recurrent dropout - to specyficzny, wbudowany sposÃ³b uÅ¼ycia dropoutu do walki z nadmiernym dopasowaniem w warstwach rekurencyjnych.\nSkÅ‚adanie warstw rekurencyjnych - zwiÄ™ksza to moc reprezentacyjnÄ… sieci (kosztem wiÄ™kszego obciÄ…Å¼enia obliczeniowego).\nDwukierunkowe warstwy rekurencyjne - prezentujÄ… one tÄ™ samÄ… informacjÄ™ sieci rekurencyjnej na rÃ³Å¼ne sposoby, zwiÄ™kszajÄ…c dokÅ‚adnoÅ›Ä‡ i Å‚agodzÄ…c problemy zwiÄ…zane z zapominaniem.\n\n\nPrzykÅ‚ad 5.1 W analizowanym zestawie danych 14 rÃ³Å¼nych wielkoÅ›ci (takich jak temperatura powietrza, ciÅ›nienie atmosferyczne, wilgotnoÅ›Ä‡, kierunek wiatru i tak dalej) byÅ‚o rejestrowanych co 10 minut, przez kilka lat. Oryginalne dane siÄ™gajÄ… 2003 roku, ale ten przykÅ‚ad jest ograniczony do danych z lat 2009-2016.\nNa poczÄ…tek pobierzemy dane z serwera https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip i rozpakujemy.\n\nKodurl &lt;-\n \"https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\"\ndownload.file(url, destfile = basename(url))\nzip::unzip(zipfile = \"jena_climate_2009_2016.csv.zip\",\n          files = \"jena_climate_2009_2016.csv\")\n\n\n\nKodfull_df &lt;- readr::read_csv(\"jena_climate_2009_2016.csv\")\nfull_df\n\n# A tibble: 420,451 Ã— 15\n   `Date Time`         `p (mbar)` `T (degC)` `Tpot (K)` `Tdew (degC)` `rh (%)`\n   &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 01.01.2009 00:10:00       997.      -8.02       265.         -8.9      93.3\n 2 01.01.2009 00:20:00       997.      -8.41       265.         -9.28     93.4\n 3 01.01.2009 00:30:00       997.      -8.51       265.         -9.31     93.9\n 4 01.01.2009 00:40:00       997.      -8.31       265.         -9.07     94.2\n 5 01.01.2009 00:50:00       997.      -8.27       265.         -9.04     94.1\n 6 01.01.2009 01:00:00       996.      -8.05       265.         -8.78     94.4\n 7 01.01.2009 01:10:00       996.      -7.62       266.         -8.3      94.8\n 8 01.01.2009 01:20:00       996.      -7.62       266.         -8.36     94.4\n 9 01.01.2009 01:30:00       996.      -7.91       266.         -8.73     93.8\n10 01.01.2009 01:40:00       997.      -8.43       265.         -9.34     93.1\n# â„¹ 420,441 more rows\n# â„¹ 9 more variables: `VPmax (mbar)` &lt;dbl&gt;, `VPact (mbar)` &lt;dbl&gt;,\n#   `VPdef (mbar)` &lt;dbl&gt;, `sh (g/kg)` &lt;dbl&gt;, `H2OC (mmol/mol)` &lt;dbl&gt;,\n#   `rho (g/m**3)` &lt;dbl&gt;, `wv (m/s)` &lt;dbl&gt;, `max. wv (m/s)` &lt;dbl&gt;,\n#   `wd (deg)` &lt;dbl&gt;\n\n\nChoÄ‡ nie jest to konieczne w tym zadaniu, to przeksztaÅ‚cimy datÄ™ (bÄ™dÄ…cÄ… pierwsza kolumnÄ… w zestawie danych) z typu character do typu DateTime.\n\nKodfull_df$`Date Time` %&lt;&gt;%\n as.POSIXct(tz = \"Etc/GMT+1\", format = \"%d.%m.%Y %H:%M:%S\")\n\n\nZwrÃ³Ä‡ uwagÄ™, Å¼e przekazujemy tz = \"Etc/GMT+1\" zamiast tz = \"Europe/Berlin\", poniewaÅ¼ znaczniki czasu w zbiorze danych nie dostosowujÄ… siÄ™ do czasu letniego Å›rodkowoeuropejskiego (znanego rÃ³wnieÅ¼ jako czas letni), ale zawsze sÄ… wedÅ‚ug czasu Å›rodkowoeuropejskiego.\n\n\n\n\n\n\nWskazÃ³wka\n\n\n\nPowyÅ¼ej po raz pierwszy uÅ¼yliÅ›my potoku przypisania x %&lt;&gt;% fn(), ktÃ³ry jest skrÃ³tem od x &lt;- x %&gt;% fn(). Jest to przydatne, poniewaÅ¼ pozwala pisaÄ‡ bardziej czytelny kod i uniknÄ…Ä‡ wielokrotnego powtarzania tej samej nazwy zmiennej. Przypisanie jest udostÄ™pniane przez wywoÅ‚anie library(keras).\n\n\n\nKodplot(`T (degC)` ~ `Date Time`, data = full_df, pch = 20, cex = .3)\n\n\n\n\n\n\nRysunekÂ 5.1: Przebieg szeregu czasowego temperatury\n\n\n\n\nRysunekÂ 5.1 przedstawia wykres temperatury (w stopniach Celsjusza) w czasie. Na tym wykresie wyraÅºnie widaÄ‡ rocznÄ… okresowoÅ›Ä‡ temperatury - dane obejmujÄ… 8 lat.\n\nKodplot(`T (degC)` ~ `Date Time`, data = full_df[1:1440, ], type = 'l')\n\n\n\n\n\n\nRysunekÂ 5.2: Wycinek przebiegu szeregu czasowego temperatury\n\n\n\n\nRysunekÂ 5.2 przedstawia wÄ™Å¼szy wykres danych temperatury z pierwszych 10 dni. PoniewaÅ¼ dane sÄ… rejestrowane co 10 minut, otrzymujemy 24 Ã— 6 = 144 punkty danych dziennie. ZauwaÅ¼ teÅ¼, Å¼e ten 10-dniowy okres musi pochodziÄ‡ z doÅ›Ä‡ zimnego zimowego miesiÄ…ca. GdybyÅ› prÃ³bowaÅ‚ przewidzieÄ‡ Å›redniÄ… temperaturÄ™ na nastÄ™pny miesiÄ…c biorÄ…c pod uwagÄ™ kilka miesiÄ™cy danych z przeszÅ‚oÅ›ci, problem byÅ‚by Å‚atwy, ze wzglÄ™du na okresowoÅ›Ä‡ danych w skali roku. Ale patrzÄ…c na dane w skali dni, temperatura wyglÄ…da o wiele bardziej chaotycznie. Czy ten szereg czasowy jest przewidywalny w skali dziennej? Przekonajmy siÄ™.\nWe wszystkich naszych eksperymentach wykorzystamy pierwsze 50% danych do szkolenia, kolejne 25% do walidacji, a ostatnie 25% do testowania. Podczas pracy z danymi szeregÃ³w czasowych waÅ¼ne jest, aby uÅ¼ywaÄ‡ danych walidacyjnych i testowych, ktÃ³re sÄ… nowsze niÅ¼ dane treningowe, poniewaÅ¼ prÃ³bujemy przewidzieÄ‡ przyszÅ‚oÅ›Ä‡ na podstawie przeszÅ‚oÅ›ci, a nie odwrotnie, a podziaÅ‚y walidacyjne / testowe powinny to odzwierciedlaÄ‡.\n\nKodnum_train_samples &lt;- round(nrow(full_df) * .5)\nnum_val_samples &lt;- round(nrow(full_df) * 0.25)\nnum_test_samples &lt;- nrow(full_df) - num_train_samples - num_val_samples\n\ntrain_df &lt;- full_df[seq(num_train_samples), ]\n\nval_df &lt;- full_df[seq(from = nrow(train_df) + 1,\n                      length.out = num_val_samples), ]\n\ntest_df &lt;- full_df[seq(to = nrow(full_df),\n                       length.out = num_test_samples), ]\n\ncat(\"num_train_samples:\", nrow(train_df), \"\\n\")\n\nnum_train_samples: 210226 \n\nKodcat(\"num_val_samples:\", nrow(val_df), \"\\n\")\n\nnum_val_samples: 105113 \n\nKodcat(\"num_test_samples:\", nrow(test_df), \"\\n\")\n\nnum_test_samples: 105112 \n\n\nDokÅ‚adne sformuÅ‚owanie problemu bÄ™dzie nastÄ™pujÄ…ce: biorÄ…c pod uwagÄ™ dane obejmujÄ…ce poprzednie piÄ™Ä‡ dni i prÃ³bkowane raz na godzinÄ™, czy moÅ¼emy przewidzieÄ‡ temperaturÄ™ w ciÄ…gu 24 godzin?\nPo pierwsze, wstÄ™pnie przetworzymy dane do formatu, ktÃ³ry moÅ¼e przyjÄ…Ä‡ sieÄ‡ neuronowa. Dane sÄ… juÅ¼ numeryczne, wiÄ™c nie trzeba ich wektoryzowaÄ‡. Jednak kaÅ¼dy szereg czasowy w danych ma innÄ… skalÄ™ (np. ciÅ›nienie atmosferyczne, mierzone w mbar, wynosi okoÅ‚o 1000, podczas gdy H2OC, mierzone w milimolach na mol, wynosi okoÅ‚o 3). Znormalizujemy kaÅ¼dÄ… seriÄ™ czasowÄ… (kolumnÄ™) niezaleÅ¼nie, tak aby wszystkie przyjmowaÅ‚y maÅ‚e wartoÅ›ci w podobnej skali. UÅ¼yjemy pierwszych 210 226 krokÃ³w czasowych jako danych treningowych, wiÄ™c obliczymy Å›redniÄ… i odchylenie standardowe tylko dla tej czÄ™Å›ci danych.\n\nKodinput_data_colnames &lt;- names(full_df) %&gt;%\n  setdiff(c(\"Date Time\"))\n\nnormalization_values &lt;-\n  zip_lists(mean = lapply(train_df[input_data_colnames], mean),\n            sd = lapply(train_df[input_data_colnames], sd))\n\nstr(normalization_values)\n\nList of 14\n $ p (mbar)       :List of 2\n  ..$ mean: num 989\n  ..$ sd  : num 8.51\n $ T (degC)       :List of 2\n  ..$ mean: num 8.83\n  ..$ sd  : num 8.77\n $ Tpot (K)       :List of 2\n  ..$ mean: num 283\n  ..$ sd  : num 8.87\n $ Tdew (degC)    :List of 2\n  ..$ mean: num 4.31\n  ..$ sd  : num 7.08\n $ rh (%)         :List of 2\n  ..$ mean: num 75.9\n  ..$ sd  : num 16.6\n $ VPmax (mbar)   :List of 2\n  ..$ mean: num 13.1\n  ..$ sd  : num 7.6\n $ VPact (mbar)   :List of 2\n  ..$ mean: num 9.19\n  ..$ sd  : num 4.15\n $ VPdef (mbar)   :List of 2\n  ..$ mean: num 3.95\n  ..$ sd  : num 4.77\n $ sh (g/kg)      :List of 2\n  ..$ mean: num 5.81\n  ..$ sd  : num 2.63\n $ H2OC (mmol/mol):List of 2\n  ..$ mean: num 9.3\n  ..$ sd  : num 4.2\n $ rho (g/m**3)   :List of 2\n  ..$ mean: num 1218\n  ..$ sd  : num 42\n $ wv (m/s)       :List of 2\n  ..$ mean: num 2.15\n  ..$ sd  : num 1.53\n $ max. wv (m/s)  :List of 2\n  ..$ mean: num 3.56\n  ..$ sd  : num 2.32\n $ wd (deg)       :List of 2\n  ..$ mean: num 176\n  ..$ sd  : num 85.9\n\nKodnormalize_input_data &lt;- function(df) {\n  normalize &lt;- function(x, center, scale)\n    (x - center) / scale\n\n  for(col_nm in input_data_colnames) {\n    col_nv &lt;- normalization_values[[col_nm]]\n    df[[col_nm]] %&lt;&gt;% normalize(., col_nv$mean, col_nv$sd)\n  }\n\n  df\n}\n\n\nNastÄ™pnie stwÃ³rzmy obiekt TF Dataset, ktÃ³ry zawiera partie danych z ostatnich piÄ™ciu dni wraz z temperaturÄ… docelowÄ… 24 godziny w przyszÅ‚oÅ›ci. PoniewaÅ¼ prÃ³bki w zestawie danych sÄ… wysoce nadmiarowe (prÃ³bka N i prÃ³bka N + 1 bÄ™dÄ… miaÅ‚y wiÄ™kszoÅ›Ä‡ wspÃ³lnych krokÃ³w czasowych), marnotrawstwem byÅ‚oby jawne przydzielanie pamiÄ™ci dla kaÅ¼dej prÃ³bki. Zamiast tego bÄ™dziemy generowaÄ‡ prÃ³bki w locie, zachowujÄ…c w pamiÄ™ci tylko oryginalne tablice danych i nic wiÄ™cej.\nMoglibyÅ›my z Å‚atwoÅ›ciÄ… napisaÄ‡ funkcjÄ™ w R, aby to zrobiÄ‡, ale istnieje wbudowane narzÄ™dzie w keras, ktÃ³re wÅ‚aÅ›nie to robi - (timeseries_dataset_from_array()) - wiÄ™c moÅ¼emy zaoszczÄ™dziÄ‡ sobie trochÄ™ pracy, korzystajÄ…c z niego. OgÃ³lnie rzecz biorÄ…c, moÅ¼na go uÅ¼ywaÄ‡ do wszelkiego rodzaju zadaÅ„ zwiÄ…zanych z prognozowaniem szeregÃ³w czasowych.\n\n\n\n\n\n\nAdnotacja\n\n\n\nAby zrozumieÄ‡ dziaÅ‚anie funkcji timeseries_dataset_from_array(), przyjrzyjmy siÄ™ prostemu przykÅ‚adowi. OgÃ³lna idea polega na dostarczeniu tablicy danych szeregÃ³w czasowych (argument dane), a funkcja timeseries_dataset_from_array() daje okna wyodrÄ™bnione z oryginalnych szeregÃ³w czasowych (nazwiemy je â€œsekwencjamiâ€).\nNa przykÅ‚ad, jeÅ›li uÅ¼yjesz data = [0 1 2 3 4 5 6] i sequence_length = 3, wÃ³wczas timeseries_dataset_from_array() wygeneruje nastÄ™pujÄ…ce prÃ³bki: [0 1 2], [1 2 3] , [2 3 4], [3 4 5], [4 5 6].\nDo funkcji timeseries_dataset_ from_array() moÅ¼na rÃ³wnieÅ¼ przekazaÄ‡ argument targets (tablicÄ™). Pierwszy wpis w tablicy targets powinien odpowiadaÄ‡ poÅ¼Ä…danemu celowi dla pierwszej sekwencji, ktÃ³ra zostanie wygenerowana z tablicy data. Tak wiÄ™c, jeÅ›li wykonujemy prognozowanie szeregÃ³w czasowych, targets powinny byÄ‡ tÄ… samÄ… tablicÄ… co data, przesuniÄ™tÄ… o pewnÄ… wartoÅ›Ä‡.\nNa przykÅ‚ad, z data = [0 1 2 3 4 5 6 ...] i sequence_length = 3, moÅ¼na utworzyÄ‡ zestaw danych do przewidywania nastÄ™pnego kroku w serii, przekazujÄ…c targets = [3 4 5 6 ...]. PrzykÅ‚adowo:\n\nKodint_sequence &lt;- seq(10)\ndummy_dataset &lt;- timeseries_dataset_from_array(\n  data = head(int_sequence, -3),\n  targets = tail(int_sequence, -3),\n  sequence_length = 3,\n  batch_size = 2\n)\n\nlibrary(tfdatasets)\ndummy_dataset_iterator &lt;- as_array_iterator(dummy_dataset)\n\nrepeat {\n  batch &lt;- iter_next(dummy_dataset_iterator)\n  if (is.null(batch))\n    break\n  c(inputs, targets) %&lt;-% batch\n  for (r in 1:nrow(inputs))\n    cat(sprintf(\"input: [ %s ]  target: %s\\n\",\n                paste(inputs[r, ], collapse = \" \"), targets[r]))\n  cat(strrep(\"-\", 27), \"\\n\")\n}\n\ninput: [ 1 2 3 ]  target: 4\ninput: [ 2 3 4 ]  target: 5\n--------------------------- \ninput: [ 3 4 5 ]  target: 6\ninput: [ 4 5 6 ]  target: 7\n--------------------------- \ninput: [ 5 6 7 ]  target: 8\n--------------------------- \n\n\n\n\nUÅ¼yjemy funkcji timeseries_dataset_from_array(), aby utworzyÄ‡ trzy zestawy danych: jeden do szkolenia, jeden do walidacji i jeden do testowania. UÅ¼yjemy nastÄ™pujÄ…cych wartoÅ›ci parametrÃ³w:\n\n\nsampling_rate = 6 - obserwacje bÄ™dÄ… prÃ³bkowane z czÄ™stotliwoÅ›ciÄ… jednego punktu danych na godzinÄ™ (zachowamy tylko jeden punkt danych z 6).\n\nsequence_length = 120 - obserwacje bÄ™dÄ… siÄ™gaÄ‡ piÄ™ciu dni wstecz (120 godzin).\n\ndelay = sampling_rate * (sequence_length + 24 - 1) - celem dla sekwencji bÄ™dzie temperatura 24 godziny po zakoÅ„czeniu sekwencji.\n\n\nKodsampling_rate &lt;- 6\nsequence_length &lt;- 120\ndelay &lt;- sampling_rate * (sequence_length + 24 - 1)\nbatch_size &lt;- 256\n\ndf_to_inputs_and_targets &lt;- function(df) {\n  inputs &lt;- df[input_data_colnames] %&gt;%\n    normalize_input_data() %&gt;%\n    as.matrix()\n\n  targets &lt;- as.array(df$`T (degC)`)\n\n  list(\n    head(inputs, -delay),\n    tail(targets, -delay)\n  )\n}\n\nmake_dataset &lt;- function(df) {\n  c(inputs, targets) %&lt;-% df_to_inputs_and_targets(df)\n  timeseries_dataset_from_array(\n    inputs, targets,\n    sampling_rate = sampling_rate,\n    sequence_length = sequence_length,\n    shuffle = TRUE,\n    batch_size = batch_size\n  )\n}\n\ntrain_dataset &lt;- make_dataset(train_df)\nval_dataset &lt;- make_dataset(val_df)\ntest_dataset &lt;- make_dataset(test_df)\n\n\nKaÅ¼dy zestaw danych daje partie jako parÄ™ (samples, targets), gdzie samples to partia 256 prÃ³bek, z ktÃ³rych kaÅ¼da zawiera 120 kolejnych godzin danych wejÅ›ciowych, a targets to odpowiednia tablica 256 temperatur docelowych. NaleÅ¼y pamiÄ™taÄ‡, Å¼e prÃ³bki sÄ… losowo tasowane, wiÄ™c dwie kolejne sekwencje w partii (takie jak sample[1, ] i sample[2, ]) niekoniecznie sÄ… czasowo blisko siebie.\n\nKodc(samples, targets) %&lt;-% iter_next(as_iterator(train_dataset))\ncat(\"samples shape: \", format(samples$shape), \"\\n\",\n    \"targets shape: \", format(targets$shape), \"\\n\", sep = \"\")\n\nsamples shape: (256, 120, 14)\ntargets shape: (256)\n\n\n\n\n\n\n\n\n\nWaÅ¼ne\n\n\n\nZanim zaczniemy wykorzystywaÄ‡ modele uczenia gÅ‚Ä™bokiego typu black-box w rozwiÄ…zywaniu problemu przewidywania temperatury, wyprÃ³bujmy proste, zdroworozsÄ…dkowe podejÅ›cie. PosÅ‚uÅ¼y ono jako sprawdzian poprawnoÅ›ci i ustanowi punkt odniesienia, ktÃ³ry bÄ™dziemy musieli pokonaÄ‡, aby zademonstrowaÄ‡ przydatnoÅ›Ä‡ bardziej zaawansowanych modeli uczenia maszynowego. Takie zdroworozsÄ…dkowe podstawy mogÄ… byÄ‡ przydatne, gdy zabieramy siÄ™ do nowego problemu, dla ktÃ³rego nie ma (jeszcze) znanego rozwiÄ…zania. Klasycznym przykÅ‚adem sÄ… niezrÃ³wnowaÅ¼one zadania klasyfikacyjne, w ktÃ³rych niektÃ³re klasy wystÄ™pujÄ… znacznie czÄ™Å›ciej niÅ¼ inne. JeÅ›li zbiÃ³r danych zawiera 90% przypadkÃ³w klasy A i 10% przypadkÃ³w klasy B, wÃ³wczas zdroworozsÄ…dkowym podejÅ›ciem do zadania klasyfikacji jest zawsze przewidywanie â€œAâ€, gdy prezentowana jest nowa prÃ³bka. Taki klasyfikator jest ogÃ³lnie dokÅ‚adny w 90%, a zatem kaÅ¼de podejÅ›cie oparte na uczeniu powinno pokonaÄ‡ ten 90% wynik, aby wykazaÄ‡ przydatnoÅ›Ä‡. Czasami takie elementarne wartoÅ›ci bazowe mogÄ… okazaÄ‡ siÄ™ zaskakujÄ…co trudne do pokonania.\n\n\n\n5.1.1 Model bazowy\nW tym przypadku moÅ¼na bezpiecznie zaÅ‚oÅ¼yÄ‡, Å¼e szereg czasowy temperatury jest ciÄ…gÅ‚y (temperatury jutro bÄ™dÄ… prawdopodobnie zbliÅ¼one do temperatur dzisiaj), a takÅ¼e okresowy z okresem dziennym. Dlatego zdroworozsÄ…dkowym podejÅ›ciem jest zawsze przewidywanie, Å¼e temperatura za 24 godziny bÄ™dzie rÃ³wna temperaturze w obecnej chwili. OceÅ„my to podejÅ›cie, korzystajÄ…c z metryki Å›redniego bÅ‚Ä™du bezwzglÄ™dnego (MAE).\nZamiast oceniaÄ‡ wszystko w R stosujÄ…c funkcje for, as_ array_iterator() i iter_next(), moÅ¼emy to rÃ³wnie Å‚atwo zrobiÄ‡ za pomocÄ… transformacji TF Dataset. Najpierw wywoÅ‚ujemy dataset_unbatch(), aby kaÅ¼dy element zbioru danych staÅ‚ siÄ™ pojedynczym przypadkiem (sample, target). NastÄ™pnie uÅ¼ywamy funkcji dataset_map(), aby obliczyÄ‡ bÅ‚Ä…d bezwzglÄ™dny dla kaÅ¼dej pary (sample, target), a nastÄ™pnie dataset_reduce(), aby zgromadziÄ‡ caÅ‚kowity bÅ‚Ä…d i caÅ‚kowitÄ… liczbÄ™ widzianych prÃ³bek.\nPrzypomnijmy, Å¼e funkcje przekazywane do dataset_map() i dataset_reduce() bÄ™dÄ… wywoÅ‚ywane z tensorami symoblicznymi. Wycinanie tensora z liczbÄ… ujemnÄ…, takÄ… jak samples[-1, ], wybiera ostatni wyraz wzdÅ‚uÅ¼ tej osi, tak jakbyÅ›my napisali samples[nrow(samples), ].\n\nKodevaluate_naive_method &lt;- function(dataset) {\n\n  unnormalize_temperature &lt;- function(x) {\n    nv &lt;- normalization_values$`T (degC)`\n    (x * nv$sd) + nv$mean\n  }\n\n  temp_col_idx &lt;- match(\"T (degC)\", input_data_colnames)\n\n  reduction &lt;- dataset %&gt;%\n    dataset_unbatch() %&gt;%\n    dataset_map(function(samples, target) {\n      last_temp_in_input &lt;- samples[-1, temp_col_idx]\n      pred &lt;- unnormalize_temperature(last_temp_in_input)\n      abs(pred - target)\n    }) %&gt;%\n    dataset_reduce(\n      initial_state = list(total_samples_seen = 0L,\n                           total_abs_error = 0),\n      reduce_func = function(state, element) {\n        state$total_samples_seen %&lt;&gt;% `+`(1L)\n        state$total_abs_error %&lt;&gt;% `+`(element)\n        state\n      }\n    ) %&gt;%\n    lapply(as.numeric)\n\n  mae &lt;- with(reduction,\n              total_abs_error / total_samples_seen)\n  mae\n}\n\nsprintf(\"Validation MAE: %.2f\", evaluate_naive_method(val_dataset))\n\n[1] \"Validation MAE: 2.43\"\n\nKodsprintf(\"Test MAE: %.2f\", evaluate_naive_method(test_dataset))\n\n[1] \"Test MAE: 2.62\"\n\n\nZdroworozsÄ…dkowy punkt odniesienia osiÄ…ga MAE na zbiorze walidacyjnym na poziomie 2,43 stopnia Celsjusza i MAE na testowym na poziomie 2,62 stopnia Celsjusza. JeÅ›li wiÄ™c zawsze zakÅ‚adamy, Å¼e temperatura w ciÄ…gu 24 godzin w przyszÅ‚oÅ›ci bÄ™dzie taka sama jak obecnie, bÄ™dziesz siÄ™ myliÅ‚ Å›rednio o okoÅ‚o dwa i pÃ³Å‚ stopnia. Prognoza nie jest zÅ‚a ale z pewnoÅ›ciÄ… da siÄ™ jÄ… poprawiÄ‡.\nW ten sam sposÃ³b, w jaki warto ustaliÄ‡ zdroworozsÄ…dkowy model bazowy przed uÅ¼yciem uczenia maszynowego, warto wyprÃ³bowaÄ‡ rÃ³wnieÅ¼ proste modele uczenia maszynowego (takie jak maÅ‚e, gÄ™sto poÅ‚Ä…czone sieci) przed przejÅ›ciem do bardziej skomplikownych i kosztownych obliczeniowo modeli, takich jak RNN. Jest to najlepszy sposÃ³b na upewnienie siÄ™, Å¼e jakakolwiek dalsza zÅ‚oÅ¼onoÅ›Ä‡ problemu jest uzasadniona i przynosi realne korzyÅ›ci.\n\n5.1.2 Prosty model sieci gÄ™stej\nPoniÅ¼szy kod pokazuje w peÅ‚ni poÅ‚Ä…czony model, ktÃ³ry rozpoczyna siÄ™ od spÅ‚aszczenia danych, a nastÄ™pnie przepuszcza je przez dwie warstwy layer_dense(). ZwrÃ³Ä‡my uwagÄ™ na brak funkcji aktywacji w ostatniej warstwie layer_dense(), co jest typowe dla problemu regresji. UÅ¼ywamy bÅ‚Ä™du Å›redniokwadratowego (MSE) jako funkcji straty, a nie MAE, poniewaÅ¼ w przeciwieÅ„stwie do MAE, jest on rÃ³Å¼niczkowalny wokÃ³Å‚ zera, co jest uÅ¼ytecznÄ… wÅ‚aÅ›ciwoÅ›ciÄ… dla spadku gradientu. MAE bÄ™dziemy rÃ³wnieÅ¼ monitorowaÄ‡, dodajÄ…c go jako metrykÄ™ w funkcji compile().\n\nKodncol_input_data &lt;- length(input_data_colnames)\n\ninputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_flatten() %&gt;%\n  layer_dense(16, activation=\"relu\") %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;%\n  compile(optimizer = \"rmsprop\",\n          loss = \"mse\",\n          metrics = \"mae\")\n\nsave_model_tf(model, \"models/jena_dense.keras\")\nsaveRDS(history, \"models/jena_dense_history.rds\")\n\nhistory &lt;- model %&gt;%\n  fit(train_dataset,\n      epochs = 10,\n      validation_data = val_dataset)\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_dense.keras\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 4s - loss: 58.4128 - mae: 6.2125 - 4s/epoch - 10ms/step\n\n\n[1] \"Test MAE: 6.21\"\n\nKodhistory &lt;- readRDS(\"models/jena_dense_history.rds\")\nplot(history, metrics = \"mae\")\n\n\n\n\n\n\n\nNiektÃ³re wartoÅ›ci funkcji straty na zbiorze walidacyjnym sÄ… zbliÅ¼one do modelu bazowego ale nie moÅ¼na powiedzieÄ‡, Å¼e model ten jest lepszy od bazowego. To pokazuje zaletÄ™ posiadania modelu odniesienia, bo okazuje siÄ™, Å¼e nie jest Å‚atwo go â€œpokonaÄ‡â€. Zdrowy rozsÄ…dek zawiera wiele cennych informacji, do ktÃ³rych model uczenia maszynowego nie ma dostÄ™pu. Jest to doÅ›Ä‡ istotne ograniczenie uczenia maszynowego w ogÃ³le: o ile algorytm uczenia nie jest zakodowany na sztywno, by szukaÄ‡ konkretnego rodzaju prostego modelu, moÅ¼e on czasem nie znaleÅºÄ‡ prostego rozwiÄ…zania problemu. WÅ‚aÅ›nie dlatego wykorzystanie dobrej inÅ¼ynierii cech i odpowiednich zaÅ‚oÅ¼eÅ„ dotyczÄ…cych architektury ma zasadnicze znaczenie. PowinniÅ›my dokÅ‚adnie powiedzieÄ‡ modelowi, czego powinien szukaÄ‡.\n\n5.1.3 Model oparty o konwolucje 1D\nMÃ³wiÄ…c o wykorzystaniu odpowiednich zaÅ‚oÅ¼eÅ„ co do architektury, byÄ‡ moÅ¼e model konwolucyjny bÄ™dzie dziaÅ‚aÄ‡ poprawnie. SieÄ‡ konwolucyjna 1D mogÅ‚aby ponownie wykorzystywaÄ‡ te same reprezentacje w rÃ³Å¼nych dniach, podobnie jak przestrzenna sieÄ‡ konwolucyjna moÅ¼e ponownie wykorzystywaÄ‡ te same reprezentacje w rÃ³Å¼nych lokalizacjach na obrazie. Znamy juÅ¼ warstwy layer_conv_2d() i layer_separable_conv_2d(), ktÃ³re widzÄ… dane wejÅ›ciowe przez maÅ‚e okna (filtry), ktÃ³re przesuwajÄ… siÄ™ po siatkach 2D. IstniejÄ… rÃ³wnieÅ¼ wersje 1D, a nawet 3D tych warstw: layer_conv_1d(), layer_separable_ conv_1d() i layer_conv_3d(). Warstwa layer_conv_1d() opiera siÄ™ na oknach 1D, ktÃ³re przesuwajÄ… siÄ™ po sekwencjach wejÅ›ciowych, natomiast warstwa layer_conv_3d() opiera siÄ™ na szeÅ›ciennych oknach, ktÃ³re przesuwajÄ… siÄ™ po woluminach wejÅ›ciowych.\nW ten sposÃ³b moÅ¼na budowaÄ‡ sieci konwolucyjne 1D, Å›ciÅ›le analogiczne do sieci 2D. Åšwietnie nadajÄ… siÄ™ do wszelkich danych sekwencyjnych, ktÃ³re sÄ… zgodne z zaÅ‚oÅ¼eniem niezmiennoÅ›ci translacji (co oznacza, Å¼e jeÅ›li przesuniesz okno po sekwencji, zawartoÅ›Ä‡ okna powinna mieÄ‡ te same wÅ‚aÅ›ciwoÅ›ci niezaleÅ¼nie od poÅ‚oÅ¼enia okna).\nWyprÃ³bujmy sieÄ‡ 1D na naszym problemie prognozowania temperatury. Wybierzemy poczÄ…tkowÄ… dÅ‚ugoÅ›Ä‡ okna wynoszÄ…cÄ… 24, tak abyÅ›my patrzyli na 24 godziny danych na raz (jeden cykl). Gdy zmniejszymy prÃ³bkowanie sekwencji (poprzez warstwy layer_max_pooling_1d()), odpowiednio zmniejszymy rozmiar okna:\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_conv_1d(8, 24, activation = \"relu\") %&gt;%\n  layer_max_pooling_1d(2) %&gt;%\n  layer_conv_1d(8, 12, activation = \"relu\") %&gt;%\n  layer_max_pooling_1d(2) %&gt;%\n  layer_conv_1d(8, 6, activation = \"relu\") %&gt;%\n  layer_global_average_pooling_1d() %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\nhistory &lt;- model %&gt;% fit(\n  train_dataset,\n  epochs = 10,\n  validation_data = val_dataset\n)\n\nsave_model_tf(model, filepath = \"models/jena_conv1D.keras\")\nsaveRDS(history, file = \"models/jena_conv1D_history.rds\")\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_conv1D.keras\")\nhistory &lt;- readRDS(\"models/jena_conv1D_history.rds\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 6s - loss: 18.9587 - mae: 3.4415 - 6s/epoch - 14ms/step\n\n\n[1] \"Test MAE: 3.44\"\n\nKodplot(history)\n\n\n\n\n\n\n\nJak siÄ™ okazuje, model ten wypada jeszcze gorzej niÅ¼ model gÄ™sto poÅ‚Ä…czony, osiÄ…gajÄ…c jedynie testowy MAE na poziomie 3,4 stopnia, daleko od zdroworozsÄ…dkowej wartoÅ›ci bazowej. Co poszÅ‚o nie tak? Dwie rzeczy:\n\nPo pierwsze, dane pogodowe nie do koÅ„ca speÅ‚niajÄ… zaÅ‚oÅ¼enie o niezmiennoÅ›ci translacji. ChociaÅ¼ dane te charakteryzujÄ… siÄ™ cyklami dobowymi, dane z poranka majÄ… inne wÅ‚aÅ›ciwoÅ›ci niÅ¼ dane z wieczora lub ze Å›rodka nocy. Dane pogodowe sÄ… translacyjnie niezmienne tylko w bardzo okreÅ›lonej skali czasowej.\nPo drugie, kolejnoÅ›Ä‡ w naszych danych ma duÅ¼e znaczenie. Niedawna przeszÅ‚oÅ›Ä‡ jest znacznie bardziej pouczajÄ…ca dla przewidywania temperatury nastÄ™pnego dnia niÅ¼ dane sprzed piÄ™ciu dni. SieÄ‡ konwekcyjna 1D nie jest w stanie wykorzystaÄ‡ tego faktu. W szczegÃ³lnoÅ›ci nasze warstwy Å‚Ä…czenia maksymalnego i Å›redniego globalnego w duÅ¼ej mierze niszczÄ… informacje o kolejnoÅ›ci.\n\n5.1.4 Model LSTM\nAni w peÅ‚ni poÅ‚Ä…czone podejÅ›cie, ani podejÅ›cie konwolucyjne nie poradziÅ‚y sobie dobrze z zadanie, ale nie oznacza to, Å¼e uczenie maszynowe nie ma zastosowania do tego problemu. SieÄ‡ gÄ™sto poÅ‚Ä…czona najpierw spÅ‚aszczyÅ‚a szereg czasowy, co usunÄ™Å‚o pojÄ™cie czasu z danych wejÅ›ciowych. PodejÅ›cie konwolucyjne traktowaÅ‚o kaÅ¼dy segment danych w ten sam sposÃ³b, nawet stosujÄ…c Å‚Ä…czenie, ktÃ³re niszczyÅ‚o informacje o kolejnoÅ›ci. Zamiast tego spÃ³jrzmy na dane jako na to, czym sÄ… - sekwencjÄ…, w ktÃ³rej liczy siÄ™ przyczynowoÅ›Ä‡ i kolejnoÅ›Ä‡. W tym celu uÅ¼yjemy sieci LSTM.\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_lstm(16) %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\nhistory &lt;- model %&gt;% fit(\n  train_dataset,\n  epochs = 10,\n  validation_data = val_dataset\n)\n\nsave_model_tf(model, filepath = \"models/jena_lstm.keras\")\nsaveRDS(history, file = \"models/jena_lstm_history.rds\")\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_lstm.keras\")\nhistory &lt;- readRDS(\"models/jena_lstm_history.rds\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 5s - loss: 11.2176 - mae: 2.6383 - 5s/epoch - 12ms/step\n\n\n[1] \"Test MAE: 2.64\"\n\nKodplot(history)\n\n\n\n\n\n\n\nDalej nie udaÅ‚o siÄ™ pokonaÄ‡ modelu bazowego, ale jesteÅ›my juÅ¼ bardzo blisko. MoÅ¼na siÄ™ teÅ¼ zastanawiÄ…c dlaczego model LSTM wypadÅ‚ znacznie lepiej niÅ¼ model gÄ™sto poÅ‚Ä…czony lub Conv1D? I jak moÅ¼emy dalej udoskonalaÄ‡ ten model? Aby odpowiedzieÄ‡ na to pytanie, przyjrzyjmy siÄ™ bliÅ¼ej rekurencyjnym sieciom neuronowym.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Rodzaje szeregÃ³w czasowych</span>"
    ]
  },
  {
    "objectID": "rnn.html#rnn",
    "href": "rnn.html#rnn",
    "title": "\n5Â  Rodzaje szeregÃ³w czasowych\n",
    "section": "\n6.1 RNN",
    "text": "6.1 RNN\nRekurencyjne sieci neuronowe (ang. Recurrent Neural Network) sÄ… bardzo czÄ™sto uÅ¼ywanym typem sztucznych sieci neuronowych w rozwiÄ…zywaniu zadaÅ„, w ktÃ³rych wartoÅ›ci pewnych cech sÄ… obserwowane w nastÄ™pstwie czasowym. RNN sÄ… specjalnym typem sieci, ktÃ³re pozwalajÄ… na przechowywanie informacji â€œna pÃ³Åºniejâ€ w celu wykorzystania ich przewidywaniu przyszÅ‚ych wartoÅ›ci. W dalszej czÄ™Å›ci tego rozdziaÅ‚u zostanÄ… one szczegÃ³Å‚owo omÃ³wione. RozdziaÅ‚ ten jednak zaczniemy od przybliÅ¼enie z jakimi typami szeregÃ³w czasowych moÅ¼emy mieÄ‡ do czynienia i w jaki sposÃ³b moÅ¼emy uÅ¼ywaÄ‡ do nich sieci rekurencyjnych.\n\nKodmodel &lt;- keras_model_sequential() %&gt;%\n  layer_embedding(input_dim = 10000, output_dim = 32) %&gt;%\n  layer_simple_rnn(units = 32) # retunr only last state\n\nsummary(model)\n\n\nlub\n\nKodmodel &lt;- keras_model_sequential() %&gt;%\n  layer_embedding(input_dim = 10000, output_dim = 32) %&gt;%\n  layer_simple_rnn(units = 32, return_sequences = TRUE) # returns the full state sequence\n\nsummary(model)\n\n\nCzasami przydatne jest uÅ‚oÅ¼enie kilku warstw rekurencyjnych jedna po drugiej w celu zwiÄ™kszenia mocy reprezentacyjnej sieci. W takiej konfiguracji musisz pamiÄ™taÄ‡ wszystkie warstwy poÅ›rednie, aby zwrÃ³ciÄ‡ peÅ‚ne sekwencje:\n\nKodmodel &lt;- keras_model_sequential() %&gt;%\n  layer_embedding(input_dim = 10000, output_dim = 32) %&gt;%\n  layer_simple_rnn(units = 32, return_sequences = TRUE) %&gt;%\n  layer_simple_rnn(units = 32, return_sequences = TRUE) %&gt;%\n  layer_simple_rnn(units = 32, return_sequences = TRUE) %&gt;%\n  layer_simple_rnn(units = 32)\n\nsummary(model)",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Rodzaje szeregÃ³w czasowych</span>"
    ]
  },
  {
    "objectID": "rnn.html#lstm-i-gru",
    "href": "rnn.html#lstm-i-gru",
    "title": "\n5Â  Rodzaje szeregÃ³w czasowych\n",
    "section": "\n6.2 LSTM i GRU",
    "text": "6.2 LSTM i GRU\nProste RNN to nie jedyne warstwy rekurencyjne dostÄ™pne w keras. SÄ… jeszcze dwie inne: layer_lstm i layer_gru. W praktyce zawsze bÄ™dziemy uÅ¼ywaÄ‡ jednej z nich, poniewaÅ¼ layer_simple_rnn jest zbyt prosta, aby byÅ‚a naprawdÄ™ uÅ¼yteczna. Jednym z gÅ‚Ã³wnych problemÃ³w z layer_simple_rnn jest to, Å¼e chociaÅ¼ teoretycznie powinna ona byÄ‡ w stanie zachowaÄ‡ w czasie \\(t\\) informacje o wejÅ›ciach widzianych wiele krokÃ³w czasowych wczeÅ›niej, w praktyce takie dÅ‚ugoterminowe zaleÅ¼noÅ›ci sÄ… niemoÅ¼liwe do nauczenia. Wynika to z problemu znikajÄ…cego gradientu, efektu podobnego do tego, ktÃ³ry obserwuje siÄ™ w sieciach nierekursywnych (feedforward networks), ktÃ³re majÄ… wiele warstw: w miarÄ™ dodawania warstw do sieci, sieÄ‡ w koÅ„cu staje siÄ™ nie do wytrenowania. Teoretyczne przyczyny tego efektu byÅ‚y badane przez Bengio, Simard, i Frasconi (1994) we wczesnych latach 90-tych. Warstwy LSTM i GRU zostaÅ‚y zaprojektowane w celu rozwiÄ…zania tego problemu.\nWeÅºmy pod uwagÄ™ warstwÄ™ LSTM. LeÅ¼Ä…cy u podstaw algorytmu Long Short-Term Memory (LSTM) kod zostaÅ‚ opracowany przez Hochreiter i Schmidhuber (1997) byÅ‚ on zwieÅ„czeniem ich badaÅ„ nad problemem znikajÄ…cego gradientu.\nTa warstwa jest wariantem layer_simple_rnn, wzbogaconym o sposÃ³b na przenoszenie informacji przez wiele krokÃ³w czasowych. WyobraÅº sobie taÅ›mÄ™ transportowÄ… biegnÄ…cÄ… rÃ³wnolegle do sekwencji, ktÃ³rÄ… przetwarzasz. Informacja z sekwencji moÅ¼e wskoczyÄ‡ na taÅ›mÄ™ w dowolnym punkcie, zostaÄ‡ przetransportowana do pÃ³Åºniejszego kroku czasowego i wyskoczyÄ‡ z niej, nienaruszona, kiedy jej potrzebujesz. To jest zasadniczo to, co robi LSTM: zapisuje informacje na pÃ³Åºniej, zapobiegajÄ…c w ten sposÃ³b stopniowemu znikaniu starszych sygnaÅ‚Ã³w podczas przetwarzania.\n\n\n\n\n\nRysunekÂ 6.2: Schemat sieci LSTM\n\n\nTypowa jednostka LSTM skÅ‚ada siÄ™ z komÃ³rki (ang. cell), bramki wejÅ›ciowej (ang. input gate), bramki wyjÅ›ciowej (ang. output gate) i bramki zapomnienia (ang. forget gate). KomÃ³rka zapamiÄ™tuje wartoÅ›ci w dowolnych odstÄ™pach czasu, a trzy bramki regulujÄ… przepÅ‚yw informacji do i z komÃ³rki. Bramki zapominania decydujÄ… o tym, jakie informacje z poprzedniego stanu naleÅ¼y odrzuciÄ‡, przypisujÄ…c poprzedniemu stanowi, w porÃ³wnaniu z bieÅ¼Ä…cym wejÅ›ciem, wartoÅ›Ä‡ z przedziaÅ‚u od 0 do 1. WartoÅ›Ä‡ 1 oznacza zachowanie informacji, a wartoÅ›Ä‡ 0 - jej odrzucenie. Bramki wejÅ›ciowe decydujÄ…, ktÃ³re kawaÅ‚ki nowej informacji zapisaÄ‡ w bieÅ¼Ä…cym stanie, uÅ¼ywajÄ…c tego samego systemu co bramki zapomnienia. Bramki wyjÅ›ciowe kontrolujÄ…, ktÃ³re fragmenty informacji z bieÅ¼Ä…cego stanu naleÅ¼y wypisaÄ‡, przypisujÄ…c im wartoÅ›Ä‡ od 0 do 1, biorÄ…c pod uwagÄ™ stan poprzedni i bieÅ¼Ä…cy. Selektywne wyprowadzanie odpowiednich informacji z bieÅ¼Ä…cego stanu pozwala sieci LSTM zachowaÄ‡ uÅ¼yteczne, dÅ‚ugoterminowe zaleÅ¼noÅ›ci, pozwalajÄ…ce na dokonywanie przewidywaÅ„, zarÃ³wno w bieÅ¼Ä…cych, jak i przyszÅ‚ych krokach czasowych.\nWrÃ³Ä‡my do modelu opartego na LSTM, ktÃ³rego uÅ¼ywaliÅ›my w przykÅ‚adzie przewidywania temperatury. JeÅ›li spojrzymy na krzywe uczenia, oczywiste jest, Å¼e model szybko ulega przeuczeniu (funkcje straty zaczynajÄ… siÄ™ znacznie rÃ³Å¼niÄ‡ po kilku epokach), mimo Å¼e jest doÅ›Ä‡ prosty. Znamy juÅ¼ klasycznÄ… technikÄ™ przeciwdziaÅ‚ania temu zjawisku. Dropout, ktÃ³ry losowo zeruje jednostki wejÅ›ciowe warstwy, aby przerwaÄ‡ przypadkowe korelacje w danych treningowych, na ktÃ³re naraÅ¼ona jest warstwa. Jednak to, jak prawidÅ‚owo stosowaÄ‡ dropout w sieciach rekurencyjnych, nie jest trywialnym pytaniem.\nSprawdzono, Å¼e zastosowanie dropout przed warstwÄ… rekurencyjnÄ… raczej utrudnia uczenie siÄ™ niÅ¼ pomaga w regularyzacji. W 2016 roku Yarin Gal, w ramach swojej pracy doktorskiej na temat gÅ‚Ä™bokiego uczenia bayesowskiego, okreÅ›liÅ‚ wÅ‚aÅ›ciwy sposÃ³b stosowania dropoutu w sieci rekurencyjnej: ta sama maska dropoutu (ten sam wzÃ³r porzuconych jednostek) powinna byÄ‡ stosowana w kaÅ¼dym kroku czasowym, zamiast stosowania maski dropoutu, ktÃ³ra zmienia siÄ™ losowo z kroku na krok czasowy. Co wiÄ™cej, aby uregulowaÄ‡ reprezentacje utworzone przez rekurencyjne bramki warstw, takich jak layer_gru() i layer_lstm(), do wewnÄ™trznych rekurencyjnych aktywacji warstwy naleÅ¼y zastosowaÄ‡ czasowo staÅ‚Ä… maskÄ™ dropout (rekurencyjnÄ… maskÄ™ porzucania). UÅ¼ywanie tej samej maski porzucania w kaÅ¼dym kroku czasowym pozwala sieci na prawidÅ‚owÄ… propagacjÄ™ bÅ‚Ä™du uczenia siÄ™ w czasie; czasowo losowa maska porzucania zakÅ‚Ã³ciÅ‚aby ten sygnaÅ‚ bÅ‚Ä™du i byÅ‚aby szkodliwa dla procesu uczenia siÄ™.\nYarin Gal przeprowadziÅ‚ swoje badania przy uÅ¼yciu keras i pomÃ³gÅ‚ zaimplementowaÄ‡ ten mechanizm bezpoÅ›rednio w warstwach rekurencyjnych keras. KaÅ¼da warstwa rekurencyjna w keras ma dwa argumenty zwiÄ…zane z dropout: dropout, zmienna okreÅ›lajÄ…ca wspÃ³Å‚czynnik porzucenia dla jednostek wejÅ›ciowych warstwy, oraz recurrent_dropout, okreÅ›lajÄ…ca wspÃ³Å‚czynnik porzucenia dla jednostek rekurencyjnych. Dodajmy rekurencyjne porzucanie do funkcji layer_lstm() naszego przykÅ‚adu LSTM i zobaczmy, jak wpÅ‚ywa to na overfitting.\nDziÄ™ki dropoutowi nie bÄ™dziemy musieli tak bardzo polegaÄ‡ na rozmiarze sieci do regularyzacji, wiÄ™c uÅ¼yjemy warstwy LSTM z dwukrotnie wiÄ™kszÄ… liczbÄ… jednostek, co powinno, miejmy nadziejÄ™, byÄ‡ bardziej wyraziste (bez dropoutu ta sieÄ‡ od razu zaczÄ™Å‚aby siÄ™ przeuczaÄ‡2). PoniewaÅ¼ sieci regularyzowane z dropoutem zawsze potrzebujÄ… znacznie wiÄ™cej czasu, aby osiÄ…gnÄ…Ä‡ zbieÅ¼noÅ›Ä‡, bÄ™dziemy trenowaÄ‡ model przez piÄ™Ä‡ razy wiÄ™cej epok.\n2Â moÅ¼esz sam sprÃ³bowaÄ‡\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_lstm(32, recurrent_dropout = 0.25) %&gt;%\n  layer_dropout(0.5) %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\nhistory &lt;- model %&gt;% fit(\n  train_dataset,\n  epochs = 50,\n  validation_data = val_dataset\n)\nsave_model_tf(\"models/jena_lstm_dropout.keras\")\n\n\n\n\n\n\n\n\nZagroÅ¼enie\n\n\n\nModele rekurencyjne z bardzo maÅ‚Ä… liczbÄ… parametrÃ³w, takie jak te w tym rozdziale, sÄ… zwykle znacznie szybsze na wielordzeniowym CPU niÅ¼ na GPU, poniewaÅ¼ obejmujÄ… tylko mnoÅ¼enia maÅ‚ych macierzy, a Å‚aÅ„cuch mnoÅ¼eÅ„ nie jest dobrze zrÃ³wnoleglony ze wzglÄ™du na obecnoÅ›Ä‡ pÄ™tli for. WiÄ™ksze sieci RNN mogÄ… jednak w znacznym stopniu skorzystaÄ‡ z moÅ¼liwoÅ›ci GPU.\nPodczas korzystania z warstw LSTM i GRU na GPU z domyÅ›lnymi argumentami, warstwy bÄ™dÄ… wykorzystywaÄ‡ jÄ…dro cuDNN, wysoce zoptymalizowanÄ…, niskopoziomowÄ… implementacjÄ™ algorytmu dostarczonÄ… przez firmÄ™ NVIDIA. Niestety, jÄ…dra cuDNN sÄ… wÄ…tpliwym bÅ‚ogosÅ‚awieÅ„stwem: sÄ… szybkie, ale nieelastyczne - jeÅ›li sprÃ³bujemy zrobiÄ‡ coÅ›, co nie jest obsÅ‚ugiwane przez domyÅ›lne jÄ…dro, doÅ›wiadczymy dramatycznego spowolnienia. PrzykÅ‚adowo, rekurencyjny dropout nie jest obsÅ‚ugiwany przez jÄ…dra LSTM i GRU cuDNN, wiÄ™c dodanie go do warstw zmusza algorytm do wykonywania na zwykÅ‚ej implementacji TensorFlow, ktÃ³ra jest generalnie od dwÃ³ch do piÄ™ciu razy wolniejsza na GPU (mimo Å¼e jej koszt obliczeniowy jest taki sam).\nAby przyspieszyÄ‡ dziaÅ‚anie warstwy RNN, gdy nie moÅ¼na uÅ¼yÄ‡ cuDNN, moÅ¼na sprÃ³bowaÄ‡ jÄ… rozwinÄ…Ä‡ (ang. unfold). Rozwijanie pÄ™tli for polega na usuniÄ™ciu pÄ™tli i po prostu wpisaniu jej zawartoÅ›ci N razy. W przypadku pÄ™tli for sieci RNN, rozwijanie moÅ¼e pomÃ³c TensorFlow zoptymalizowaÄ‡ bazowy graf obliczeniowy. Jednak znacznie zwiÄ™kszy to rÃ³wnieÅ¼ zuÅ¼ycie pamiÄ™ci przez sieÄ‡ RNN. W zwiÄ…zku z tym jest to opÅ‚acalne tylko w przypadku stosunkowo maÅ‚ych sekwencji (okoÅ‚o 100 krokÃ³w lub mniej). NaleÅ¼y rÃ³wnieÅ¼ pamiÄ™taÄ‡, Å¼e moÅ¼na to zrobiÄ‡ tylko wtedy, gdy liczba krokÃ³w czasowych w danych jest znana z gÃ³ry przez model. DziaÅ‚a to w nastÄ™pujÄ…cy sposÃ³b:\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, num_features))\nx &lt;- inputs %&gt;% layer_lstm(32, recurrent_dropout = 0.2, unroll = TRUE)\n\n\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_lstm_dropout.keras\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 273s - loss: 10.2870 - mae: 2.5415 - 273s/epoch - 675ms/step\n\n\n[1] \"Test MAE: 2.54\"\n\n\n\n\n\n\n\nRysunekÂ 6.3\n\n\nRysunekÂ 6.3 przedstawia wyniki uczenia. UsuniÄ™to przeuczenie (do co najmniej 20 epoki). OsiÄ…gamy MAE walidacji na poziomie zaledwie 2,37 stopnia (2,5% poprawa w stosunku do modelu bazowego bez uczenia) i testowy MAE na poziomie 2,54 stopnia (3% poprawa w stosunku do lini bazowej).\nPoniewaÅ¼ overfitting nie jest juÅ¼ tak wyraÅºnym problemem, ale wydaje siÄ™, Å¼e trafiliÅ›my na wÄ…skie gardÅ‚o wydajnoÅ›ci, powinniÅ›my rozwaÅ¼yÄ‡ zwiÄ™kszenie pojemnoÅ›ci i mocy obliczeniowej sieci. Przypomnijmy sobie opis uniwersalnego przepÅ‚ywu pracy uczenia maszynowego: generalnie dobrym pomysÅ‚em jest zwiÄ™kszenie pojemnoÅ›ci modelu, dopÃ³ki overfitting nie stanie siÄ™ gÅ‚Ã³wnym problemem.\nZwiÄ™kszenie pojemnoÅ›ci sieci odbywa siÄ™ zazwyczaj poprzez zwiÄ™kszenie liczby neuronÃ³w w warstwach lub dodanie wiÄ™kszej liczby warstw. SkÅ‚adanie warstw rekurencyjnych to klasyczny sposÃ³b budowania potÄ™Å¼niejszych sieci rekurencyjnych. Aby ukÅ‚adaÄ‡ warstwy rekurencyjne jedna na drugiej w Kerasie, wszystkie warstwy poÅ›rednie powinny zwracaÄ‡ peÅ‚nÄ… sekwencjÄ™ swoich wyjÅ›Ä‡ (tensor rangi 3), a nie swoje wyjÅ›cie w ostatnim kroku czasowym. Jak juÅ¼ siÄ™ dowiedzieliÅ›my, odbywa siÄ™ to poprzez ustawienie flagi return_ sequences = TRUE.\nW poniÅ¼szym przykÅ‚adzie wyprÃ³bujemy stos dwÃ³ch warstw rekurencyjnych z regularyzacjÄ… dropout. Dla odmiany uÅ¼yjemy warstw Gated Recurrent Unit (GRU) zamiast LSTM. GRU jest bardzo podobny do LSTM - moÅ¼na o nim myÅ›leÄ‡ jako o nieco prostszej, usprawnionej wersji architektury LSTM. ZostaÅ‚a ona wprowadzona w 2014 roku przez Cho i in. (b.d.), gdy sieci rekurencyjne dopiero zaczynaÅ‚y na nowo zyskiwaÄ‡ zainteresowanie w niewielkiej wÃ³wczas spoÅ‚ecznoÅ›ci badawczej.\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_gru(32, recurrent_dropout = 0.5, return_sequences = TRUE) %&gt;%\n  layer_gru(32, recurrent_dropout = 0.5) %&gt;%\n  layer_dropout(0.5) %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\nhistory &lt;- model %&gt;% fit(\n  train_dataset,\n  epochs = 50,\n  validation_data = val_dataset\n)\nsave_model_tf(\"models/jena_gru_dropout.keras\")\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_gru_dropout.keras\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 577s - loss: 9.6074 - mae: 2.4491 - 577s/epoch - 1s/step\n\n\n[1] \"Test MAE: 2.45\"\n\n\n\n\n\n\n\nRysunekÂ 6.4\n\n\n?fig-gru-dropout przedstawia wyniki uczenia. OsiÄ…gnÄ™liÅ›my testowy MAE na poziomie 2,45 stopnia (poprawa o 6,5% w stosunku do linii bazowej). WidaÄ‡, Å¼e dodana warstwa nieco poprawia wyniki, choÄ‡ nie dramatycznie, zatem moÅ¼na zaobserwowaÄ‡ malejÄ…ce zyski ze zwiÄ™kszania pojemnoÅ›ci sieci.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Rodzaje szeregÃ³w czasowych</span>"
    ]
  },
  {
    "objectID": "rnn.html#dwukierunkowe-sieci-rekurencyjne",
    "href": "rnn.html#dwukierunkowe-sieci-rekurencyjne",
    "title": "\n5Â  Rodzaje szeregÃ³w czasowych\n",
    "section": "\n6.3 Dwukierunkowe sieci rekurencyjne",
    "text": "6.3 Dwukierunkowe sieci rekurencyjne\nOstatniÄ… technikÄ…, ktÃ³rej przyjrzymy siÄ™ w tej sekcji, jest dwukierunkowa sieÄ‡ RNN. Dwukierunkowy RNN jest powszechnym wariantem RNN, ktÃ³ry moÅ¼e oferowaÄ‡ wiÄ™kszÄ… wydajnoÅ›Ä‡ niÅ¼ zwykÅ‚y RNN w niektÃ³rych zadaniach. Jest czÄ™sto uÅ¼ywany w przetwarzaniu jÄ™zyka naturalnego - moÅ¼na go nazwaÄ‡ szwajcarskim scyzorykiem gÅ‚Ä™bokiego uczenia siÄ™ do przetwarzania jÄ™zyka naturalnego.\nRNN sÄ… w szczegÃ³lnoÅ›ci zaleÅ¼ne od kolejnoÅ›ci: przetwarzajÄ… kroki czasowe swoich sekwencji wejÅ›ciowych w kolejnoÅ›ci, a tasowanie lub odwracanie krokÃ³w czasowych moÅ¼e caÅ‚kowicie zmieniÄ‡ reprezentacje, ktÃ³re RNN wyodrÄ™bnia z sekwencji. To jest wÅ‚aÅ›nie powÃ³d, dla ktÃ³rego dobrze radzÄ… sobie z problemami, w ktÃ³rych kolejnoÅ›Ä‡ ma znaczenie, takimi jak problem prognozowania temperatury. Dwukierunkowa RNN wykorzystuje wraÅ¼liwoÅ›Ä‡ RNN na kolejnoÅ›Ä‡: wykorzystuje dwie zwykÅ‚e RNN, takie jak GRU i LSTM, z ktÃ³rych kaÅ¼da przetwarza sekwencjÄ™ wejÅ›ciowÄ… w jednym kierunku (chronologicznie i antychronologicznie), a nastÄ™pnie Å‚Ä…czy ich reprezentacje. PrzetwarzajÄ…c sekwencjÄ™ w obie strony, dwukierunkowa sieÄ‡ RNN moÅ¼e wychwyciÄ‡ wzorce, ktÃ³re mogÄ… zostaÄ‡ przeoczone przez jednokierunkowÄ… sieÄ‡ RNN.\nCzy RNN mogÅ‚yby dziaÅ‚aÄ‡ wystarczajÄ…co dobrze, gdyby na przykÅ‚ad przetwarzaÅ‚y sekwencje wejÅ›ciowe w porzÄ…dku antychronologicznym (z nowszymi krokami czasowymi jako pierwszymi)? SprÃ³bujmy tego i zobaczmy, co siÄ™ stanie. Wszystko, co musimy zrobiÄ‡, to zmodyfikowaÄ‡ zestaw danych TF, aby sekwencje wejÅ›ciowe zostaÅ‚y odwrÃ³cone wzdÅ‚uÅ¼ wymiaru czasu. Wystarczy przeksztaÅ‚ciÄ‡ zbiÃ³r danych za pomocÄ… funkcji dataset_map() w nastÄ™pujÄ…cy sposÃ³b:\n\nKoddataset_map(function(samples, targets) {\n  list(samples[, NA:NA:-1, ], targets)\n})\n\n\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_lstm(16) %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\ncallbacks &lt;- list(callback_model_checkpoint(\"jena_lstm_reversed\",\n                                            save_best_only = TRUE))\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\ndataset_reverse_time &lt;- function(ds) {\n  dataset_map(ds, function(samples, targets)\n    list(samples[, NA:NA:-1, ], targets))\n}\nhistory &lt;- model %&gt;% fit(\n  train_dataset %&gt;% dataset_reverse_time(),\n  epochs = 10,\n  validation_data = val_dataset %&gt;% dataset_reverse_time(),\n  callbacks = callbacks\n)\nsave_model_tf(model, \"models/jena_lstm_rev.keras\")\nsaveRDS(history, \"models/jena_lstm_rev_hist.rds\")\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_lstm_rev.keras\")\nhistory &lt;- readRDS(\"models/jena_lstm_rev_hist.rds\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 5s - loss: 22.8799 - mae: 3.8075 - 5s/epoch - 12ms/step\n\n\n[1] \"Test MAE: 3.81\"\n\nKodplot(history)\n\n\n\n\n\n\n\nLSTM z odwrÃ³conym czasem silnie ustÄ™puje nawet zdroworozsÄ…dkowemu poziomowi bazowemu, wskazujÄ…c, Å¼e w tym przypadku przetwarzanie chronologiczne jest waÅ¼ne dla powodzenia tego podejÅ›cia. Ma to sens: warstwa LSTM zazwyczaj lepiej zapamiÄ™tuje niedawnÄ… przeszÅ‚oÅ›Ä‡ niÅ¼ odlegÅ‚Ä… przeszÅ‚oÅ›Ä‡, a naturalnie bardziej aktualne dane pogodowe niosÄ… w sobie wiÄ™cej informacji niÅ¼ starsze dane (to wÅ‚aÅ›nie sprawia, Å¼e zdroworozsÄ…dkowa linia bazowa jest doÅ›Ä‡ silna). Tak wiÄ™c chronologiczna wersja sieci z pewnoÅ›ciÄ… przewyÅ¼szy wersjÄ™ z odwrÃ³conym porzÄ…dkiem.\nNie jest to jednak prawdÄ… w przypadku wielu innych problemÃ³w, w tym jÄ™zyka naturalnego: intuicyjnie, znaczenie sÅ‚owa w zrozumieniu zdania zwykle nie zaleÅ¼y od jego pozycji w zdaniu. W przypadku danych tekstowych, przetwarzanie w odwrÃ³conej kolejnoÅ›ci dziaÅ‚a rÃ³wnie dobrze jak przetwarzanie chronologiczne - moÅ¼na czytaÄ‡ tekst od tyÅ‚u. ChociaÅ¼ kolejnoÅ›Ä‡ sÅ‚Ã³w ma znaczenie dla zrozumienia jÄ™zyka, to kolejnoÅ›Ä‡, ktÃ³rej uÅ¼ywamy, nie jest kluczowa. Co waÅ¼ne, RNN wytrenowana na odwrÃ³conych sekwencjach nauczy siÄ™ innych reprezentacji niÅ¼ ta wytrenowana na oryginalnych sekwencjach, podobnie jak w prawdziwym Å›wiecie mielibyÅ›my inne modele mentalne, gdyby czas pÅ‚ynÄ…Å‚ wstecz - gdybyÅ›my Å¼yli Å¼yciem, w ktÃ³rym umieramy pierwszego dnia i rodzimy siÄ™ ostatniego. W uczeniu maszynowym reprezentacje, ktÃ³re sÄ… uÅ¼yteczne, sÄ… zawsze warte wykorzystania, a im bardziej siÄ™ rÃ³Å¼niÄ…, tym lepiej, bo oferujÄ… nowy kÄ…t, z ktÃ³rego moÅ¼na spojrzeÄ‡ na dane, wychwytujÄ…c aspekty danych, ktÃ³re zostaÅ‚y pominiÄ™te przez inne podejÅ›cia, a tym samym mogÄ… pomÃ³c zwiÄ™kszyÄ‡ wydajnoÅ›Ä‡ zadania.\nDwukierunkowa sieÄ‡ RNN wykorzystuje ten pomysÅ‚, aby poprawiÄ‡ wydajnoÅ›Ä‡ sieci RNN z porzÄ…dkiem chronologicznym. Analizuje sekwencjÄ™ wejÅ›ciowÄ… w obie strony (patrz RysunekÂ 6.5), uzyskujÄ…c potencjalnie bogatsze reprezentacje i wychwytujÄ…c wzorce, ktÃ³re mogÅ‚y zostaÄ‡ pominiÄ™te przez samÄ… wersjÄ™ chronologicznÄ….\n\n\n\n\n\nRysunekÂ 6.5: Zasada dziaÅ‚ania warstw dwukierunkowych\n\n\nAby utworzyÄ‡ instancjÄ™ dwukierunkowej RNN w Keras, naleÅ¼y uÅ¼yÄ‡ warstw bidirectional(), ktÃ³re jako pierwszy argument przyjmujÄ… instancjÄ™ warstwy rekurencyjnej. bidirectional() tworzy drugÄ…, oddzielnÄ… instancjÄ™ tej warstwy rekurencyjnej i wykorzystuje jednÄ… instancjÄ™ do przetwarzania sekwencji wejÅ›ciowych w porzÄ…dku chronologicznym, a drugÄ… instancjÄ™ do przetwarzania sekwencji wejÅ›ciowych w porzÄ…dku odwrÃ³conym.\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  bidirectional(layer_lstm(units = 16)) %&gt;%\n  layer_dense(1)\n\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\nhistory &lt;- model %&gt;%\n  fit(train_dataset,\n      epochs = 10,\n      validation_data = val_dataset)\n\nsave_model_tf(model, \"models/jena_lstm_bi.keras\")\nsaveRDS(history, \"models/jena_lstm_bi_hist.rds\")\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_lstm_bi.keras\")\nhistory &lt;- readRDS(\"models/jena_lstm_bi_hist.rds\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 8s - loss: 10.8280 - mae: 2.5962 - 8s/epoch - 21ms/step\n\n\n[1] \"Test MAE: 2.60\"\n\nKodplot(history)\n\n\n\n\n\n\n\nJeÅ›li porÃ³wnamy wyniki do zwykÅ‚ej layer_lstm(), to zauwaÅ¼ymy tylko nieznacznÄ… poprawÄ™ wynikÃ³w. Åatwo jest zrozumieÄ‡, dlaczego - niemal caÅ‚a zdolnoÅ›Ä‡ predykcyjna musi pochodziÄ‡ z chronologicznej poÅ‚owy sieci, poniewaÅ¼ wiadomo, Å¼e antychronologiczna poÅ‚owa ma znacznie gorsze wyniki w tym zadaniu (ponownie, poniewaÅ¼ niedawna przeszÅ‚oÅ›Ä‡ ma w tym przypadku znacznie wiÄ™ksze znaczenie niÅ¼ odlegÅ‚a przeszÅ‚oÅ›Ä‡). JednoczeÅ›nie obecnoÅ›Ä‡ antychronologicznej poÅ‚owy podwaja pojemnoÅ›Ä‡ sieci i powoduje, Å¼e zaczyna siÄ™ ona przeuczaÄ‡ znacznie wczeÅ›niej.\nJednak dwukierunkowe sieci RNN doskonale nadajÄ… siÄ™ do danych tekstowych lub innych rodzajÃ³w danych, w ktÃ³rych kolejnoÅ›Ä‡ ma znaczenie, ale gdzie kolejnoÅ›Ä‡, ktÃ³rej uÅ¼ywasz, nie ma znaczenia. W rzeczywistoÅ›ci aÅ¼ do roku 2016 dwukierunkowe LSTM byÅ‚y uwaÅ¼ane za najnowoczeÅ›niejsze w wielu zadaniach przetwarzania jÄ™zyka naturalnego (przed pojawieniem siÄ™ architektury Transformer, o ktÃ³rej bÄ™dzie nieco pÃ³Åºniej).\nIstnieje wiele innych rzeczy, ktÃ³re moÅ¼na wyprÃ³bowaÄ‡ w celu poprawy wydajnoÅ›ci prognozowania temperatury:\n\nDostosowaÄ‡ liczbÄ™ neuronÃ³w w kaÅ¼dej warstwie rekurencyjnej, a takÅ¼e iloÅ›Ä‡ porzuconych neurnonÃ³w. Obecne wybory sÄ… w duÅ¼ej mierze arbitralne, a zatem prawdopodobnie nieoptymalne.\nDostosowaÄ‡ szybkoÅ›Ä‡ uczenia optymalizatora RMSprop lub wyprÃ³bowaÄ‡ inny optymalizator.\nUÅ¼yÄ‡ stosu kilku warstw gÄ™stych layer_dense() jako regresora na wierzchu warstwy rekurencyjnej, zamiast pojedynczej.\nUlepszyÄ‡ dane wejÅ›ciowe do modelu - uÅ¼yÄ‡ dÅ‚uÅ¼szych lub krÃ³tszych sekwencji lub innej czÄ™stotliwoÅ›ci prÃ³bkowania lub wykonaÄ‡ inÅ¼ynieriÄ™ cech.\n\n\n\n\n\n\n\nWskazÃ³wka\n\n\n\nGÅ‚Ä™bokie uczenie jest bardziej sztukÄ… niÅ¼ naukÄ…. MoÅ¼emy dostarczaÄ‡ wskazÃ³wek, ktÃ³re sugerujÄ…, co moÅ¼e dziaÅ‚aÄ‡ lub nie dziaÅ‚aÄ‡ w danym problemie, ale ostatecznie kaÅ¼dy zbiÃ³r danych jest wyjÄ…tkowy; bÄ™dziesz musiaÅ‚ empirycznie oceniÄ‡ rÃ³Å¼ne strategie. Obecnie nie istnieje Å¼adna teoria, ktÃ³ra z gÃ³ry powiedziaÅ‚aby, co powinniÅ›my zrobiÄ‡, aby optymalnie rozwiÄ…zaÄ‡ dany problem.\n\n\n\n\n\n\n\n\nOstrzeÅ¼enie\n\n\n\nNiektÃ³rzy czytelnicy z pewnoÅ›ciÄ… bÄ™dÄ… chcieli skorzystaÄ‡ z technik, ktÃ³re tu przedstawiliÅ›my i wyprÃ³bowaÄ‡ je w problemie prognozowania przyszÅ‚ych cen papierÃ³w wartoÅ›ciowych na gieÅ‚dzie (lub kursÃ³w wymiany walut itp.). Rynki majÄ… jednak zupeÅ‚nie innÄ… charakterystykÄ™ statystycznÄ… niÅ¼ zjawiska naturalne, takie jak wzorce pogodowe. JeÅ›li chodzi o rynki, przeszÅ‚e wyniki nie sÄ… dobrym predyktorem przyszÅ‚ych zwrotÃ³w3. Z drugiej strony uczenie maszynowe ma zastosowanie do zbiorÃ³w danych, w ktÃ³rych przeszÅ‚oÅ›Ä‡ jest dobrym predyktorem przyszÅ‚oÅ›ci, takich jak pogoda, zuÅ¼ycie energii elektrycznej lub ruch pieszych na danym odcinku drogi.\nZawsze pamiÄ™tajmy, Å¼e caÅ‚y handel papierami wartoÅ›ciowymi jest zasadniczo arbitraÅ¼em informacyjnym: zdobywaniem przewagi poprzez wykorzystanie danych lub spostrzeÅ¼eÅ„, ktÃ³rych brakuje innym uczestnikom rynku. PrÃ³ba wykorzystania dobrze znanych technik uczenia maszynowego i publicznie dostÄ™pnych danych w celu pokonania rynkÃ³w jest w rzeczywistoÅ›ci Å›lepym zauÅ‚kiem, poniewaÅ¼ nie bÄ™dzie dawaÄ‡ Å¼adnej przewagi informacyjnej w porÃ³wnaniu do wszystkich innych.\n\n\n\n\n3Â patrzenie w lusterko wsteczne nie jest najlepszÄ… metodÄ… prowadzenia auta ğŸ™‰ ğŸ¤”\n\nBengio, Y., P. Simard, i P. Frasconi. 1994. â€Learning long-term dependencies with gradient descent is difficultâ€. IEEE Transactions on Neural Networks 5 (2): 157â€“66. https://doi.org/10.1109/72.279181.\n\n\nCho, Kyunghyun, Bart van Merrienboer, Dzmitry Bahdanau, i Yoshua Bengio. b.d. â€On the Properties of Neural Machine Translation: Encoder-Decoder Approachesâ€. https://doi.org/10.48550/arXiv.1409.1259.\n\n\nHochreiter, Sepp, i JÃ¼rgen Schmidhuber. 1997. â€Long Short-Term Memoryâ€. Neural Computation 9 (8): 1735â€“80. https://doi.org/10.1162/neco.1997.9.8.1735.",
    "crumbs": [
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Rodzaje szeregÃ³w czasowych</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatura",
    "section": "",
    "text": "Bengio, Y., P. Simard, and P. Frasconi. 1994. â€œLearning Long-Term\nDependencies with Gradient Descent Is Difficult.â€ IEEE\nTransactions on Neural Networks 5 (2): 157â€“66. https://doi.org/10.1109/72.279181.\n\n\nBorchani, Hanen, Gherardo Varando, Concha Bielza, and Pedro LarraÃ±aga.\n2015. â€œA Survey on Multi-Output Regression.â€ WIREs Data\nMining and Knowledge Discovery 5 (5): 216â€“33. https://doi.org/10.1002/widm.1157.\n\n\nBreiman, Leo, J. H. Friedman, Richard A. Olshen, and Charles J. Stone.\n2017. Classification and Regression Trees. Routledge. http://search.ebscohost.com/login.aspx?direct=true&db=edsebk&AN=1619230&lang=pl&site=eds-live&scope=site.\n\n\nCho, Kyunghyun, Bart van Merrienboer, Dzmitry Bahdanau, and Yoshua\nBengio. n.d. â€œOn the Properties of Neural Machine Translation:\nEncoder-Decoder Approaches.â€ https://doi.org/10.48550/arXiv.1409.1259.\n\n\nEvgeniou, Theodoros, and Massimiliano Pontil. 2004. â€œRegularized\nMultiâ€“Task Learning.â€ Proceedings of the Tenth ACM SIGKDD\nInternational Conference on Knowledge Discovery and Data Mining,\nAugust. https://doi.org/10.1145/1014052.1014067.\n\n\nFaddoul, Jean Baptiste, Boris Chidlovskii, RÃ©mi Gilleron, and Fabien\nTorre. 2012. â€œLearning Multiple Tasks with Boosted Decision\nTrees.â€ In Proceedings of the 2012th European Conference on\nMachine Learning and Knowledge Discovery in Databases - Volume Part\ni, 681â€“96. ECMLPKDDâ€™12. Springer-Verlag.\n\n\nFaddoul, Jean Baptiste, Boris Chidlovskii, Fabien Torre, and Remi\nGilleron. 2010. â€œBoosting Multi-Task Weak Learners with\nApplications to Textual and Social Data.â€ In 2010 Ninth\nInternational Conference on Machine Learning and Applications,\n367â€“72. IEEE. https://doi.org/10.1109/ICMLA.2010.61.\n\n\nGlocker, Ben, Olivier Pauly, Ender Konukoglu, and Antonio Criminisi.\n2012. â€œJoint Classification-Regression Forests for Spatially\nStructured Multi-Object Segmentation.â€ In Computer Vision â€“\nECCV 2012, edited by Andrew Fitzgibbon, Svetlana Lazebnik, Pietro\nPerona, Yoichi Sato, and Cordelia Schmid, 7575:870â€“81. Springer Berlin\nHeidelberg. http://link.springer.com/10.1007/978-3-642-33765-9_62.\n\n\nHochreiter, Sepp, and JÃ¼rgen Schmidhuber. 1997. â€œLong\nShort-Term Memory.â€ Neural Computation 9\n(8): 1735â€“80. https://doi.org/10.1162/neco.1997.9.8.1735.\n\n\nIzenman, Alan Julian. 1975. â€œReduced-Rank Regression for the\nMultivariate Linear Model.â€ Journal of Multivariate\nAnalysis 5 (2): 248â€“64.\n\n\nKocev, Dragi, Celine Vens, Jan Struyf, and SaÅ¡o DÅ¾eroski. 2013.\nâ€œTree Ensembles for Predicting Structured Outputs.â€\nPattern Recognition 46 (3): 817â€“33. https://doi.org/10.1016/j.patcog.2012.09.023.\n\n\nMelki, Gabriella, Alberto Cano, Vojislav Kecman, and SebastiÃ¡n Ventura.\n2017. â€œMulti-Target Support Vector Regression via Correlation\nRegressor Chains.â€ Information Sciences 415â€“416\n(November): 53â€“69. https://doi.org/10.1016/j.ins.2017.06.017.\n\n\nQuinlan, J Ross. 1993. C4. 5: Programs for Machine Learning.\nMorgan Kaufmann.\n\n\nSantana, Everton Jose, Felipe Rodrigues dos Santos, Saulo Martiello\nMastelini, Fabio Luiz Melquiades, and Sylvio Barbon Jr. 2020.\nâ€œImproved Prediction of Soil Properties with Multi-Target Stacked\nGeneralisation on EDXRF Spectra.â€ arXiv Preprint\narXiv:2002.04312. https://arxiv.org/abs/2002.04312.\n\n\nSegal, Mark Robert. 1992. â€œTree-Structured Methods for\nLongitudinal Data.â€ Journal of the American Statistical\nAssociation 87 (418): 407â€“18. https://doi.org/10.2307/2290271.\n\n\nSpyromitros-Xioufis, Eleftherios, Grigorios Tsoumakas, William Groves,\nand Ioannis Vlahavas. 2016. â€œMulti-Target Regression\nvia Input Space Expansion: Treating Targets as\nInputs.â€ Machine Learning 104 (1): 55â€“98.\nhttps://doi.org/10.1007/s10994-016-5546-z.\n\n\nStruyf, Jan, and SaÅ¡o DÅ¾eroski. 2006. â€œConstraint Based Induction\nof Multi-Objective Regression Trees.â€ In Knowledge Discovery\nin Inductive Databases, edited by Francesco Bonchi and\nJean-FranÃ§ois Boulicaut, 222â€“33. Lecture Notes in Computer Science.\nSpringer. https://doi.org/10.1007/11733492_13.\n\n\nTawiah, Clifford, and Victor Sheng. 2013. â€œEmpirical Comparison of\nMulti-Label Classification Algorithms.â€ In Proceedings of the\nAAAI Conference on Artificial\nIntelligence, 27:1645â€“46.\n\n\nTsoumakas, Grigorios, and Ioannis Katakis. 2007. â€œMulti-Label\nClassification: An Overview.â€ International\nJournal of Data Warehousing and Mining (IJDWM) 3 (3): 1â€“13.\n\n\nVazquez, Emmanuel, and Eric Walter. 2003. â€œMulti-Output Suppport\nVector Regression.â€ IFAC Proceedings Volumes, 13th IFAC\nsymposium on system identification (SYSID 2003), rotterdam, the\nnetherlands, 27-29 august, 2003, 36 (16): 1783â€“88. https://doi.org/10.1016/S1474-6670(17)35018-8.\n\n\nXu, Yitian, Rui Guo, and Laisheng Wang. 2013. â€œA Twin Multi-Class\nClassification Support Vector Machine.â€ Cognitive\nComputation 5 (4): 580â€“88. https://doi.org/10.1007/s12559-012-9179-7.\n\n\nZhang, Zhendong, and Cheolkon Jung. n.d. â€œGBDT-MO: Gradient\nBoosted Decision Trees for Multiple Outputs.â€ https://doi.org/10.48550/arXiv.1909.04373.",
    "crumbs": [
      "Literatura"
    ]
  }
]