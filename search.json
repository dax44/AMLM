[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zaawansowane metody uczenia maszynowego",
    "section": "",
    "text": "Wstęp\nKsiążka ta jest napisana na potrzeby prowadzenia zajęć na kierunku Inżynieria i analiza danych z przedmiotu Zaawansowane metody uczenia maszynowego. Jest swego rodzaju autorskim podejściem do tematu, przedstawiającym wybrane metody uczenia maszynowego, które rzadziej występują w opracowaniach na temat uczenia maszynowego.\nUczenie maszynowe stanowi obszar intensywnego rozwoju, który obejmuje szereg technik umożliwiających bardziej skomplikowane i wydajne modele predykcyjne. Wśród tych metod warto wyróżnić głębokie sieci neuronowe, zwłaszcza konwolucyjne sieci neuronowe (CNN) i rekurencyjne sieci neuronowe (RNN). CNN są wykorzystywane w zadaniach przetwarzania obrazów, gdzie potrafią efektywnie ekstrahować hierarchiczne cechy z danych wejściowych, natomiast RNN są efektywne w analizie sekwencji danych, takich jak język naturalny. Ponadto, metody uczenia maszynowego obejmują techniki transferu wiedzy, uczenie ze wzmocnieniem, generatywne modele, takie jak generatywne sieci przeciwdziedzinowe (GAN), czy też autokodery. Te nowoczesne podejścia umożliwiają modelom uczącym się wykonywanie bardziej złożonych zadań, a także adaptację do różnorodnych danych wejściowych, co sprawia, że są one stosowane w obszarach takich jak rozpoznawanie obrazów, przetwarzanie języka naturalnego, czy nawet w autonomicznych systemach decyzyjnych.\nPonadto, zaawansowane metody uczenia maszynowego obejmują także techniki regularyzacji, optymalizacji i inżynierię cech. Regularyzacja ma na celu zapobieganie przeuczeniu poprzez kontrolowanie złożoności modelu, natomiast optymalizacja skupia się na dostosowywaniu wag modelu w celu minimalizacji funkcji straty. Inżynieria cech polega na ręcznym lub automatycznym dostosowywaniu danych wejściowych w celu uzyskania lepszych wyników modelu. Dzięki tym zaawansowanym metodom, uczenie maszynowe staje się coraz bardziej potężnym narzędziem w analizie danych i podejmowaniu skomplikowanych decyzji w różnych dziedzinach.\nModele predykcyjne dla wielu wyjść, czyli tzw. multi-target regression and classification, stanowią kolejny istotny obszar w dziedzinie uczenia maszynowego. W przypadku multi-target regression, celem jest przewidywanie wielu wartości wyjściowych dla danego zestawu wejściowego, co często spotyka się w złożonych problemach predykcyjnych, takich jak prognozowanie wielu parametrów jednocześnie. Z kolei w przypadku multi-target classification, model ma za zadanie przypisanie jednego lub więcej klas dla każdego przykładu wejściowego. Te modele są powszechnie stosowane w różnych dziedzinach, takich jak bioinformatyka, finanse czy przemysł, gdzie jednoczesne przewidywanie wielu zmiennych jest kluczowe dla skutecznego rozwiązania problemu. Wdrożenie takich zaawansowanych modeli predykcyjnych wymaga starannej obróbki danych, odpowiedniego dostosowania architektury modelu oraz precyzyjnej oceny wyników, co sprawia, że są one istotnym narzędziem w obszarze analizy danych i podejmowania decyzji.\nModele językowe stanowią jeszcze jeden kluczowy obszar w dziedzinie uczenia maszynowego, skoncentrowany na zrozumieniu i generowaniu ludzkiego języka naturalnego. Głębokie sieci neuronowe, zwłaszcza rekurencyjne sieci neuronowe (RNN) i transformery, zostały skutecznie wykorzystane do tworzenia modeli językowych o zdolnościach przetwarzania i generowania tekstu na poziomie zbliżonym do ludzkiego. Te modele zdolne są do zrozumienia kontekstu, analizy gramatyki, a także generowania spójnych i sensownych odpowiedzi. Wykorzystywane są w różnorodnych zastosowaniach, takich jak tłumaczenie maszynowe, generowanie tekstu, czy analiza nastroju w tekście. Ponadto, pre-trenowane modele językowe, takie jak BERT czy GPT (Generative Pre-trained Transformer), zdobywają popularność, umożliwiając dostosowanie ich do różnych zadań poprzez fine-tuning. W miarę postępu badań i rozwoju w tej dziedzinie, modele językowe stają się coraz bardziej zaawansowane, co przyczynia się do doskonalenia komunikacji między maszynami a ludźmi oraz do rozwijania nowych możliwości w dziedzinie przetwarzania języka naturalnego.\nWspomniane powyżej metody i modele będą stanowić treść wykładów z wspomnianego na wstępie przedmiotu.",
    "crumbs": [
      "Wstęp"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Wprowadzenie",
    "section": "",
    "text": "Witam w świecie zaawansowanych metod uczenia maszynowego 🤖, prezentowanej w niniejszej publikacji. Książka ta skupia się na trzech głównych obszarach, zaczynając od wielowymiarowych problemów predykcyjnych, przechodząc przez kompleksowe modele głębokich sieci neuronowych, a kończąc na zaawansowanych modelach językowych. Koncepcyjnie rozpoczniemy od omówienia multiple target regression and classification, gdzie przedstawimy skomplikowane zadania predykcyjne wymagające jednoczesnej prognozy wielu zmiennych. Przeanalizujemy praktyczne zastosowania tych modeli w obszarach, takich jak nauki społeczne, biologia i finanse.\nNastępnie poświęcimy uwagę głębokim sieciom neuronowym, głównemu filarowi nowoczesnej sztucznej inteligencji. Omówimy ewolucję od konwolucyjnych sieci neuronowych (CNN) do rekurencyjnych sieci neuronowych (RNN), zwracając uwagę na ich zdolność do efektywnego przetwarzania obrazów, sekwencji danych i rozwiązania bardziej złożonych problemów. W ramach tego obszaru, przyjrzymy się również technikom transferu wiedzy, uczenia ze wzmocnieniem oraz generatywnym modelom, takim jak generatywne sieci przeciwdziedzinowe (GAN), które poszerzają granice możliwości maszynowego uczenia się.\n\n\n\nTrzeci kluczowy obszar, który będzie przedmiotem analizy, to modele językowe. Rozważania rozpoczniemy od głębokich sieci neuronowych, a następnie skoncentrujemy się na transformatorach, które rewolucjonizują przetwarzanie języka naturalnego 👅. Przedstawimy praktyczne zastosowania tych modeli, zwłaszcza w tłumaczeniu maszynowym, generowaniu tekstu i analizie sentymentu. Ponadto, omówimy pre-trenowane modele językowe, takie jak BERT czy GPT, jako kluczowe narzędzia adaptacyjne, zdolne do fine-tuningu w zależności od konkretnego zadania.\nKażdy podejmowany temat będzie wzbogacony o implementację analizowanych metod w realnych scenariuszach. Omówimy kroki od obróbki danych, przez dostosowywanie architektury modelu, aż po ocenę wyników. W tym kontekście poruszymy także aspekty etyczne i wyzwania związane z zastosowaniem zaawansowanych modeli uczenia maszynowego.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_target_models.html",
    "href": "multi_target_models.html",
    "title": "2  Modele z wieloma wyjściami",
    "section": "",
    "text": "2.1 Typy modeli z wieloma zmiennymi wynikowymi\nWśród nadzorowanych modeli uczenia maszynowego z wieloma zmiennymi wynikowymi można wymienić zarówno te dedykowane do klasyfikacji, jak i regresji. Modele te są znane jako modele z wieloma wyjściami (klasyfikacyjne) lub modele z wieloma wyjściami (regresyjne), w zależności od rodzaju problemu, który rozwiązują.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Modele z wieloma wyjściami</span>"
    ]
  },
  {
    "objectID": "multi_target_models.html#typy-modeli-z-wieloma-zmiennymi-wynikowymi",
    "href": "multi_target_models.html#typy-modeli-z-wieloma-zmiennymi-wynikowymi",
    "title": "2  Modele z wieloma wyjściami",
    "section": "",
    "text": "Modele z wieloma wyjściami (klasyfikacyjne)\nW przypadku klasyfikacji, gdy mamy wiele kategorii (klas) jako zmienną wynikową, modele te są nazywane modelami z wieloma wyjściami. Przykłady obejmują algorytmy takie jak regresja logistyczna, metoda k najbliższych sąsiadów (k-NN) czy algorytmy drzew decyzyjnych, które zostały dostosowane do obsługi wielu klas.\nPrzykładowe zadanie: Załóżmy, że mamy zbiór danych dotyczący różnych rodzajów owoców (np. jabłek, pomarańczy, bananów) i chcemy stworzyć model, który jednocześnie przewiduje gatunek owocu oraz kolor owocu. Mamy więc dwie zmienne wynikowe: gatunek (klasyfikacja wieloklasowa) i kolor (klasyfikacja wieloklasowa).\nModele z wieloma wyjściami (regresyjne).\nW przypadku regresji, gdzie zmienną wynikową jest wektor wartości numerycznych, modele te są nazywane modelami z wieloma wyjściami. Przykłady obejmują algorytmy regresji liniowej lub nieliniowej, algorytmy oparte na drzewach decyzyjnych, czy też bardziej zaawansowane modele, takie jak sieci neuronowe.\nPrzykładowe zadanie: Zakładamy, że mamy zbiór danych zawierający informacje o pracownikach, takie jak doświadczenie zawodowe, poziom wykształcenia, liczba godzin pracy tygodniowo itp. Chcemy stworzyć model, który jednocześnie przewiduje zarobki pracowników oraz ich poziom satysfakcji zawodowej.\nModele wielozadaniowe.\nModele wielozadaniowe to rodzaj nadzorowanego uczenia maszynowego, w którym model jest trenowany jednocześnie do rozwiązania kilku zadań. Te zadania mogą obejmować zarówno klasyfikację, jak i regresję. Dzięki wspólnemu trenowaniu modelu na wielu zadaniach, można uzyskać korzyści w postaci wspólnego wykorzystywania wiedzy między zadaniami.\nPrzykładowe zadanie: Załóżmy, że mamy zbiór danych dotyczący zakupów klientów w sklepie internetowym. Dla każdego klienta mamy informacje o różnych aspektach zakupów, takich jak czas dostawy, łatwość obsługi strony, jakość produktów itp. Chcemy stworzyć model, który jednocześnie przewiduje dwie zmienne wynikowe: jakość obsługi klienta (skala jakościowa, np. “Niska”, “Średnia”, “Wysoka”) oraz całkowity wydatek klienta (zmienna ilościowa, np. kwota zakupów).\nModele hierarchiczne.\nW niektórych przypadkach, szczególnie gdy mamy hierarchię zmiennych wynikowych, modele te mogą być budowane w sposób hierarchiczny. Przykładowo, w problemie klasyfikacji obrazów z hierarchią kategorii (na przykład rozpoznawanie gatunków zwierząt), model może być zaprojektowany do rozpoznawania zarówno ogólnych, jak i bardziej szczegółowych kategorii.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Modele z wieloma wyjściami</span>"
    ]
  },
  {
    "objectID": "multi_target_models.html#różnie-podejścia-do-modelowania-z-wieloma-wyjściami",
    "href": "multi_target_models.html#różnie-podejścia-do-modelowania-z-wieloma-wyjściami",
    "title": "2  Modele z wieloma wyjściami",
    "section": "2.2 Różnie podejścia do modelowania z wieloma wyjściami",
    "text": "2.2 Różnie podejścia do modelowania z wieloma wyjściami\nIstnieją dwa ogólne podejścia do rozwiązywania problemów wieloetykietowych: transformacja problemu i adaptacja algorytmu. Transformacja problemu polega na manipulowaniu zbiorem danych w taki sposób, że problem wieloetykietowy staje się jednym lub kilkoma problemami jednoetykietowymi (Tawiah i Sheng 2013). Adaptacja algorytmu polega na tym, że sam algorytm jest w stanie poradzić sobie bezpośrednio z problemem wieloetykietowym. Okazuje się, że wiele, choć nie wszystkie, metody adaptacji algorytmów metod adaptacji algorytmów w rzeczywistości wykorzystuje transformację problemu (Tsoumakas i Katakis 2007).\n\n2.2.1 Transformacja problemu\nTechniki te przewidują stworzenie indywidualnego modelu dla każdego celu, a następnie połączenie oddzielnych modeli w celu uzyskania ogólnej prognozy. Metody transformacji problemów okazały się lepsze od metod adaptacji algorytmów pod względem dokładności (Spyromitros-Xioufis i in. 2016). Co więcej, podstawowa zasada sprawia, że metody transformacji problemu są niezależne od algorytmu. W konsekwencji, można je łatwo dostosować do danego problemu poprzez zastosowanie odpowiednich bazowych metod uczących. Punkt ten ma również szczególne znaczenie dla modeli typu ensemble, które łączą oszacowania z wielu potencjalnie różnych algorytmów w ostateczną prognozę. Niedawno Spyromitros-Xioufis i in. (2016) zaproponowali rozszerzenie znanych metod transformacji klasyfikacji wieloetykietowej, aby poradzić sobie z problemem regresji wielowynikowej i modelować zależności między celami. W szczególności wprowadzili oni dwa nowe podejścia do regresji wielocelowej, składanie regresorów wielocelowych i łańcuchy regresorów, inspirowane popularnymi i skutecznymi podejściami do klasyfikacji wieloznaczeniowej.\nPodstawową koncepcją w metodach transformacji problemów jest wykorzystanie poprzednich modeli do nowego przewidywania poprzez rozszerzoną przestrzeń cech (Borchani i in. 2015). Stacked generalization to podejście do meta-uczenia, które wykorzystuje dane wyjściowe wcześniej wyuczonych modeli do uczenia się nowego modelu. W związku z tym początkowe dane wyjściowe modelu są traktowane jako nowe cechy i są układane w stos do początkowego wektora cech przed ponownym uczeniem. W oryginalnym sformułowaniu przewidziano tylko dwuetapową procedurę, tj. początkowe modele wyuczone z początkowego wektora cech odpowiadają odpowiednio modelom i danym poziomu 0, a powiększony wektor cech i ponownie wyuczony model są określane odpowiednio jako dane poziomu 1 i generalizator. Jednakże, rozsądnie rzecz biorąc, ten proces układania pojedynczego celu (ang. Single-target Stacking - STS) może być również przeprowadzany w wielu iteracjach. Aby wdrożyć tę zasadę dla problemów z wieloma celami, w których kodowane są również możliwe korelacje między zmiennymi docelowymi, wprowadzono koncepcję układania wielu celów (ang. Multi-target Stacking - MTS) (Borchani i in. 2015). Analogicznie do STS, szkolenie modelu MTS można uznać za procedurę dwuetapową. W pierwszym etapie uczone są niezależne modele dla każdej zmiennej docelowej. Następnie uczone są meta-modele dla każdej zmiennej docelowej z rozszerzonymi wektorami cech, które zawierają początkowe wektory cech, a także oszacowania poziomu 0 pozostałych zmiennych docelowych. Podobne pomysły były również stosowane w kontekście modeli zespołowych, tj. uczenia się kilku modeli poziomu 0 dla każdej zmiennej docelowej, które są łączone w procedurze uogólniania poziomu 1 dla wielu zmiennych docelowych (Santana i in. 2020).\n\n2.2.1.1 Single-target stacking\nMetoda ta jest stosowana przede wszystkim z zadaniach regresyjnych z wieloma wyjściami. Rozważmy zbiór danych \\(D = \\left\\{\\left(\\mathbf{x}^{(1)}, \\mathbf{y}^{(1)}\\right), \\ldots, \\left(\\mathbf{x}^{(N)}, \\mathbf{y}^{(N)}\\right)\\right\\}\\), składający się z \\(N\\) obserwacji, które są realizacjami zmiennych losowych \\(X_1,\\ldots,X_m, Y_1,\\ldots,Y_d\\). Zatem każde wejście do modelu jest charakteryzowane przez \\(m\\) zmiennych \\(\\mathbf{x}{(l)}=\\left(x_1^{(l)},\\ldots, x_j^{(l)}, \\ldots, x_m^{(l)} \\right)\\) oraz \\(d\\) odpowiadających im wyjść \\(\\mathbf{y}{(l)}=\\left(y_1^{(l)},\\ldots, y_i^{(l)}, \\ldots, y_d^{(l)} \\right)\\), gdzie \\(l\\in\\{1,\\ldots,N\\}, j\\in\\{1,\\ldots,m\\}, i\\in\\{1,\\ldots,d\\}\\). Naszym celem w zadaniu regresyjnym (MTR - Multi-target Regression) jest nauczenie takiego modelu \\(h\\), który przekształca \\(\\mathbf{x}\\) w \\(\\mathbf{y}\\).\nW podejściu STS w pierwszym kroku budowanych jest \\(d\\) niezależnych modeli przewidujących pojedyncze wyjście. Po tej czynności meta-model jest trenowany na zbiorze \\(D_i'\\), który jest wzbogaconym zbiorem \\(D_i\\) o predykcje zmiennej \\(Y_i\\), czyli\n\\[\nD_i'=\\left\\{\\left(\\mathbf{x}'^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}'^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}'^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_i^{(l)} \\right)\\). W zależności czy rozpatrujemy algorytm STS niekumulatywny, czy kumulatywny, drugi krok iteracji wygląda nieco inaczej:\n\nniekumulatywny\n\\[\n\\bar{D}_i''=\\left\\{\\left(\\mathbf{x}''^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}''^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}''^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_i'^{(l)} \\right)\\)\nkumulatywny\n\\[\n\\bar{\\bar{D}}_i''=\\left\\{\\left(\\mathbf{x}''^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}''^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}''^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_i^{(l)},\\hat{y}_i'^{(l)} \\right)\\).\n\n\n\n\nSingle-target stacking\n\n\n\n\n2.2.1.2 Multi-target stacking\nW przeciwieństwie do STS, MTS został zaprojektowany do dzielenia się wiedzą w skorelowanych zmiennych docelowych w ramach procedury łączenia w stosy. Podobnie, najpierw uczone są modele pojedynczego celu. Następnie tworzony jest zestaw meta-modeli, które zawierają model dla każdej zmiennej docelowej \\(Y_i,\\) \\(i \\in \\{1, \\ldots, d\\}\\). W ten sposób uwzględniane są szacunki dotyczące pozostałych zmiennych docelowych z pierwszego etapu, tj. model jest uczony z przekształconego zbioru\n\\[\nD_i'=\\left\\{\\left(\\mathbf{x}'^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}'^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}'^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_1^{(l)},\\ldots,\\hat{y}_d^{(l)} \\right)\\). W metodzie MTS istnieją również dwa sposoby składania kolejnych iteracji. Przebiegają one w podobny sposób jak w przypadku STS.\n\n\n\nMulti-target stacking\n\n\nIstnieje jeszcze trzecia metoda powszechnie stosowana do predykcji wielowyniowej zwana Regressor Chains lub Classifier Chains w zależności od celu zadania. Idę działania tej metody przedstawię na przykładzie modelu regresyjnego.\n\n\n2.2.1.3 Regressor Chains\nRC opierają się na idei dopasowywania modeli pojedynczego celu wzdłuż wybranej permutacji, tj. łańcucha. Najpierw losowana jest permutacja w odniesieniu do zmiennych docelowych. Proces ten można przeprowadzić w sposób losowy (Spyromitros-Xioufis i in. 2016) lub uporządkowany (Melki i in. 2017). Wybrana permutacja jest wykorzystywana do zbudowania oddzielnego modelu regresji dla zmiennych docelowych zgodnie z kolejnością permutacji. Aby wykorzystać tę strukturę do MTR, rzeczywiste wartości zmiennych docelowych są dostarczane do kolejnych modeli podczas uczenia się wzdłuż łańcucha. Na podstawie pełnego łańcucha lub wybranego zestawu \\(C = (Y_1,\\ldots,Y_d)\\), pierwszy model jest ograniczony do ustalenia predykcji dla \\(Y_1\\). Następnie, kolejno dla \\(Y_i\\) uczone są modele na podstawie zbioru\n\\[\nD_i'=\\left\\{\\left(\\mathbf{x}'^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}'^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}'^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, y_1^{(l)},\\ldots, y_{i-1}^{(l)} \\right)\\). Ten algorytm ma również dwie odmiany (niekumulatywną i kumulatywną) w zależności od kształtu kolejnych iteracji.\n\n\n\nRegressor chains\n\n\nPonieważ, jak można się spodziewać wyniki modelowania w znaczny sposób zależą od wylosowanej permutacji, to w metodzie zaproponowanej przez Melki i in. (2017) aby uniknąć tego efektu buduje się \\(k\\) modeli dla różnych permutacji i łączy się wyniki w podobny sposób jak w lasach losowych.\n\n\n\n\n\n\n\n\n\nAdnotacja\n\n\n\nSłowo komentarza jeśli chodzi o dostępność tych metod w językach programowania. Niestety wspomniane metody w R nie są zaimplementowane w sposób, który pozwalałby na bezpieczne używanie przygotowanych rozwiązań. Istnieje kilka wzmianek (na dzień dzisiejszy, czyli początek 2024 roku) na ten temat. Twórcy dwóch głównych frameworków do uczenia maszynowego, czyli mlr3 oraz tidymodels przygotowują implementacje tych metod. Dodatkowo istnieje rozwiązanie w wersji eksperymentalnej mtr-toolkit, które pozwala na wykonanie modelowania z wieloma wyjściami, którym można się posiłkować. Na potrzeby klasyfikacji istnieje również pakiet mldr i ultim, które pozwalają na uczenie modeli klasyfikacyjnymi z wieloma wyjściami.\nNiestety w przypadku Python-a nie jest dużo lepiej. Wprawdzie w pakiecie scikit-learn istnieją implementacje pozwalające na predykcje wielowyjściowe w obu typach zadań poprzez MultiOutputRegressor i MultiOutputClassifier, ale dokonują one predykcji naiwnej poprzez złożenie w listę wyników pojedynczych modeli dla każdej zmiennej. Nieco lepiej sprawa wygląda w przypadku metod łańcuchowych, ponieważ zarówno dla klasyfikacji, jak i regresji są metody to realizujące (ClassifierChain i RegressorChain).\n\n\n\n\n\n2.2.2 Adaptacja algorytmu\nProstota podejścia transformacji problemu sprawia, że jest ono odpowiednie dla problemów, w których jego wady mają niewielki lub żaden wpływ - jednak dla złożonych problemów podejście adaptacji algorytmu może okazać się bardziej efektywne. Dodatkowo, dowody empiryczne sugerują, że uczenie się powiązanych zadań jednocześnie, a nie niezależnie, może poprawić wyniki predykcyjne (Evgeniou i Pontil 2004). Z drugiej strony, jeśli zadania są bardzo odmienne, wydajność predykcyjna może ucierpieć, gdy zadania są uczone razem, a nie niezależnie (Faddoul i in. 2010). W związku z tym możemy wyciągnąć następujące wnioski:\n\njeśli zadania, których nasz predyktor ma się nauczyć, są powiązane, powinniśmy dążyć do znalezienia odpowiedniej metody adaptacji algorytmu;\njeśli zadania, których chcemy się nauczyć, nie są powiązane, powinniśmy zamiast tego dążyć do znalezienia odpowiedniej metody transformacji problemu.\n\nWreszcie, powinniśmy wziąć pod uwagę rozmiar problemu i zdać sobie sprawę, że gdy zadania są niepowiązane, istnieje potencjalny kompromis między efektywnością czasową a wydajnością predykcyjną przy wyborze metody transformacji problemu lub metody adaptacji algorytmu. W przypadku niepowiązanych ze sobą zadań, metody transformacji problemu mogą zwiększać skuteczność predykcyjną, ale zmniejszać wydajność czasową w przypadku dużych problemów i odwrotnie.\nNiestety tej metody nie da się zastosować do każdego typu modelu. Rodzina modeli, których adaptacja jest wykonana cały czas rośnie. Adaptacja modelu polega na przekształceniu go do postaci, w której da się wykonać predykcję dla wielu wyjść. Wśród modeli, których wersje native multi-target istnieją należy wymienić:\n\nregresja wieloraka (Izenman 1975)\nkNN\ndrzewo decyzyjne (Struyf i Džeroski 2006)\nlas losowy (Kocev i in. 2013)\nbagging (Kocev i in. 2013)\ngradient boosting (Zhang i Jung, b.d.; Faddoul i in. 2012)\nSVM (Xu, Guo, i Wang 2013; Vazquez i Walter 2003)\nno i oczywiście sieci neuronowe.\n\nNie sposób przedstawić w jaki sposób wprowadzone zostały zmiany we wszystkich algorytmach. Skupię się jednak na pokazaniu adaptacji drzew decyzyjnych do predykcji wielu wyjść jednocześnie, ponieważ jest to meta-model modeli takich jak lasy losowe, bagging czy boosting.\n\n2.2.2.1 Adaptacja klasyfikacyjnego drzewa decyzyjnego\nFaddoul i in. (2012) zaproponowali zmodyfikowaną wersję algorytmu drzewa decyzyjnego C4.5 (Quinlan 1993), która bezpośrednio obsługuje problemy klasyfikacji wielowyjściowej. Zmodyfikowana wersja (nazwana MT-DT) różni się od standardowej implementacji C4.5 w dwóch krytycznych aspektach: kryteriach podziału węzłów i procesie decyzyjnym. Faddoul i in. (2012) proponują trzy różne podejścia do łączenia wielu miar przyrostu informacji w jedną miarę: wspólny przyrost informacji, suma nieważona i maksymalny przyrost informacji. Wspólny przyrost informacyjny jest definiowany przy użyciu konkatenacji wszystkich poszczególnych zadań, tj. względnej różnicy w entropii mierzonej we wszystkich zadaniach decyzyjnych. Autorzy pokazują, że nieważona suma (Równanie 2.1) indywidualnych przyrostów informacyjnych wszystkich zadań jest równoważna wspólnemu przyrostowi informacyjnemu.\n\\[\nIG_U=\\sum_YIG_Y\n\\tag{2.1}\\]\nMaksymalny przyrost informacyjny, zgodnie z propozycją autorów jest definiowany po prostu jako maksymalny przyrost informacyjny wszystkich zadań:\n\\[\nIG_M=\\max_YIG_Y\n\\tag{2.2}\\]\nBadania eksperymentalne pokazały, że maksymalny przyrost informacyjny wykorzystany do budowania reguł podziału, charakteryzuje się wyższym poziomem dopasowania modeli, niż przy zastosowaniu \\(IG_U\\) i \\(IG_J\\).\nW przypadku klasyfikacji z jedną etykietą, algorytm indukcji drzewa decyzyjnego (taki jak C4.5) rekurencyjnie dzieli węzły, dodając (zazwyczaj dwa) elementy potomne, aż możliwe jest utworzenie liścia takiego, że znaczna większość (lub nawet wszystkie) jego przykładowych instancji należy do tej samej klasy. W przypadku wielu wyjść, indukcja drzewa niekoniecznie jest tak prosta. Rozważmy problem klasyfikacji wielowyjściowej z dwoma wyjściami binarnymi \\(\\nu_1\\) i \\(\\nu_2\\); możliwe jest, że po \\(t\\) podziałach, węzeł zawiera tylko wartości pozytywne dla \\(\\nu_1\\), ale mieszankę wartości pozytywnych i negatywnych dla \\(\\nu_2\\) - stąd, podczas konstruowania drzew decyzyjnych dla wielu jednoczesnych zadań, należy pamiętać, że proces decyzyjny dla pewnego zadania może wymagać krótszej ścieżki decyzyjnej niż inne zadania w ramach tego samego problemu wielowyjściowego. MT-DT radzi sobie z tym, sprawdzając w każdym węźle, czy możliwe jest utworzenie węzła terminalnego dla któregokolwiek z zadań - w powyższym przykładzie spowodowałoby to utworzenie drzewa, w którym wewnętrzny węzeł \\(t_1\\) jest oznaczony jako węzeł zatrzymania dla \\(\\nu_1\\), oznaczony klasą pozytywną. Ponieważ celem jest prognozowanie dla obu wyjść binarnych, \\(t_1\\) nie jest węzłem liścia - zamiast tego rekurencyjne dzielenie jest kontynuowane od \\(t_1\\), aż do znalezienia węzła \\(t_2\\) takiego, że \\(t_2\\) jest wystarczająco czysty w odniesieniu do \\(\\nu_2\\), aby można było utworzyć regułę klasyfikacji dla drugiego zadania binarnego. W tym momencie węzły decyzyjne (węzły wewnętrzne lub liście) zostały znalezione dla wszystkich wyników (\\(\\nu_1\\) i \\(\\nu_2\\)), a algorytm indukcji drzewa rekurencyjnego może zostać zakończony.\nNic dziwnego, że klasyfikacja przy użyciu już zbudowanego modelu MT-DT przebiega według tej samej formuły, co jego indukcja - podczas przechodzenia przez drzewo każdy węzeł jest sprawdzany w celu ustalenia, czy można podjąć decyzję dla któregokolwiek z aktualnie nierozstrzygniętych zadań. W przykładzie \\(\\nu_1\\), \\(\\nu_2\\), klasyfikacja zostanie dokonana dla \\(\\nu_1\\) w węźle \\(t_1\\), ponieważ jest on oznaczony jako węzeł zatrzymania dla \\(\\nu_1\\); następnie przejście jest kontynuowane do momentu napotkania \\(t_2\\) i klasyfikacja może zostać dokonana dla \\(\\nu_2\\). W tym momencie wszystkie wyjścia zostały sklasyfikowane, a przechodzenie może się zakończyć, zwracając dwie wartości w \\(t_1\\) i \\(t_2\\) jako klasyfikacje odpowiednio dla \\(\\nu_1\\) i \\(\\nu_2\\).\n\n\n2.2.2.2 Adaptacja regresyjnego drzewa decyzyjnego\nSegal (1992) zaproponował rozwiązanie dla drzew regresyjnych o wielu wyjściach (MRT), które są w stanie przewidywać wyniki dla wielu powiązanych zadań regresyjnych; te wielowyjściowe drzewa regresyjne są oparte na funkcji podziału najmniejszych kwadratów zaproponowanej w ramach CART (Breiman i in. 2017). W przypadku drzewa regresyjnego o jednej odpowiedzi celem jest minimalizacja następującej funkcji celu:\n\\[\n\\phi(t) = SS(t)-SS(t_L)-SS(t_R)\n\\]\ngdzie \\(SS(t)\\) jest zdefiniowana następująco\n\\[\nSS(t) = \\sum_{i\\in t}(y_i-\\bar{y}(t))^2.\n\\]\nSegal (1992) dodał ważenie macierzą kowariancji do błędu kwadratowego, co prowadzi algorytm drzewa do tworzenia węzłów potomnych, które reprezentują jednorodne klastry w odniesieniu do zestawu odpowiedzi wyjściowych:\n\\[\nSS(t) = \\sum_{i\\in t}(y_i-\\bar{y}(t))'V^{-1}(t)(y_i-\\bar{y}(t)),\n\\]\ngdzie \\(V(t)\\) oznacza macierz kowariancji w węźle \\(t\\).\n\n\n2.2.2.3 Adaptacja drzew decyzyjnych do realizacji obu zadań\nJak wspomniano wcześniej, jedną z kluczowych motywacji do podejmowania prób rozwiązywania problemów rozpoznawania wzorców z wieloma wyjściami przy użyciu metod adaptacji algorytmów jest oczekiwanie, że pojedynczy model wytrenowany na zestawie powiązanych zadań wykaże poprawę wydajności predykcyjnej w porównaniu do zestawu indywidualnych modeli, z których każdy został wytrenowany na pojedynczym zadaniu. Rodzi to pytanie: co jeśli problem wielowynikowy zawiera zarówno zadania klasyfikacji, jak i regresji? Jeśli zadania są niepowiązane, rozwiązanie takiego wspólnego problemu klasyfikacyjno-regresyjnego nie musi być trudniejsze niż szkolenie zestawu klasyfikatorów i regresorów dla poszczególnych zadań; jeśli jednak zadania są powiązane, oczekujemy, że metoda adaptacji algorytmu zapewni lepsze wyniki pod względem wydajności predykcyjnej.\nGlocker i in. (2012) zaproponował algorytm indukcji drzewa, który jednocześnie rozwiązuje jedno zadanie klasyfikacji i jedno zadanie regresji. Podobnie jak MT-DT i MRT, wspólne drzewo klasyfikacyjno-regresyjne (JCRT) rozwiązuje wiele jednoczesnych zadań predykcji poprzez modyfikację funkcji podziału węzła w kroku indukcyjnym i oznaczenie węzłów końcowych odpowiednimi wartościami dla każdego zadania. Ze względu na charakter wspólnych problemów klasyfikacyjno-regresyjnych, zmodyfikowana funkcja podziału jest wymagana do jednoczesnego uwzględnienia błędu zarówno części klasyfikacyjnej, jak i regresyjnej. Funkcja podziału zaproponowana przez Glocker i in. (2012) wykorzystuje funkcję entropii składającą się z trzech części:\n\npo pierwsze, entropia Shannona jest obliczana dla części klasyfikacji;\npo drugie, ważona entropia różnicowa jest obliczana dla części regresji;\npo trzecie, ze względu na fakt, że entropia Shannona i entropia różnicowa istnieją w różnych zakresach, stosuje się krok normalizacji w celu połączenia dwóch entropii. Entropia Shannona jest obliczana tak, jak opisano wcześniej:\n\n\\[\nH_c(t) = \\sum_{c\\in C}p(c|x)\\log p(c|x).\n\\]\nMiara entropii różniczkowej stosowana przez Glocker i in. (2012) dla regresyjnej części problemu jest obliczana w podobny sposób, z dwiema kluczowymi różnicami:\n\nzamiast sumowania prawdopodobieństw wartości nominalnych, entropia jest definiowana przez różniczkę funkcji prawdopodobieństwa wyjścia o wartości rzeczywistej;\ndodatkowo funkcja prawdopodobieństwa jest ważona w klasach:\n\n\\[\nH_{r|c}(t) = \\sum_{c\\in C}p(c|x)\\int_{r\\in \\mathbb{R}^n}-p(r|c,x)\\log p(r|c,x)dr.\n\\]\nNastępnie dokonywana jest normalizacja ze względu na oba zadania, gdzie punktem odniesienie jest entropia w korzeniu:\n\\[\nH(t) = \\frac12\\left(\\frac{H_c(t)}{H_c(t_0)}+\\frac{H_{r|c}(t)}{H_{r|c}(t_0)}\\right).\n\\]\n\n\n\n\n\n\nAdnotacja\n\n\n\nJedyne implementacje, które znalazłem dla obu języków programowania (R i Python) dotyczyły lasów losowych. W R pakiet nazywa się randomForestSRC, a w Pythonie morfist. Pozwalają one zarówno na wykonywanie wielowyjściowych zadań klasyfikacyjnych i regresyjnych, jak również zadań mieszanych. Oczywiście wspomniane wyżej typy zadań można realizować przy użyciu sieci neuronowych w obu językach programowania.\n\n\n\n\n\n\nBorchani, Hanen, Gherardo Varando, Concha Bielza, i Pedro Larrañaga. 2015. „A Survey on Multi-Output Regression”. WIREs Data Mining and Knowledge Discovery 5 (5): 216–33. https://doi.org/10.1002/widm.1157.\n\n\nBreiman, Leo, J. H. Friedman, Richard A. Olshen, i Charles J. Stone. 2017. Classification and Regression Trees. Routledge. http://search.ebscohost.com/login.aspx?direct=true&db=edsebk&AN=1619230&lang=pl&site=eds-live&scope=site.\n\n\nEvgeniou, Theodoros, i Massimiliano Pontil. 2004. „Regularized multi–task learning”. Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, sierpień. https://doi.org/10.1145/1014052.1014067.\n\n\nFaddoul, Jean Baptiste, Boris Chidlovskii, Rémi Gilleron, i Fabien Torre. 2012. „Learning multiple tasks with boosted decision trees”. W Proceedings of the 2012th European Conference on Machine Learning and Knowledge Discovery in Databases - Volume Part I, 681–96. ECMLPKDD’12. Springer-Verlag.\n\n\nFaddoul, Jean Baptiste, Boris Chidlovskii, Fabien Torre, i Remi Gilleron. 2010. „Boosting Multi-Task Weak Learners with Applications to Textual and Social Data”. W 2010 Ninth International Conference on Machine Learning and Applications, 367–72. IEEE. https://doi.org/10.1109/ICMLA.2010.61.\n\n\nGlocker, Ben, Olivier Pauly, Ender Konukoglu, i Antonio Criminisi. 2012. „Joint Classification-Regression Forests for Spatially Structured Multi-object Segmentation”. W Computer Vision – ECCV 2012, zredagowane przez Andrew Fitzgibbon, Svetlana Lazebnik, Pietro Perona, Yoichi Sato, i Cordelia Schmid, 7575:870–81. Springer Berlin Heidelberg. http://link.springer.com/10.1007/978-3-642-33765-9_62.\n\n\nIzenman, Alan Julian. 1975. „Reduced-rank regression for the multivariate linear model”. Journal of multivariate analysis 5 (2): 248–64.\n\n\nKocev, Dragi, Celine Vens, Jan Struyf, i Sašo Džeroski. 2013. „Tree ensembles for predicting structured outputs”. Pattern Recognition 46 (3): 817–33. https://doi.org/10.1016/j.patcog.2012.09.023.\n\n\nMelki, Gabriella, Alberto Cano, Vojislav Kecman, i Sebastián Ventura. 2017. „Multi-Target Support Vector Regression via Correlation Regressor Chains”. Information Sciences 415–416 (listopad): 53–69. https://doi.org/10.1016/j.ins.2017.06.017.\n\n\nQuinlan, J Ross. 1993. C4. 5: Programs for Machine Learning. Morgan Kaufmann.\n\n\nSantana, Everton Jose, Felipe Rodrigues dos Santos, Saulo Martiello Mastelini, Fabio Luiz Melquiades, i Sylvio Barbon Jr. 2020. „Improved Prediction of Soil Properties with Multi-Target Stacked Generalisation on EDXRF Spectra”. arXiv preprint arXiv:2002.04312. https://arxiv.org/abs/2002.04312.\n\n\nSegal, Mark Robert. 1992. „Tree-Structured Methods for Longitudinal Data”. Journal of the American Statistical Association 87 (418): 407–18. https://doi.org/10.2307/2290271.\n\n\nSpyromitros-Xioufis, Eleftherios, Grigorios Tsoumakas, William Groves, i Ioannis Vlahavas. 2016. „Multi-Target Regression via Input Space Expansion: Treating Targets as Inputs”. Machine Learning 104 (1): 55–98. https://doi.org/10.1007/s10994-016-5546-z.\n\n\nStruyf, Jan, i Sašo Džeroski. 2006. „Constraint Based Induction of Multi-objective Regression Trees”. W Knowledge Discovery in Inductive Databases, zredagowane przez Francesco Bonchi i Jean-François Boulicaut, 222–33. Lecture Notes w Computer Science. Springer. https://doi.org/10.1007/11733492_13.\n\n\nTawiah, Clifford, i Victor Sheng. 2013. „Empirical Comparison of Multi-Label Classification Algorithms”. W Proceedings of the AAAI Conference on Artificial Intelligence, 27:1645–46.\n\n\nTsoumakas, Grigorios, i Ioannis Katakis. 2007. „Multi-Label Classification: An Overview”. International Journal of Data Warehousing and Mining (IJDWM) 3 (3): 1–13.\n\n\nVazquez, Emmanuel, i Eric Walter. 2003. „Multi-Output Suppport Vector Regression”. IFAC Proceedings Volumes, 13th IFAC Symposium on System Identification (SYSID 2003), Rotterdam, The Netherlands, 27-29 August, 2003, 36 (16): 1783–88. https://doi.org/10.1016/S1474-6670(17)35018-8.\n\n\nXu, Yitian, Rui Guo, i Laisheng Wang. 2013. „A Twin Multi-Class Classification Support Vector Machine”. Cognitive Computation 5 (4): 580–88. https://doi.org/10.1007/s12559-012-9179-7.\n\n\nZhang, Zhendong, i Cheolkon Jung. b.d. „GBDT-MO: Gradient Boosted Decision Trees for Multiple Outputs”. https://doi.org/10.48550/arXiv.1909.04373.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Modele z wieloma wyjściami</span>"
    ]
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "3  Przykłady - metody klasyczne",
    "section": "",
    "text": "3.1 Przykład 1\nNajpierw sformułujemy problem badawczy wymagający zastosowania modeli z wieloma wyjściami.\nKod\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import make_regression\nKod\n# generowanie danych do zadania\nX, y = make_regression(n_samples=700, n_features=10, n_informative = 8, n_targets=3, random_state=4)\nKod\n# łączenie ich w ramki danych\nX_df = pd.DataFrame(i for i in X)\nX_df.columns = [\"X\"+ str(i) for i in range(1,11)]\ny_df = pd.DataFrame(i for i in y)\ny_df.columns = [\"y\"+str(i) for i in range(1,4)]\n\ndf = pd.concat([X_df,y_df], axis=1)\ndf.head()\n\n\n\n\n\n\n\n\n\nX1\nX2\nX3\nX4\nX5\nX6\nX7\nX8\nX9\nX10\ny1\ny2\ny3\n\n\n\n\n0\n-0.547331\n0.426522\n-1.693585\n-0.740282\n0.277445\n-1.910679\n-0.320635\n1.449172\n-0.469619\n0.371273\n-92.924393\n-116.819352\n-32.117311\n\n\n1\n2.314630\n-0.936016\n-1.833034\n-0.394507\n-0.902981\n-1.089381\n1.005442\n-0.351289\n1.218223\n0.350258\n88.577211\n182.003040\n67.579488\n\n\n2\n-0.025423\n0.684189\n1.208964\n1.325672\n0.328946\n-0.354083\n-0.566556\n0.671359\n-0.560768\n0.327379\n115.652472\n63.462207\n43.519697\n\n\n3\n-0.044533\n0.603030\n-1.495716\n-0.507870\n-0.268485\n-0.140194\n-0.246658\n-0.758946\n2.567979\n1.808345\n-12.092227\n65.181041\n96.138770\n\n\n4\n2.083679\n0.318852\n-0.080982\n-1.284608\n0.281687\n0.792470\n-0.560598\n-1.368963\n0.718059\n-1.741815\n-18.573726\n-103.219393\n11.559200\nKod\ndf_X_boxplot = pd.melt(X_df)\nsns.boxplot(data = df_X_boxplot, x = \"variable\", y = \"value\")\nplt.show()\nKod\ndf_y_boxplot = pd.melt(y_df)\nsns.boxplot(data = df_y_boxplot, x = \"variable\", y = \"value\")\nplt.show()\nZarówno zmienne X, jak i y mają zbliżone rozkłady.\nKod\nsns.set_theme(style=\"white\")\ng = sns.PairGrid(y_df, diag_sharey=False)\ng.map_upper(sns.scatterplot, s=7)\ng.map_lower(sns.kdeplot)\ng.map_diag(sns.histplot)\nplt.show()\nJak widać z powyższego wykresu zmienne y1,y2,y3 wykazują pewne wzajemne zależności, dlatego budowa oddzielnych modeli dla każdej ze zmiennych powinna dawać gorsze predykcje niż modele wiążące wszystkie zmiennej w jednym modelu. Można też zauważyć, że rozkłady są zbliżone do normalnego.\nKod\ncor = df.corr()\nplt.figure(figsize = (12,10))\nsns.heatmap(cor, \n            xticklabels=cor.columns.values,\n            yticklabels=cor.columns.values,\n            annot = True, fmt = '.2f')\nplt.show()\nJak widać z powyższej macierzy korelacji, przynajmniej 8 spośród 10 zmiennych X koreluje istotnie ze zmiennymi y.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Przykłady - metody klasyczne</span>"
    ]
  },
  {
    "objectID": "examples.html#przykład-1",
    "href": "examples.html#przykład-1",
    "title": "3  Przykłady - metody klasyczne",
    "section": "",
    "text": "Przykład 3.1 Dane do zadania wygenerujemy za pomocą funkcji make_regression() z pakietu sklern.dataset1. Wygenerujemy 700 obserwacji z 10 predyktorami i 3 zmiennymi zależnymi.\n1 Nie znam R-owego odpowiednika",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Przykłady - metody klasyczne</span>"
    ]
  },
  {
    "objectID": "examples.html#rozwiązanie",
    "href": "examples.html#rozwiązanie",
    "title": "3  Przykłady - metody klasyczne",
    "section": "3.2 Rozwiązanie",
    "text": "3.2 Rozwiązanie\nNa potrzeby porównania różnych rozwiązań zbudujemy następujące konfiguracje modeli:\n\ntrzy lasy losowe dla każdej zmiennej y niezależnie;\nmodel lasu losowego z wykorzystaniem reguły Regression Chains jako transformacji modelu;\nlas losowy dla trzech zmiennych wynikowych jednocześnie (adaptacja modelu)\n\nRozwiązania te porównamy pod względem dopasowania.\n\n3.2.1 Niezależne lasy losowe\nFunkcja MultiOutputRegressor nałożona na model lasu losowego takie rozwiązanie tworzy.\n\n\nKod\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.multioutput import RegressorChain\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)\n\n\n\n\nKod\nrf_meta = RandomForestRegressor(random_state=4)\nrf_indep = MultiOutputRegressor(rf_meta)\nprint(rf_indep)\n\n\nMultiOutputRegressor(estimator=RandomForestRegressor(random_state=4))\n\n\n\n\nKod\nrf_indep.fit(X_train, y_train)\nr2_indep= rf_indep.score(X_test, y_test)\npred_indep = rf_indep.predict(X_test)\nrmse_indep = mean_squared_error(y_test, pred_indep, squared = False)\n\nprint(f'R2 on test samples: {r2_indep:.2f}')\nprint(f'RMSE on test samples: {rmse_indep:.1f}')\n\n\nR2 on test samples: 0.82\nRMSE on test samples: 71.1\n\n\n\n\n3.2.2 Regressor Chains RF\n\n\nKod\nrf_chains = RegressorChain(rf_meta)\nprint(rf_chains)\n\n\nRegressorChain(base_estimator=RandomForestRegressor(random_state=4))\n\n\n\n\nKod\nrf_chains.fit(X_train, y_train)\nr2_chains= rf_chains.score(X_test, y_test)\npred_chains = rf_chains.predict(X_test)\nrmse_chains = mean_squared_error(y_test, pred_chains, squared = False)\n\nprint(f'R2 on test samples: {r2_chains:.2f}')\nprint(f'RMSE on test samples: {rmse_chains:.1f}')\n\n\nR2 on test samples: 0.80\nRMSE on test samples: 72.5\n\n\n\n\n3.2.3 Adaptacja modelu RF\n\n\nKod\nprint(rf_meta)\n\n\nRandomForestRegressor(random_state=4)\n\n\n\n\nKod\nrf_meta.fit(X_train, y_train)\nr2_meta= rf_meta.score(X_test, y_test)\npred_meta = rf_meta.predict(X_test)\nrmse_meta = mean_squared_error(y_test, pred_meta, squared = False)\n\nprint(f'R2 on test samples: {r2_meta:.2f}')\nprint(f'RMSE on test samples: {rmse_meta:.1f}')\n\n\nR2 on test samples: 0.77\nRMSE on test samples: 78.0\n\n\n\n\n3.2.4 Podsumowanie\nBiorąc pod uwagę miary dopasowania najlepiej poradził sobie z tym zadaniem model składający się z trzech niezależnych modeli RF, potem model RF w wersji Regressor Chains, a najgorzej (o dziwo) radzi sobie z predykcją model korzystający adaptacji drzew decyzyjnych do wersji wielowyjściowej.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Przykłady - metody klasyczne</span>"
    ]
  },
  {
    "objectID": "examples.html#przykład-2",
    "href": "examples.html#przykład-2",
    "title": "3  Przykłady - metody klasyczne",
    "section": "3.3 Przykład 2",
    "text": "3.3 Przykład 2\nTym razem sformułujemy problem z wieloma wyjściami ale klasyfikacyjny i również dopasujemy trzy wersje modelu lasu losowego:\n\nlasy losowe dla każdej zmiennej y niezależnie;\nmodel lasu losowego z wykorzystaniem reguły Classifier Chains jako transformacji modelu\nlas losowy dla wszystkich zmiennych wynikowych jednocześnie (adaptacja modelu).\n\nAnalizowany problem będzie prawdziwy i będzie dotyczył klasyfikacji enzymów na podstawie cech charakterystycznych substratów. Pierwszych 31 zmiennych stanowi zmienne objaśniające, a 6 pozostałych zmienne kodujące przynależność do danej grupy enzymów.\n\n\nKod\ndt = pd.read_csv(\"data/original.csv\", index_col = \"id\")\ndt.head()\n\n\n\n\n\n\n\n\n\nBertzCT\nChi1\nChi1n\nChi1v\nChi2n\nChi2v\nChi3v\nChi4n\nEState_VSA1\nEState_VSA2\n...\nSlogP_VSA3\nVSA_EState9\nfr_COO\nfr_COO2\nEC1\nEC2\nEC3\nEC4\nEC5\nEC6\n\n\nid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC00009\n49.783540\n2.000000\n0.782574\n2.347723\n0.513277\n1.539831\n0.000000\n0.000000\n7.822697\n0.000000\n...\n4.565048\n16.923611\n0\n0\n1\n1\n1\n1\n0\n1\n\n\nC00013\n147.355172\n3.707107\n1.530297\n4.590890\n1.062804\n3.678309\n1.914534\n0.138556\n15.645394\n0.000000\n...\n13.440728\n20.899028\n0\n0\n1\n1\n1\n1\n0\n1\n\n\nC00014\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n6.150546\n...\n0.000000\n0.000000\n0\n0\n1\n1\n1\n1\n0\n1\n\n\nC00017\n172.720106\n4.947265\n2.081214\n2.081214\n1.157830\n1.157830\n0.489278\n0.180980\n12.514062\n12.451936\n...\n9.589074\n35.105740\n1\n1\n0\n1\n1\n0\n0\n0\n\n\nC00022\n72.039100\n2.642734\n1.381855\n1.381855\n0.861339\n0.861339\n0.301176\n0.000000\n11.752550\n0.000000\n...\n9.589074\n25.333333\n1\n1\n1\n1\n1\n1\n0\n1\n\n\n\n\n5 rows × 37 columns\n\n\n\n\n\nKod\ndt.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1039 entries, C00009 to C22220\nData columns (total 37 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   BertzCT            1039 non-null   float64\n 1   Chi1               1039 non-null   float64\n 2   Chi1n              1039 non-null   float64\n 3   Chi1v              1039 non-null   float64\n 4   Chi2n              1039 non-null   float64\n 5   Chi2v              1039 non-null   float64\n 6   Chi3v              1039 non-null   float64\n 7   Chi4n              1039 non-null   float64\n 8   EState_VSA1        1039 non-null   float64\n 9   EState_VSA2        1039 non-null   float64\n 10  ExactMolWt         1039 non-null   float64\n 11  FpDensityMorgan1   1039 non-null   float64\n 12  FpDensityMorgan2   1039 non-null   float64\n 13  FpDensityMorgan3   1039 non-null   float64\n 14  HallKierAlpha      1039 non-null   float64\n 15  HeavyAtomMolWt     1039 non-null   float64\n 16  Kappa3             1039 non-null   float64\n 17  MaxAbsEStateIndex  1039 non-null   float64\n 18  MinEStateIndex     1039 non-null   float64\n 19  NumHeteroatoms     1039 non-null   int64  \n 20  PEOE_VSA10         1039 non-null   float64\n 21  PEOE_VSA14         1039 non-null   float64\n 22  PEOE_VSA6          1039 non-null   float64\n 23  PEOE_VSA7          1039 non-null   float64\n 24  PEOE_VSA8          1039 non-null   float64\n 25  SMR_VSA10          1039 non-null   float64\n 26  SMR_VSA5           1039 non-null   float64\n 27  SlogP_VSA3         1039 non-null   float64\n 28  VSA_EState9        1039 non-null   float64\n 29  fr_COO             1039 non-null   int64  \n 30  fr_COO2            1039 non-null   int64  \n 31  EC1                1039 non-null   int64  \n 32  EC2                1039 non-null   int64  \n 33  EC3                1039 non-null   int64  \n 34  EC4                1039 non-null   int64  \n 35  EC5                1039 non-null   int64  \n 36  EC6                1039 non-null   int64  \ndtypes: float64(28), int64(9)\nmemory usage: 308.5+ KB\n\n\nSprawdzimy na ile niezbalansowane są poszczególne klasy wynikowe.\n\n\nKod\ndt_deps = dt.loc[:,'EC1':'EC6']\ndt_deps = dt_deps.melt()\ndt_deps = dt_deps[dt_deps.value == 1]\nsns.countplot(data = dt_deps, x = 'variable')\n\n\n\n\n\n\n\n\n\nNiestety nie wszystkie klasy występują jednakowo często i może pojawić się zjawisko, że kombinacja enzymów będzie występowała bardzo rzadko (np. raz). Jak widać z poniższej tabeli faktycznie tak się dzieje. To nie pozwala przeprowadzić uczenia. Dlatego musimy połączyć pewne klasy enzymów aby uniemożliwić taką sytuację.\n\n\nKod\ndt.loc[:,'EC1':'EC6'].value_counts()\n\n\nEC1  EC2  EC3  EC4  EC5  EC6\n1    0    0    0    0    0      178\n0    1    0    0    0    0      136\n1    1    0    0    0    0      112\n0    1    1    0    0    0       90\n     0    1    0    0    0       69\n1    1    0    1    0    0       38\n          1    0    0    0       37\n     0    0    1    0    0       33\n0    0    0    1    0    0       30\n     1    0    1    0    0       27\n               0    1    0       21\n1    0    1    0    0    0       20\n     1    0    0    0    1       19\n               1    0    1       15\n0    0    0    0    1    0       15\n1    1    0    0    1    0       14\n     0    0    0    1    0       12\n0    0    1    1    0    0       12\n          0    0    0    1       11\n1    1    0    1    1    1       11\n0    1    0    0    0    1       10\n          1    1    0    0        9\n1    0    0    1    1    0        8\n     1    1    1    0    1        8\n     0    0    1    0    1        7\n     1    1    0    0    1        7\n     0    0    0    0    1        7\n0    1    1    0    1    0        7\n                    0    1        7\n1    1    1    1    1    0        6\n          0    1    1    0        6\n0    1    0    1    0    1        6\n1    1    1    0    1    0        5\n0    0    0    1    1    0        5\n     1    1    1    1    0        4\n1    1    0    0    1    1        4\n          1    1    0    0        4\n0    0    1    0    0    1        4\n                    1    0        3\n1    1    1    1    1    1        3\n     0    1    1    0    0        3\n               0    0    1        3\n0    1    0    1    1    0        2\n                         1        2\n     0    0    1    0    1        2\n1    0    0    0    1    1        1\n0    0    1    1    0    1        1\n               0    1    1        1\n1    0    1    1    0    1        1\n               0    1    0        1\n0    1    1    1    0    1        1\n     0    1    1    1    0        1\nName: count, dtype: int64\n\n\nUsuniemy zatem takie kombinacje, które występują bardzo rzadko w danych.\n\n\nKod\ncombinations = dt.loc[:,'EC1':'EC6'].value_counts().index.to_numpy()\nidx = dt.loc[:,'EC1':'EC6'].value_counts().to_numpy()\nbad_combinations = combinations[idx&lt;10]\nidx = []\nfor i in range(len(dt)):\n  idx.append(True)\n  for j in range(len(bad_combinations)):\n    if all(dt.iloc[i, 31:] == bad_combinations[j]):\n      idx[i]=False\n\ndt = dt.iloc[idx,:]\n\n\n\n\nKod\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import MultiOutputClassifier, ClassifierChain\ny = dt.iloc[:,31:].to_numpy()\nX = dt.iloc[:,:31].to_numpy()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 44)\n\n\n\n3.3.1 Niezależne lasy losowe\n\n\nKod\nrf_meta = RandomForestClassifier(random_state=4)\nrf_indep = MultiOutputClassifier(rf_meta)\nprint(rf_indep)\n\nrf_indep.fit(X_train, y_train)\nacc_indep= rf_indep.score(X_test, y_test)\npred_indep = rf_indep.predict(X_test)\n\nprint(f'Accuracy on test samples: {acc_indep:.3f}')\n\n\nMultiOutputClassifier(estimator=RandomForestClassifier(random_state=4))\nAccuracy on test samples: 0.179\n\n\n\n\n3.3.2 Classifier Chains\n\n\nKod\nrf_chains = ClassifierChain(rf_meta)\nprint(rf_chains)\n\nrf_chains.fit(X_train, y_train)\nacc_chains= rf_chains.score(X_test, y_test)\npred_chains = rf_chains.predict(X_test)\n\nprint(f'Accuracy on test samples: {acc_chains:.3f}')\n\n\nClassifierChain(base_estimator=RandomForestClassifier(random_state=4))\nAccuracy on test samples: 0.190\n\n\n\n\n3.3.3 Adaptacja modelu RF\n\n\nKod\nrf_meta.fit(X_train, y_train)\nacc_meta= rf_meta.score(X_test, y_test)\npred_meta = rf_meta.predict(X_test)\n\nprint(f'Accuracy on test samples: {acc_meta:.3f}')\n\n\nAccuracy on test samples: 0.201\n\n\n\n\n3.3.4 Podsumowanie\nRównież i tym razem nie widać wyraźnych różnic pomiędzy jakością dopasowania modeli. Model adaptowanego lasu losowego poradził sobie z zadanie najlepiej (19% poprawności trafień), Classifier Chains dał 18,7%, a niezależne lasy losowe 17,2%.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Przykłady - metody klasyczne</span>"
    ]
  },
  {
    "objectID": "examples2.html",
    "href": "examples2.html",
    "title": "4  Przykłady NN",
    "section": "",
    "text": "4.1 Przykład 1\nRozwiązanie przykładu z poprzedniego rozdziału można dokonać z dużo lepszą precyzją wykorzystując sieci neuronowe. W tym przykładzie po raz kolejny wygenerujemy dane do uczenia1, a następnie wytrenujemy sieć (dosyć płytką) MLP.\nKod\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization, ReLU, LeakyReLU, ELU\nfrom keras.callbacks import EarlyStopping\nimport keras\nKod\n# generowanie danych do zadania\nX, y = make_regression(n_samples=700, n_features=10, n_informative = 8, n_targets=3, random_state=4)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)\n\nn_neurons = [10,20,50]\nModel będzie bardzo prosty, składający się z tylko jednej warstwy ukrytej.\nKod\ndef get_model(n_inputs, n_outputs, n_neurons):\n  model = Sequential()\n  model.add(Dense(int(n_neurons), input_dim=n_inputs, activation='relu'))\n  model.add(Dense(n_outputs, activation='linear'))\n  model.compile(loss='mse', optimizer='adam')\n  return model\nW tym przykładzie chciałem również pokazać jak wykonywać trenowanie sieci z użyciem sprawdzianu krzyżowego, który pomoże nam ustalić optymalną liczę neuronów w warstwie ukrytej.\nKod\n# ocena dopasowania modelu z wykorzystaniem CV\ndef evaluate_model(X, y, n_neurons):\n    results = list()\n    n_inputs, n_outputs = X.shape[1], y.shape[1]\n    # definicja CV\n    cv = RepeatedKFold(n_splits=5, random_state=1)\n    # pętla po foldach\n    for train_ix, test_ix in cv.split(X):\n        # przygotowanie danych\n        X_tr, X_te = X[train_ix], X[test_ix]\n        y_tr, y_te = y[train_ix], y[test_ix]\n        # określenie modelu\n        model = get_model(n_inputs, n_outputs, n_neurons)\n        # dopasowanie modelu\n        model.fit(X_tr, y_tr, verbose=0, epochs=100)\n        # ocena dopasowania na foldzie testowym\n        mae = model.evaluate(X_te, y_te, verbose=0)\n        results.append(mae)\n    return results\nKod\nresults = []\nfor i in n_neurons:\n  # dopasuj i oceń model na zbiorze uczącym\n  results.append(np.mean(evaluate_model(X_train, y_train, i)))\nKod\nresults = np.load(\"./data/mlp_eval.npz\")\nresults = results['arr_0'].tolist()\nfor i in range(len(n_neurons)):\n  print(f\"Dla {n_neurons[i]} neuronów MAE: {results[i]:.0f}\")\n\n\nDla 10 neuronów MAE: 16409\nDla 20 neuronów MAE: 9806\nDla 50 neuronów MAE: 3779\nNajlepszy rezultat osiągamy dla 50 neuronów i taki parametr dobierzemy w ostatecznym modelu.\nKod\nkeras.utils.set_random_seed(44)\nmy_callbacks = [\n    EarlyStopping(patience=2)\n]\n\nmodel = get_model(X_train.shape[1], y_train.shape[1], 50)\nhistory = model.fit(X_train, y_train, \n                    verbose=0, epochs=1000, \n                    validation_split=0.2, callbacks=my_callbacks)\nProces uczenia przebiegał prawidłowo i osiągnięto niski poziom funkcji straty.\nKod\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()\nWyniki dopasowania znacznie przekraczają wyniki uzyskane metodami z poprzedniego rozdziału.\nKod\ny_pred = model.predict(X_test, verbose=0)\nrmse_mlp = mean_squared_error(y_test, y_pred, squared=False)\nr2_mlp = r2_score(y_test, y_pred)\nprint(f\"R2 on test sample: {r2_mlp:.2f}\")\nprint(f\"RMSE on test sample: {rmse_mlp:.1f}\")\n\n\nR2 on test sample: 1.00\nRMSE on test sample: 0.0",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Przykłady NN</span>"
    ]
  },
  {
    "objectID": "examples2.html#przykład-1",
    "href": "examples2.html#przykład-1",
    "title": "4  Przykłady NN",
    "section": "",
    "text": "1 te same co z przykładu regresyjnego z poprzedniego wykładu",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Przykłady NN</span>"
    ]
  },
  {
    "objectID": "examples2.html#przykład-2",
    "href": "examples2.html#przykład-2",
    "title": "4  Przykłady NN",
    "section": "4.2 Przykład 2",
    "text": "4.2 Przykład 2\nW tym przykładzie jeszcze raz rozpatrzymy zadanie klasyfikacyjne z wieloma wyjściami z poprzedniego rozdziału. Przeprowadzimy czynności preprocessingu podobne jak w poprzednim rozdziale, dodając jeszcze standaryzację, która dla sieci neuronowych jest bardzo ważna.\n\n\nKod\nfrom sklearn.preprocessing import StandardScaler\ndt = pd.read_csv(\"./data/original.csv\", index_col = \"id\")\ncombinations = dt.loc[:,'EC1':'EC6'].value_counts().index.to_numpy()\nidx = dt.loc[:,'EC1':'EC6'].value_counts().to_numpy()\nbad_combinations = combinations[idx&lt;10]\nidx = []\nfor i in range(len(dt)):\n  idx.append(True)\n  for j in range(len(bad_combinations)):\n    if all(dt.iloc[i, 31:] == bad_combinations[j]):\n      idx[i]=False\n\ndt = dt.iloc[idx,:]\n\ny = dt.iloc[:,31:].to_numpy()\nX = dt.iloc[:,:31].to_numpy()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 44)\n\nscaler = StandardScaler().fit(X_train)\nX_test = scaler.transform(X_test)\nX_train = scaler.transform(X_train)\n\n\nNastępnie przygotujemy model sieci neuronowej, która pozwoli na właściwe klasyfikacje obiektów.\n\n\nKod\nmodel = Sequential()\nmodel.add(Dense(15, input_dim=X_train.shape[1]))\nmodel.add(ReLU())\nmodel.add(Dropout(0.1))\nmodel.add(Dense(y_train.shape[1], activation='sigmoid'))\n\nopt = keras.optimizers.Nadam(0.001)\nmodel.compile(loss='binary_crossentropy', optimizer=opt)\nmodel.summary()\n\n\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_2 (Dense)             (None, 15)                480       \n                                                                 \n re_lu (ReLU)                (None, 15)                0         \n                                                                 \n dropout (Dropout)           (None, 15)                0         \n                                                                 \n dense_3 (Dense)             (None, 6)                 96        \n                                                                 \n=================================================================\nTotal params: 576 (2.25 KB)\nTrainable params: 576 (2.25 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\n\nKod\nkeras.utils.set_random_seed(44)\nmy_callbacks = [\n    EarlyStopping(patience=10)\n]\nhistory = model.fit(X_train, y_train, epochs=1000,  validation_split=0.4, verbose=0,\ncallbacks=my_callbacks)\n\n\n\n\nKod\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nKod\nfrom sklearn.metrics import accuracy_score\ny_pred = model.predict(X_test, verbose=0)\ny_class = y_pred.round()\nacc = accuracy_score(y_test, y_class)\nprint(f\"ACC on test sample: {acc:.3f}\")\n\n\nACC on test sample: 0.198\n\n\n\n4.2.1 Podsumowanie\nModel prostej sieci neuronowej nie poprawił znacząco jakości dopasowania w stosunku do modelu lasu losowego adaptowanego do zadania z wieloma wyjściami.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Przykłady NN</span>"
    ]
  },
  {
    "objectID": "rnn.html",
    "href": "rnn.html",
    "title": "\n5  Rodzaje szeregów czasowych\n",
    "section": "",
    "text": "5.1 Zastosowanie sieci rekurencyjnych w szeregach czasowych\nW tym podrozdziale omówimy trzy zaawansowane techniki poprawy wydajności i siły generalizacji rekurencyjnych sieci neuronowych. Zademonstrujemy wszystkie trzy koncepcje na problemie prognozowania pogody, gdzie mamy dostęp do szeregu obserwacji pochodzących z czujników zainstalowanych na dachu budynku, takich jak temperatura, ciśnienie powietrza i wilgotność, które użyjemy do przewidywania, jaka będzie temperatura 24 godziny po ostatniej obserwacji w bazie danych. Jest to dość trudny problem, który ilustruje wiele typowych trudności napotykanych podczas pracy z szeregami czasowymi.\nOmówimy następujące techniki:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Rodzaje szeregów czasowych</span>"
    ]
  },
  {
    "objectID": "rnn.html#zastosowanie-sieci-rekurencyjnych-w-szeregach-czasowych",
    "href": "rnn.html#zastosowanie-sieci-rekurencyjnych-w-szeregach-czasowych",
    "title": "\n5  Rodzaje szeregów czasowych\n",
    "section": "",
    "text": "Recurrent dropout - to specyficzny, wbudowany sposób użycia dropoutu do walki z nadmiernym dopasowaniem w warstwach rekurencyjnych.\nSkładanie warstw rekurencyjnych - zwiększa to moc reprezentacyjną sieci (kosztem większego obciążenia obliczeniowego).\nDwukierunkowe warstwy rekurencyjne - prezentują one tę samą informację sieci rekurencyjnej na różne sposoby, zwiększając dokładność i łagodząc problemy związane z zapominaniem.\n\n\nPrzykład 5.1 W analizowanym zestawie danych 14 różnych wielkości (takich jak temperatura powietrza, ciśnienie atmosferyczne, wilgotność, kierunek wiatru i tak dalej) było rejestrowanych co 10 minut, przez kilka lat. Oryginalne dane sięgają 2003 roku, ale ten przykład jest ograniczony do danych z lat 2009-2016.\nNa początek pobierzemy dane z serwera https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip i rozpakujemy.\n\nKodurl &lt;-\n \"https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\"\ndownload.file(url, destfile = basename(url))\nzip::unzip(zipfile = \"jena_climate_2009_2016.csv.zip\",\n          files = \"jena_climate_2009_2016.csv\")\n\n\n\nKodfull_df &lt;- readr::read_csv(\"jena_climate_2009_2016.csv\")\nfull_df\n\n# A tibble: 420,451 × 15\n   `Date Time`         `p (mbar)` `T (degC)` `Tpot (K)` `Tdew (degC)` `rh (%)`\n   &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 01.01.2009 00:10:00       997.      -8.02       265.         -8.9      93.3\n 2 01.01.2009 00:20:00       997.      -8.41       265.         -9.28     93.4\n 3 01.01.2009 00:30:00       997.      -8.51       265.         -9.31     93.9\n 4 01.01.2009 00:40:00       997.      -8.31       265.         -9.07     94.2\n 5 01.01.2009 00:50:00       997.      -8.27       265.         -9.04     94.1\n 6 01.01.2009 01:00:00       996.      -8.05       265.         -8.78     94.4\n 7 01.01.2009 01:10:00       996.      -7.62       266.         -8.3      94.8\n 8 01.01.2009 01:20:00       996.      -7.62       266.         -8.36     94.4\n 9 01.01.2009 01:30:00       996.      -7.91       266.         -8.73     93.8\n10 01.01.2009 01:40:00       997.      -8.43       265.         -9.34     93.1\n# ℹ 420,441 more rows\n# ℹ 9 more variables: `VPmax (mbar)` &lt;dbl&gt;, `VPact (mbar)` &lt;dbl&gt;,\n#   `VPdef (mbar)` &lt;dbl&gt;, `sh (g/kg)` &lt;dbl&gt;, `H2OC (mmol/mol)` &lt;dbl&gt;,\n#   `rho (g/m**3)` &lt;dbl&gt;, `wv (m/s)` &lt;dbl&gt;, `max. wv (m/s)` &lt;dbl&gt;,\n#   `wd (deg)` &lt;dbl&gt;\n\n\nChoć nie jest to konieczne w tym zadaniu, to przekształcimy datę (będącą pierwsza kolumną w zestawie danych) z typu character do typu DateTime.\n\nKodfull_df$`Date Time` %&lt;&gt;%\n as.POSIXct(tz = \"Etc/GMT+1\", format = \"%d.%m.%Y %H:%M:%S\")\n\n\nZwróć uwagę, że przekazujemy tz = \"Etc/GMT+1\" zamiast tz = \"Europe/Berlin\", ponieważ znaczniki czasu w zbiorze danych nie dostosowują się do czasu letniego środkowoeuropejskiego (znanego również jako czas letni), ale zawsze są według czasu środkowoeuropejskiego.\n\n\n\n\n\n\nWskazówka\n\n\n\nPowyżej po raz pierwszy użyliśmy potoku przypisania x %&lt;&gt;% fn(), który jest skrótem od x &lt;- x %&gt;% fn(). Jest to przydatne, ponieważ pozwala pisać bardziej czytelny kod i uniknąć wielokrotnego powtarzania tej samej nazwy zmiennej. Przypisanie jest udostępniane przez wywołanie library(keras).\n\n\n\nKodplot(`T (degC)` ~ `Date Time`, data = full_df, pch = 20, cex = .3)\n\n\n\n\n\n\nRysunek 5.1: Przebieg szeregu czasowego temperatury\n\n\n\n\nRysunek 5.1 przedstawia wykres temperatury (w stopniach Celsjusza) w czasie. Na tym wykresie wyraźnie widać roczną okresowość temperatury - dane obejmują 8 lat.\n\nKodplot(`T (degC)` ~ `Date Time`, data = full_df[1:1440, ], type = 'l')\n\n\n\n\n\n\nRysunek 5.2: Wycinek przebiegu szeregu czasowego temperatury\n\n\n\n\nRysunek 5.2 przedstawia węższy wykres danych temperatury z pierwszych 10 dni. Ponieważ dane są rejestrowane co 10 minut, otrzymujemy 24 × 6 = 144 punkty danych dziennie. Zauważ też, że ten 10-dniowy okres musi pochodzić z dość zimnego zimowego miesiąca. Gdybyś próbował przewidzieć średnią temperaturę na następny miesiąc biorąc pod uwagę kilka miesięcy danych z przeszłości, problem byłby łatwy, ze względu na okresowość danych w skali roku. Ale patrząc na dane w skali dni, temperatura wygląda o wiele bardziej chaotycznie. Czy ten szereg czasowy jest przewidywalny w skali dziennej? Przekonajmy się.\nWe wszystkich naszych eksperymentach wykorzystamy pierwsze 50% danych do szkolenia, kolejne 25% do walidacji, a ostatnie 25% do testowania. Podczas pracy z danymi szeregów czasowych ważne jest, aby używać danych walidacyjnych i testowych, które są nowsze niż dane treningowe, ponieważ próbujemy przewidzieć przyszłość na podstawie przeszłości, a nie odwrotnie, a podziały walidacyjne / testowe powinny to odzwierciedlać.\n\nKodnum_train_samples &lt;- round(nrow(full_df) * .5)\nnum_val_samples &lt;- round(nrow(full_df) * 0.25)\nnum_test_samples &lt;- nrow(full_df) - num_train_samples - num_val_samples\n\ntrain_df &lt;- full_df[seq(num_train_samples), ]\n\nval_df &lt;- full_df[seq(from = nrow(train_df) + 1,\n                      length.out = num_val_samples), ]\n\ntest_df &lt;- full_df[seq(to = nrow(full_df),\n                       length.out = num_test_samples), ]\n\ncat(\"num_train_samples:\", nrow(train_df), \"\\n\")\n\nnum_train_samples: 210226 \n\nKodcat(\"num_val_samples:\", nrow(val_df), \"\\n\")\n\nnum_val_samples: 105113 \n\nKodcat(\"num_test_samples:\", nrow(test_df), \"\\n\")\n\nnum_test_samples: 105112 \n\n\nDokładne sformułowanie problemu będzie następujące: biorąc pod uwagę dane obejmujące poprzednie pięć dni i próbkowane raz na godzinę, czy możemy przewidzieć temperaturę w ciągu 24 godzin?\nPo pierwsze, wstępnie przetworzymy dane do formatu, który może przyjąć sieć neuronowa. Dane są już numeryczne, więc nie trzeba ich wektoryzować. Jednak każdy szereg czasowy w danych ma inną skalę (np. ciśnienie atmosferyczne, mierzone w mbar, wynosi około 1000, podczas gdy H2OC, mierzone w milimolach na mol, wynosi około 3). Znormalizujemy każdą serię czasową (kolumnę) niezależnie, tak aby wszystkie przyjmowały małe wartości w podobnej skali. Użyjemy pierwszych 210 226 kroków czasowych jako danych treningowych, więc obliczymy średnią i odchylenie standardowe tylko dla tej części danych.\n\nKodinput_data_colnames &lt;- names(full_df) %&gt;%\n  setdiff(c(\"Date Time\"))\n\nnormalization_values &lt;-\n  zip_lists(mean = lapply(train_df[input_data_colnames], mean),\n            sd = lapply(train_df[input_data_colnames], sd))\n\nstr(normalization_values)\n\nList of 14\n $ p (mbar)       :List of 2\n  ..$ mean: num 989\n  ..$ sd  : num 8.51\n $ T (degC)       :List of 2\n  ..$ mean: num 8.83\n  ..$ sd  : num 8.77\n $ Tpot (K)       :List of 2\n  ..$ mean: num 283\n  ..$ sd  : num 8.87\n $ Tdew (degC)    :List of 2\n  ..$ mean: num 4.31\n  ..$ sd  : num 7.08\n $ rh (%)         :List of 2\n  ..$ mean: num 75.9\n  ..$ sd  : num 16.6\n $ VPmax (mbar)   :List of 2\n  ..$ mean: num 13.1\n  ..$ sd  : num 7.6\n $ VPact (mbar)   :List of 2\n  ..$ mean: num 9.19\n  ..$ sd  : num 4.15\n $ VPdef (mbar)   :List of 2\n  ..$ mean: num 3.95\n  ..$ sd  : num 4.77\n $ sh (g/kg)      :List of 2\n  ..$ mean: num 5.81\n  ..$ sd  : num 2.63\n $ H2OC (mmol/mol):List of 2\n  ..$ mean: num 9.3\n  ..$ sd  : num 4.2\n $ rho (g/m**3)   :List of 2\n  ..$ mean: num 1218\n  ..$ sd  : num 42\n $ wv (m/s)       :List of 2\n  ..$ mean: num 2.15\n  ..$ sd  : num 1.53\n $ max. wv (m/s)  :List of 2\n  ..$ mean: num 3.56\n  ..$ sd  : num 2.32\n $ wd (deg)       :List of 2\n  ..$ mean: num 176\n  ..$ sd  : num 85.9\n\nKodnormalize_input_data &lt;- function(df) {\n  normalize &lt;- function(x, center, scale)\n    (x - center) / scale\n\n  for(col_nm in input_data_colnames) {\n    col_nv &lt;- normalization_values[[col_nm]]\n    df[[col_nm]] %&lt;&gt;% normalize(., col_nv$mean, col_nv$sd)\n  }\n\n  df\n}\n\n\nNastępnie stwórzmy obiekt TF Dataset, który zawiera partie danych z ostatnich pięciu dni wraz z temperaturą docelową 24 godziny w przyszłości. Ponieważ próbki w zestawie danych są wysoce nadmiarowe (próbka N i próbka N + 1 będą miały większość wspólnych kroków czasowych), marnotrawstwem byłoby jawne przydzielanie pamięci dla każdej próbki. Zamiast tego będziemy generować próbki w locie, zachowując w pamięci tylko oryginalne tablice danych i nic więcej.\nMoglibyśmy z łatwością napisać funkcję w R, aby to zrobić, ale istnieje wbudowane narzędzie w keras, które właśnie to robi - (timeseries_dataset_from_array()) - więc możemy zaoszczędzić sobie trochę pracy, korzystając z niego. Ogólnie rzecz biorąc, można go używać do wszelkiego rodzaju zadań związanych z prognozowaniem szeregów czasowych.\n\n\n\n\n\n\nAdnotacja\n\n\n\nAby zrozumieć działanie funkcji timeseries_dataset_from_array(), przyjrzyjmy się prostemu przykładowi. Ogólna idea polega na dostarczeniu tablicy danych szeregów czasowych (argument dane), a funkcja timeseries_dataset_from_array() daje okna wyodrębnione z oryginalnych szeregów czasowych (nazwiemy je “sekwencjami”).\nNa przykład, jeśli użyjesz data = [0 1 2 3 4 5 6] i sequence_length = 3, wówczas timeseries_dataset_from_array() wygeneruje następujące próbki: [0 1 2], [1 2 3] , [2 3 4], [3 4 5], [4 5 6].\nDo funkcji timeseries_dataset_ from_array() można również przekazać argument targets (tablicę). Pierwszy wpis w tablicy targets powinien odpowiadać pożądanemu celowi dla pierwszej sekwencji, która zostanie wygenerowana z tablicy data. Tak więc, jeśli wykonujemy prognozowanie szeregów czasowych, targets powinny być tą samą tablicą co data, przesuniętą o pewną wartość.\nNa przykład, z data = [0 1 2 3 4 5 6 ...] i sequence_length = 3, można utworzyć zestaw danych do przewidywania następnego kroku w serii, przekazując targets = [3 4 5 6 ...]. Przykładowo:\n\nKodint_sequence &lt;- seq(10)\ndummy_dataset &lt;- timeseries_dataset_from_array(\n  data = head(int_sequence, -3),\n  targets = tail(int_sequence, -3),\n  sequence_length = 3,\n  batch_size = 2\n)\n\nlibrary(tfdatasets)\ndummy_dataset_iterator &lt;- as_array_iterator(dummy_dataset)\n\nrepeat {\n  batch &lt;- iter_next(dummy_dataset_iterator)\n  if (is.null(batch))\n    break\n  c(inputs, targets) %&lt;-% batch\n  for (r in 1:nrow(inputs))\n    cat(sprintf(\"input: [ %s ]  target: %s\\n\",\n                paste(inputs[r, ], collapse = \" \"), targets[r]))\n  cat(strrep(\"-\", 27), \"\\n\")\n}\n\ninput: [ 1 2 3 ]  target: 4\ninput: [ 2 3 4 ]  target: 5\n--------------------------- \ninput: [ 3 4 5 ]  target: 6\ninput: [ 4 5 6 ]  target: 7\n--------------------------- \ninput: [ 5 6 7 ]  target: 8\n--------------------------- \n\n\n\n\nUżyjemy funkcji timeseries_dataset_from_array(), aby utworzyć trzy zestawy danych: jeden do szkolenia, jeden do walidacji i jeden do testowania. Użyjemy następujących wartości parametrów:\n\n\nsampling_rate = 6 - obserwacje będą próbkowane z częstotliwością jednego punktu danych na godzinę (zachowamy tylko jeden punkt danych z 6).\n\nsequence_length = 120 - obserwacje będą sięgać pięciu dni wstecz (120 godzin).\n\ndelay = sampling_rate * (sequence_length + 24 - 1) - celem dla sekwencji będzie temperatura 24 godziny po zakończeniu sekwencji.\n\n\nKodsampling_rate &lt;- 6\nsequence_length &lt;- 120\ndelay &lt;- sampling_rate * (sequence_length + 24 - 1)\nbatch_size &lt;- 256\n\ndf_to_inputs_and_targets &lt;- function(df) {\n  inputs &lt;- df[input_data_colnames] %&gt;%\n    normalize_input_data() %&gt;%\n    as.matrix()\n\n  targets &lt;- as.array(df$`T (degC)`)\n\n  list(\n    head(inputs, -delay),\n    tail(targets, -delay)\n  )\n}\n\nmake_dataset &lt;- function(df) {\n  c(inputs, targets) %&lt;-% df_to_inputs_and_targets(df)\n  timeseries_dataset_from_array(\n    inputs, targets,\n    sampling_rate = sampling_rate,\n    sequence_length = sequence_length,\n    shuffle = TRUE,\n    batch_size = batch_size\n  )\n}\n\ntrain_dataset &lt;- make_dataset(train_df)\nval_dataset &lt;- make_dataset(val_df)\ntest_dataset &lt;- make_dataset(test_df)\n\n\nKażdy zestaw danych daje partie jako parę (samples, targets), gdzie samples to partia 256 próbek, z których każda zawiera 120 kolejnych godzin danych wejściowych, a targets to odpowiednia tablica 256 temperatur docelowych. Należy pamiętać, że próbki są losowo tasowane, więc dwie kolejne sekwencje w partii (takie jak sample[1, ] i sample[2, ]) niekoniecznie są czasowo blisko siebie.\n\nKodc(samples, targets) %&lt;-% iter_next(as_iterator(train_dataset))\ncat(\"samples shape: \", format(samples$shape), \"\\n\",\n    \"targets shape: \", format(targets$shape), \"\\n\", sep = \"\")\n\nsamples shape: (256, 120, 14)\ntargets shape: (256)\n\n\n\n\n\n\n\n\n\nWażne\n\n\n\nZanim zaczniemy wykorzystywać modele uczenia głębokiego typu black-box w rozwiązywaniu problemu przewidywania temperatury, wypróbujmy proste, zdroworozsądkowe podejście. Posłuży ono jako sprawdzian poprawności i ustanowi punkt odniesienia, który będziemy musieli pokonać, aby zademonstrować przydatność bardziej zaawansowanych modeli uczenia maszynowego. Takie zdroworozsądkowe podstawy mogą być przydatne, gdy zabieramy się do nowego problemu, dla którego nie ma (jeszcze) znanego rozwiązania. Klasycznym przykładem są niezrównoważone zadania klasyfikacyjne, w których niektóre klasy występują znacznie częściej niż inne. Jeśli zbiór danych zawiera 90% przypadków klasy A i 10% przypadków klasy B, wówczas zdroworozsądkowym podejściem do zadania klasyfikacji jest zawsze przewidywanie “A”, gdy prezentowana jest nowa próbka. Taki klasyfikator jest ogólnie dokładny w 90%, a zatem każde podejście oparte na uczeniu powinno pokonać ten 90% wynik, aby wykazać przydatność. Czasami takie elementarne wartości bazowe mogą okazać się zaskakująco trudne do pokonania.\n\n\n\n5.1.1 Model bazowy\nW tym przypadku można bezpiecznie założyć, że szereg czasowy temperatury jest ciągły (temperatury jutro będą prawdopodobnie zbliżone do temperatur dzisiaj), a także okresowy z okresem dziennym. Dlatego zdroworozsądkowym podejściem jest zawsze przewidywanie, że temperatura za 24 godziny będzie równa temperaturze w obecnej chwili. Oceńmy to podejście, korzystając z metryki średniego błędu bezwzględnego (MAE).\nZamiast oceniać wszystko w R stosując funkcje for, as_ array_iterator() i iter_next(), możemy to równie łatwo zrobić za pomocą transformacji TF Dataset. Najpierw wywołujemy dataset_unbatch(), aby każdy element zbioru danych stał się pojedynczym przypadkiem (sample, target). Następnie używamy funkcji dataset_map(), aby obliczyć błąd bezwzględny dla każdej pary (sample, target), a następnie dataset_reduce(), aby zgromadzić całkowity błąd i całkowitą liczbę widzianych próbek.\nPrzypomnijmy, że funkcje przekazywane do dataset_map() i dataset_reduce() będą wywoływane z tensorami symoblicznymi. Wycinanie tensora z liczbą ujemną, taką jak samples[-1, ], wybiera ostatni wyraz wzdłuż tej osi, tak jakbyśmy napisali samples[nrow(samples), ].\n\nKodevaluate_naive_method &lt;- function(dataset) {\n\n  unnormalize_temperature &lt;- function(x) {\n    nv &lt;- normalization_values$`T (degC)`\n    (x * nv$sd) + nv$mean\n  }\n\n  temp_col_idx &lt;- match(\"T (degC)\", input_data_colnames)\n\n  reduction &lt;- dataset %&gt;%\n    dataset_unbatch() %&gt;%\n    dataset_map(function(samples, target) {\n      last_temp_in_input &lt;- samples[-1, temp_col_idx]\n      pred &lt;- unnormalize_temperature(last_temp_in_input)\n      abs(pred - target)\n    }) %&gt;%\n    dataset_reduce(\n      initial_state = list(total_samples_seen = 0L,\n                           total_abs_error = 0),\n      reduce_func = function(state, element) {\n        state$total_samples_seen %&lt;&gt;% `+`(1L)\n        state$total_abs_error %&lt;&gt;% `+`(element)\n        state\n      }\n    ) %&gt;%\n    lapply(as.numeric)\n\n  mae &lt;- with(reduction,\n              total_abs_error / total_samples_seen)\n  mae\n}\n\nsprintf(\"Validation MAE: %.2f\", evaluate_naive_method(val_dataset))\n\n[1] \"Validation MAE: 2.43\"\n\nKodsprintf(\"Test MAE: %.2f\", evaluate_naive_method(test_dataset))\n\n[1] \"Test MAE: 2.62\"\n\n\nZdroworozsądkowy punkt odniesienia osiąga MAE na zbiorze walidacyjnym na poziomie 2,43 stopnia Celsjusza i MAE na testowym na poziomie 2,62 stopnia Celsjusza. Jeśli więc zawsze zakładamy, że temperatura w ciągu 24 godzin w przyszłości będzie taka sama jak obecnie, będziesz się mylił średnio o około dwa i pół stopnia. Prognoza nie jest zła ale z pewnością da się ją poprawić.\nW ten sam sposób, w jaki warto ustalić zdroworozsądkowy model bazowy przed użyciem uczenia maszynowego, warto wypróbować również proste modele uczenia maszynowego (takie jak małe, gęsto połączone sieci) przed przejściem do bardziej skomplikownych i kosztownych obliczeniowo modeli, takich jak RNN. Jest to najlepszy sposób na upewnienie się, że jakakolwiek dalsza złożoność problemu jest uzasadniona i przynosi realne korzyści.\n\n5.1.2 Prosty model sieci gęstej\nPoniższy kod pokazuje w pełni połączony model, który rozpoczyna się od spłaszczenia danych, a następnie przepuszcza je przez dwie warstwy layer_dense(). Zwróćmy uwagę na brak funkcji aktywacji w ostatniej warstwie layer_dense(), co jest typowe dla problemu regresji. Używamy błędu średniokwadratowego (MSE) jako funkcji straty, a nie MAE, ponieważ w przeciwieństwie do MAE, jest on różniczkowalny wokół zera, co jest użyteczną właściwością dla spadku gradientu. MAE będziemy również monitorować, dodając go jako metrykę w funkcji compile().\n\nKodncol_input_data &lt;- length(input_data_colnames)\n\ninputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_flatten() %&gt;%\n  layer_dense(16, activation=\"relu\") %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;%\n  compile(optimizer = \"rmsprop\",\n          loss = \"mse\",\n          metrics = \"mae\")\n\nsave_model_tf(model, \"models/jena_dense.keras\")\nsaveRDS(history, \"models/jena_dense_history.rds\")\n\nhistory &lt;- model %&gt;%\n  fit(train_dataset,\n      epochs = 10,\n      validation_data = val_dataset)\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_dense.keras\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 4s - loss: 58.4128 - mae: 6.2125 - 4s/epoch - 10ms/step\n\n\n[1] \"Test MAE: 6.21\"\n\nKodhistory &lt;- readRDS(\"models/jena_dense_history.rds\")\nplot(history, metrics = \"mae\")\n\n\n\n\n\n\n\nNiektóre wartości funkcji straty na zbiorze walidacyjnym są zbliżone do modelu bazowego ale nie można powiedzieć, że model ten jest lepszy od bazowego. To pokazuje zaletę posiadania modelu odniesienia, bo okazuje się, że nie jest łatwo go “pokonać”. Zdrowy rozsądek zawiera wiele cennych informacji, do których model uczenia maszynowego nie ma dostępu. Jest to dość istotne ograniczenie uczenia maszynowego w ogóle: o ile algorytm uczenia nie jest zakodowany na sztywno, by szukać konkretnego rodzaju prostego modelu, może on czasem nie znaleźć prostego rozwiązania problemu. Właśnie dlatego wykorzystanie dobrej inżynierii cech i odpowiednich założeń dotyczących architektury ma zasadnicze znaczenie. Powinniśmy dokładnie powiedzieć modelowi, czego powinien szukać.\n\n5.1.3 Model oparty o konwolucje 1D\nMówiąc o wykorzystaniu odpowiednich założeń co do architektury, być może model konwolucyjny będzie działać poprawnie. Sieć konwolucyjna 1D mogłaby ponownie wykorzystywać te same reprezentacje w różnych dniach, podobnie jak przestrzenna sieć konwolucyjna może ponownie wykorzystywać te same reprezentacje w różnych lokalizacjach na obrazie. Znamy już warstwy layer_conv_2d() i layer_separable_conv_2d(), które widzą dane wejściowe przez małe okna (filtry), które przesuwają się po siatkach 2D. Istnieją również wersje 1D, a nawet 3D tych warstw: layer_conv_1d(), layer_separable_ conv_1d() i layer_conv_3d(). Warstwa layer_conv_1d() opiera się na oknach 1D, które przesuwają się po sekwencjach wejściowych, natomiast warstwa layer_conv_3d() opiera się na sześciennych oknach, które przesuwają się po woluminach wejściowych.\nW ten sposób można budować sieci konwolucyjne 1D, ściśle analogiczne do sieci 2D. Świetnie nadają się do wszelkich danych sekwencyjnych, które są zgodne z założeniem niezmienności translacji (co oznacza, że jeśli przesuniesz okno po sekwencji, zawartość okna powinna mieć te same właściwości niezależnie od położenia okna).\nWypróbujmy sieć 1D na naszym problemie prognozowania temperatury. Wybierzemy początkową długość okna wynoszącą 24, tak abyśmy patrzyli na 24 godziny danych na raz (jeden cykl). Gdy zmniejszymy próbkowanie sekwencji (poprzez warstwy layer_max_pooling_1d()), odpowiednio zmniejszymy rozmiar okna:\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_conv_1d(8, 24, activation = \"relu\") %&gt;%\n  layer_max_pooling_1d(2) %&gt;%\n  layer_conv_1d(8, 12, activation = \"relu\") %&gt;%\n  layer_max_pooling_1d(2) %&gt;%\n  layer_conv_1d(8, 6, activation = \"relu\") %&gt;%\n  layer_global_average_pooling_1d() %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\nhistory &lt;- model %&gt;% fit(\n  train_dataset,\n  epochs = 10,\n  validation_data = val_dataset\n)\n\nsave_model_tf(model, filepath = \"models/jena_conv1D.keras\")\nsaveRDS(history, file = \"models/jena_conv1D_history.rds\")\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_conv1D.keras\")\nhistory &lt;- readRDS(\"models/jena_conv1D_history.rds\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 6s - loss: 18.9587 - mae: 3.4415 - 6s/epoch - 14ms/step\n\n\n[1] \"Test MAE: 3.44\"\n\nKodplot(history)\n\n\n\n\n\n\n\nJak się okazuje, model ten wypada jeszcze gorzej niż model gęsto połączony, osiągając jedynie testowy MAE na poziomie 3,4 stopnia, daleko od zdroworozsądkowej wartości bazowej. Co poszło nie tak? Dwie rzeczy:\n\nPo pierwsze, dane pogodowe nie do końca spełniają założenie o niezmienności translacji. Chociaż dane te charakteryzują się cyklami dobowymi, dane z poranka mają inne właściwości niż dane z wieczora lub ze środka nocy. Dane pogodowe są translacyjnie niezmienne tylko w bardzo określonej skali czasowej.\nPo drugie, kolejność w naszych danych ma duże znaczenie. Niedawna przeszłość jest znacznie bardziej pouczająca dla przewidywania temperatury następnego dnia niż dane sprzed pięciu dni. Sieć konwekcyjna 1D nie jest w stanie wykorzystać tego faktu. W szczególności nasze warstwy łączenia maksymalnego i średniego globalnego w dużej mierze niszczą informacje o kolejności.\n\n5.1.4 Model LSTM\nAni w pełni połączone podejście, ani podejście konwolucyjne nie poradziły sobie dobrze z zadanie, ale nie oznacza to, że uczenie maszynowe nie ma zastosowania do tego problemu. Sieć gęsto połączona najpierw spłaszczyła szereg czasowy, co usunęło pojęcie czasu z danych wejściowych. Podejście konwolucyjne traktowało każdy segment danych w ten sam sposób, nawet stosując łączenie, które niszczyło informacje o kolejności. Zamiast tego spójrzmy na dane jako na to, czym są - sekwencją, w której liczy się przyczynowość i kolejność. W tym celu użyjemy sieci LSTM.\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_lstm(16) %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\nhistory &lt;- model %&gt;% fit(\n  train_dataset,\n  epochs = 10,\n  validation_data = val_dataset\n)\n\nsave_model_tf(model, filepath = \"models/jena_lstm.keras\")\nsaveRDS(history, file = \"models/jena_lstm_history.rds\")\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_lstm.keras\")\nhistory &lt;- readRDS(\"models/jena_lstm_history.rds\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 5s - loss: 11.2176 - mae: 2.6383 - 5s/epoch - 12ms/step\n\n\n[1] \"Test MAE: 2.64\"\n\nKodplot(history)\n\n\n\n\n\n\n\nDalej nie udało się pokonać modelu bazowego, ale jesteśmy już bardzo blisko. Można się też zastanawiąc dlaczego model LSTM wypadł znacznie lepiej niż model gęsto połączony lub Conv1D? I jak możemy dalej udoskonalać ten model? Aby odpowiedzieć na to pytanie, przyjrzyjmy się bliżej rekurencyjnym sieciom neuronowym.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Rodzaje szeregów czasowych</span>"
    ]
  },
  {
    "objectID": "rnn.html#rnn",
    "href": "rnn.html#rnn",
    "title": "\n5  Rodzaje szeregów czasowych\n",
    "section": "\n6.1 RNN",
    "text": "6.1 RNN\nRekurencyjne sieci neuronowe (ang. Recurrent Neural Network) są bardzo często używanym typem sztucznych sieci neuronowych w rozwiązywaniu zadań, w których wartości pewnych cech są obserwowane w następstwie czasowym. RNN są specjalnym typem sieci, które pozwalają na przechowywanie informacji “na później” w celu wykorzystania ich przewidywaniu przyszłych wartości. W dalszej części tego rozdziału zostaną one szczegółowo omówione. Rozdział ten jednak zaczniemy od przybliżenie z jakimi typami szeregów czasowych możemy mieć do czynienia i w jaki sposób możemy używać do nich sieci rekurencyjnych.\n\nKodmodel &lt;- keras_model_sequential() %&gt;%\n  layer_embedding(input_dim = 10000, output_dim = 32) %&gt;%\n  layer_simple_rnn(units = 32) # retunr only last state\n\nsummary(model)\n\n\nlub\n\nKodmodel &lt;- keras_model_sequential() %&gt;%\n  layer_embedding(input_dim = 10000, output_dim = 32) %&gt;%\n  layer_simple_rnn(units = 32, return_sequences = TRUE) # returns the full state sequence\n\nsummary(model)\n\n\nCzasami przydatne jest ułożenie kilku warstw rekurencyjnych jedna po drugiej w celu zwiększenia mocy reprezentacyjnej sieci. W takiej konfiguracji musisz pamiętać wszystkie warstwy pośrednie, aby zwrócić pełne sekwencje:\n\nKodmodel &lt;- keras_model_sequential() %&gt;%\n  layer_embedding(input_dim = 10000, output_dim = 32) %&gt;%\n  layer_simple_rnn(units = 32, return_sequences = TRUE) %&gt;%\n  layer_simple_rnn(units = 32, return_sequences = TRUE) %&gt;%\n  layer_simple_rnn(units = 32, return_sequences = TRUE) %&gt;%\n  layer_simple_rnn(units = 32)\n\nsummary(model)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Rodzaje szeregów czasowych</span>"
    ]
  },
  {
    "objectID": "rnn.html#lstm-i-gru",
    "href": "rnn.html#lstm-i-gru",
    "title": "\n5  Rodzaje szeregów czasowych\n",
    "section": "\n6.2 LSTM i GRU",
    "text": "6.2 LSTM i GRU\nProste RNN to nie jedyne warstwy rekurencyjne dostępne w keras. Są jeszcze dwie inne: layer_lstm i layer_gru. W praktyce zawsze będziemy używać jednej z nich, ponieważ layer_simple_rnn jest zbyt prosta, aby była naprawdę użyteczna. Jednym z głównych problemów z layer_simple_rnn jest to, że chociaż teoretycznie powinna ona być w stanie zachować w czasie \\(t\\) informacje o wejściach widzianych wiele kroków czasowych wcześniej, w praktyce takie długoterminowe zależności są niemożliwe do nauczenia. Wynika to z problemu znikającego gradientu, efektu podobnego do tego, który obserwuje się w sieciach nierekursywnych (feedforward networks), które mają wiele warstw: w miarę dodawania warstw do sieci, sieć w końcu staje się nie do wytrenowania. Teoretyczne przyczyny tego efektu były badane przez Bengio, Simard, i Frasconi (1994) we wczesnych latach 90-tych. Warstwy LSTM i GRU zostały zaprojektowane w celu rozwiązania tego problemu.\nWeźmy pod uwagę warstwę LSTM. Leżący u podstaw algorytmu Long Short-Term Memory (LSTM) kod został opracowany przez Hochreiter i Schmidhuber (1997) był on zwieńczeniem ich badań nad problemem znikającego gradientu.\nTa warstwa jest wariantem layer_simple_rnn, wzbogaconym o sposób na przenoszenie informacji przez wiele kroków czasowych. Wyobraź sobie taśmę transportową biegnącą równolegle do sekwencji, którą przetwarzasz. Informacja z sekwencji może wskoczyć na taśmę w dowolnym punkcie, zostać przetransportowana do późniejszego kroku czasowego i wyskoczyć z niej, nienaruszona, kiedy jej potrzebujesz. To jest zasadniczo to, co robi LSTM: zapisuje informacje na później, zapobiegając w ten sposób stopniowemu znikaniu starszych sygnałów podczas przetwarzania.\n\n\n\n\n\nRysunek 6.2: Schemat sieci LSTM\n\n\nTypowa jednostka LSTM składa się z komórki (ang. cell), bramki wejściowej (ang. input gate), bramki wyjściowej (ang. output gate) i bramki zapomnienia (ang. forget gate). Komórka zapamiętuje wartości w dowolnych odstępach czasu, a trzy bramki regulują przepływ informacji do i z komórki. Bramki zapominania decydują o tym, jakie informacje z poprzedniego stanu należy odrzucić, przypisując poprzedniemu stanowi, w porównaniu z bieżącym wejściem, wartość z przedziału od 0 do 1. Wartość 1 oznacza zachowanie informacji, a wartość 0 - jej odrzucenie. Bramki wejściowe decydują, które kawałki nowej informacji zapisać w bieżącym stanie, używając tego samego systemu co bramki zapomnienia. Bramki wyjściowe kontrolują, które fragmenty informacji z bieżącego stanu należy wypisać, przypisując im wartość od 0 do 1, biorąc pod uwagę stan poprzedni i bieżący. Selektywne wyprowadzanie odpowiednich informacji z bieżącego stanu pozwala sieci LSTM zachować użyteczne, długoterminowe zależności, pozwalające na dokonywanie przewidywań, zarówno w bieżących, jak i przyszłych krokach czasowych.\nWróćmy do modelu opartego na LSTM, którego używaliśmy w przykładzie przewidywania temperatury. Jeśli spojrzymy na krzywe uczenia, oczywiste jest, że model szybko ulega przeuczeniu (funkcje straty zaczynają się znacznie różnić po kilku epokach), mimo że jest dość prosty. Znamy już klasyczną technikę przeciwdziałania temu zjawisku. Dropout, który losowo zeruje jednostki wejściowe warstwy, aby przerwać przypadkowe korelacje w danych treningowych, na które narażona jest warstwa. Jednak to, jak prawidłowo stosować dropout w sieciach rekurencyjnych, nie jest trywialnym pytaniem.\nSprawdzono, że zastosowanie dropout przed warstwą rekurencyjną raczej utrudnia uczenie się niż pomaga w regularyzacji. W 2016 roku Yarin Gal, w ramach swojej pracy doktorskiej na temat głębokiego uczenia bayesowskiego, określił właściwy sposób stosowania dropoutu w sieci rekurencyjnej: ta sama maska dropoutu (ten sam wzór porzuconych jednostek) powinna być stosowana w każdym kroku czasowym, zamiast stosowania maski dropoutu, która zmienia się losowo z kroku na krok czasowy. Co więcej, aby uregulować reprezentacje utworzone przez rekurencyjne bramki warstw, takich jak layer_gru() i layer_lstm(), do wewnętrznych rekurencyjnych aktywacji warstwy należy zastosować czasowo stałą maskę dropout (rekurencyjną maskę porzucania). Używanie tej samej maski porzucania w każdym kroku czasowym pozwala sieci na prawidłową propagację błędu uczenia się w czasie; czasowo losowa maska porzucania zakłóciłaby ten sygnał błędu i byłaby szkodliwa dla procesu uczenia się.\nYarin Gal przeprowadził swoje badania przy użyciu keras i pomógł zaimplementować ten mechanizm bezpośrednio w warstwach rekurencyjnych keras. Każda warstwa rekurencyjna w keras ma dwa argumenty związane z dropout: dropout, zmienna określająca współczynnik porzucenia dla jednostek wejściowych warstwy, oraz recurrent_dropout, określająca współczynnik porzucenia dla jednostek rekurencyjnych. Dodajmy rekurencyjne porzucanie do funkcji layer_lstm() naszego przykładu LSTM i zobaczmy, jak wpływa to na overfitting.\nDzięki dropoutowi nie będziemy musieli tak bardzo polegać na rozmiarze sieci do regularyzacji, więc użyjemy warstwy LSTM z dwukrotnie większą liczbą jednostek, co powinno, miejmy nadzieję, być bardziej wyraziste (bez dropoutu ta sieć od razu zaczęłaby się przeuczać2). Ponieważ sieci regularyzowane z dropoutem zawsze potrzebują znacznie więcej czasu, aby osiągnąć zbieżność, będziemy trenować model przez pięć razy więcej epok.\n2 możesz sam spróbować\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_lstm(32, recurrent_dropout = 0.25) %&gt;%\n  layer_dropout(0.5) %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\nhistory &lt;- model %&gt;% fit(\n  train_dataset,\n  epochs = 50,\n  validation_data = val_dataset\n)\nsave_model_tf(\"models/jena_lstm_dropout.keras\")\n\n\n\n\n\n\n\n\nZagrożenie\n\n\n\nModele rekurencyjne z bardzo małą liczbą parametrów, takie jak te w tym rozdziale, są zwykle znacznie szybsze na wielordzeniowym CPU niż na GPU, ponieważ obejmują tylko mnożenia małych macierzy, a łańcuch mnożeń nie jest dobrze zrównoleglony ze względu na obecność pętli for. Większe sieci RNN mogą jednak w znacznym stopniu skorzystać z możliwości GPU.\nPodczas korzystania z warstw LSTM i GRU na GPU z domyślnymi argumentami, warstwy będą wykorzystywać jądro cuDNN, wysoce zoptymalizowaną, niskopoziomową implementację algorytmu dostarczoną przez firmę NVIDIA. Niestety, jądra cuDNN są wątpliwym błogosławieństwem: są szybkie, ale nieelastyczne - jeśli spróbujemy zrobić coś, co nie jest obsługiwane przez domyślne jądro, doświadczymy dramatycznego spowolnienia. Przykładowo, rekurencyjny dropout nie jest obsługiwany przez jądra LSTM i GRU cuDNN, więc dodanie go do warstw zmusza algorytm do wykonywania na zwykłej implementacji TensorFlow, która jest generalnie od dwóch do pięciu razy wolniejsza na GPU (mimo że jej koszt obliczeniowy jest taki sam).\nAby przyspieszyć działanie warstwy RNN, gdy nie można użyć cuDNN, można spróbować ją rozwinąć (ang. unfold). Rozwijanie pętli for polega na usunięciu pętli i po prostu wpisaniu jej zawartości N razy. W przypadku pętli for sieci RNN, rozwijanie może pomóc TensorFlow zoptymalizować bazowy graf obliczeniowy. Jednak znacznie zwiększy to również zużycie pamięci przez sieć RNN. W związku z tym jest to opłacalne tylko w przypadku stosunkowo małych sekwencji (około 100 kroków lub mniej). Należy również pamiętać, że można to zrobić tylko wtedy, gdy liczba kroków czasowych w danych jest znana z góry przez model. Działa to w następujący sposób:\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, num_features))\nx &lt;- inputs %&gt;% layer_lstm(32, recurrent_dropout = 0.2, unroll = TRUE)\n\n\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_lstm_dropout.keras\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 273s - loss: 10.2870 - mae: 2.5415 - 273s/epoch - 675ms/step\n\n\n[1] \"Test MAE: 2.54\"\n\n\n\n\n\n\n\nRysunek 6.3\n\n\nRysunek 6.3 przedstawia wyniki uczenia. Usunięto przeuczenie (do co najmniej 20 epoki). Osiągamy MAE walidacji na poziomie zaledwie 2,37 stopnia (2,5% poprawa w stosunku do modelu bazowego bez uczenia) i testowy MAE na poziomie 2,54 stopnia (3% poprawa w stosunku do lini bazowej).\nPonieważ overfitting nie jest już tak wyraźnym problemem, ale wydaje się, że trafiliśmy na wąskie gardło wydajności, powinniśmy rozważyć zwiększenie pojemności i mocy obliczeniowej sieci. Przypomnijmy sobie opis uniwersalnego przepływu pracy uczenia maszynowego: generalnie dobrym pomysłem jest zwiększenie pojemności modelu, dopóki overfitting nie stanie się głównym problemem.\nZwiększenie pojemności sieci odbywa się zazwyczaj poprzez zwiększenie liczby neuronów w warstwach lub dodanie większej liczby warstw. Składanie warstw rekurencyjnych to klasyczny sposób budowania potężniejszych sieci rekurencyjnych. Aby układać warstwy rekurencyjne jedna na drugiej w Kerasie, wszystkie warstwy pośrednie powinny zwracać pełną sekwencję swoich wyjść (tensor rangi 3), a nie swoje wyjście w ostatnim kroku czasowym. Jak już się dowiedzieliśmy, odbywa się to poprzez ustawienie flagi return_ sequences = TRUE.\nW poniższym przykładzie wypróbujemy stos dwóch warstw rekurencyjnych z regularyzacją dropout. Dla odmiany użyjemy warstw Gated Recurrent Unit (GRU) zamiast LSTM. GRU jest bardzo podobny do LSTM - można o nim myśleć jako o nieco prostszej, usprawnionej wersji architektury LSTM. Została ona wprowadzona w 2014 roku przez Cho i in. (b.d.), gdy sieci rekurencyjne dopiero zaczynały na nowo zyskiwać zainteresowanie w niewielkiej wówczas społeczności badawczej.\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_gru(32, recurrent_dropout = 0.5, return_sequences = TRUE) %&gt;%\n  layer_gru(32, recurrent_dropout = 0.5) %&gt;%\n  layer_dropout(0.5) %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\nhistory &lt;- model %&gt;% fit(\n  train_dataset,\n  epochs = 50,\n  validation_data = val_dataset\n)\nsave_model_tf(\"models/jena_gru_dropout.keras\")\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_gru_dropout.keras\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 577s - loss: 9.6074 - mae: 2.4491 - 577s/epoch - 1s/step\n\n\n[1] \"Test MAE: 2.45\"\n\n\n\n\n\n\n\nRysunek 6.4\n\n\n?fig-gru-dropout przedstawia wyniki uczenia. Osiągnęliśmy testowy MAE na poziomie 2,45 stopnia (poprawa o 6,5% w stosunku do linii bazowej). Widać, że dodana warstwa nieco poprawia wyniki, choć nie dramatycznie, zatem można zaobserwować malejące zyski ze zwiększania pojemności sieci.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Rodzaje szeregów czasowych</span>"
    ]
  },
  {
    "objectID": "rnn.html#dwukierunkowe-sieci-rekurencyjne",
    "href": "rnn.html#dwukierunkowe-sieci-rekurencyjne",
    "title": "\n5  Rodzaje szeregów czasowych\n",
    "section": "\n6.3 Dwukierunkowe sieci rekurencyjne",
    "text": "6.3 Dwukierunkowe sieci rekurencyjne\nOstatnią techniką, której przyjrzymy się w tej sekcji, jest dwukierunkowa sieć RNN. Dwukierunkowy RNN jest powszechnym wariantem RNN, który może oferować większą wydajność niż zwykły RNN w niektórych zadaniach. Jest często używany w przetwarzaniu języka naturalnego - można go nazwać szwajcarskim scyzorykiem głębokiego uczenia się do przetwarzania języka naturalnego.\nRNN są w szczególności zależne od kolejności: przetwarzają kroki czasowe swoich sekwencji wejściowych w kolejności, a tasowanie lub odwracanie kroków czasowych może całkowicie zmienić reprezentacje, które RNN wyodrębnia z sekwencji. To jest właśnie powód, dla którego dobrze radzą sobie z problemami, w których kolejność ma znaczenie, takimi jak problem prognozowania temperatury. Dwukierunkowa RNN wykorzystuje wrażliwość RNN na kolejność: wykorzystuje dwie zwykłe RNN, takie jak GRU i LSTM, z których każda przetwarza sekwencję wejściową w jednym kierunku (chronologicznie i antychronologicznie), a następnie łączy ich reprezentacje. Przetwarzając sekwencję w obie strony, dwukierunkowa sieć RNN może wychwycić wzorce, które mogą zostać przeoczone przez jednokierunkową sieć RNN.\nCzy RNN mogłyby działać wystarczająco dobrze, gdyby na przykład przetwarzały sekwencje wejściowe w porządku antychronologicznym (z nowszymi krokami czasowymi jako pierwszymi)? Spróbujmy tego i zobaczmy, co się stanie. Wszystko, co musimy zrobić, to zmodyfikować zestaw danych TF, aby sekwencje wejściowe zostały odwrócone wzdłuż wymiaru czasu. Wystarczy przekształcić zbiór danych za pomocą funkcji dataset_map() w następujący sposób:\n\nKoddataset_map(function(samples, targets) {\n  list(samples[, NA:NA:-1, ], targets)\n})\n\n\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  layer_lstm(16) %&gt;%\n  layer_dense(1)\nmodel &lt;- keras_model(inputs, outputs)\n\ncallbacks &lt;- list(callback_model_checkpoint(\"jena_lstm_reversed\",\n                                            save_best_only = TRUE))\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\ndataset_reverse_time &lt;- function(ds) {\n  dataset_map(ds, function(samples, targets)\n    list(samples[, NA:NA:-1, ], targets))\n}\nhistory &lt;- model %&gt;% fit(\n  train_dataset %&gt;% dataset_reverse_time(),\n  epochs = 10,\n  validation_data = val_dataset %&gt;% dataset_reverse_time(),\n  callbacks = callbacks\n)\nsave_model_tf(model, \"models/jena_lstm_rev.keras\")\nsaveRDS(history, \"models/jena_lstm_rev_hist.rds\")\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_lstm_rev.keras\")\nhistory &lt;- readRDS(\"models/jena_lstm_rev_hist.rds\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 5s - loss: 22.8799 - mae: 3.8075 - 5s/epoch - 12ms/step\n\n\n[1] \"Test MAE: 3.81\"\n\nKodplot(history)\n\n\n\n\n\n\n\nLSTM z odwróconym czasem silnie ustępuje nawet zdroworozsądkowemu poziomowi bazowemu, wskazując, że w tym przypadku przetwarzanie chronologiczne jest ważne dla powodzenia tego podejścia. Ma to sens: warstwa LSTM zazwyczaj lepiej zapamiętuje niedawną przeszłość niż odległą przeszłość, a naturalnie bardziej aktualne dane pogodowe niosą w sobie więcej informacji niż starsze dane (to właśnie sprawia, że zdroworozsądkowa linia bazowa jest dość silna). Tak więc chronologiczna wersja sieci z pewnością przewyższy wersję z odwróconym porządkiem.\nNie jest to jednak prawdą w przypadku wielu innych problemów, w tym języka naturalnego: intuicyjnie, znaczenie słowa w zrozumieniu zdania zwykle nie zależy od jego pozycji w zdaniu. W przypadku danych tekstowych, przetwarzanie w odwróconej kolejności działa równie dobrze jak przetwarzanie chronologiczne - można czytać tekst od tyłu. Chociaż kolejność słów ma znaczenie dla zrozumienia języka, to kolejność, której używamy, nie jest kluczowa. Co ważne, RNN wytrenowana na odwróconych sekwencjach nauczy się innych reprezentacji niż ta wytrenowana na oryginalnych sekwencjach, podobnie jak w prawdziwym świecie mielibyśmy inne modele mentalne, gdyby czas płynął wstecz - gdybyśmy żyli życiem, w którym umieramy pierwszego dnia i rodzimy się ostatniego. W uczeniu maszynowym reprezentacje, które są użyteczne, są zawsze warte wykorzystania, a im bardziej się różnią, tym lepiej, bo oferują nowy kąt, z którego można spojrzeć na dane, wychwytując aspekty danych, które zostały pominięte przez inne podejścia, a tym samym mogą pomóc zwiększyć wydajność zadania.\nDwukierunkowa sieć RNN wykorzystuje ten pomysł, aby poprawić wydajność sieci RNN z porządkiem chronologicznym. Analizuje sekwencję wejściową w obie strony (patrz Rysunek 6.5), uzyskując potencjalnie bogatsze reprezentacje i wychwytując wzorce, które mogły zostać pominięte przez samą wersję chronologiczną.\n\n\n\n\n\nRysunek 6.5: Zasada działania warstw dwukierunkowych\n\n\nAby utworzyć instancję dwukierunkowej RNN w Keras, należy użyć warstw bidirectional(), które jako pierwszy argument przyjmują instancję warstwy rekurencyjnej. bidirectional() tworzy drugą, oddzielną instancję tej warstwy rekurencyjnej i wykorzystuje jedną instancję do przetwarzania sekwencji wejściowych w porządku chronologicznym, a drugą instancję do przetwarzania sekwencji wejściowych w porządku odwróconym.\n\nKodinputs &lt;- layer_input(shape = c(sequence_length, ncol_input_data))\noutputs &lt;- inputs %&gt;%\n  bidirectional(layer_lstm(units = 16)) %&gt;%\n  layer_dense(1)\n\nmodel &lt;- keras_model(inputs, outputs)\n\nmodel %&gt;% compile(optimizer = \"rmsprop\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\nhistory &lt;- model %&gt;%\n  fit(train_dataset,\n      epochs = 10,\n      validation_data = val_dataset)\n\nsave_model_tf(model, \"models/jena_lstm_bi.keras\")\nsaveRDS(history, \"models/jena_lstm_bi_hist.rds\")\n\n\n\nKodmodel &lt;- load_model_tf(\"models/jena_lstm_bi.keras\")\nhistory &lt;- readRDS(\"models/jena_lstm_bi_hist.rds\")\nsprintf(\"Test MAE: %.2f\", evaluate(model, test_dataset)[\"mae\"])\n\n405/405 - 8s - loss: 10.8280 - mae: 2.5962 - 8s/epoch - 21ms/step\n\n\n[1] \"Test MAE: 2.60\"\n\nKodplot(history)\n\n\n\n\n\n\n\nJeśli porównamy wyniki do zwykłej layer_lstm(), to zauważymy tylko nieznaczną poprawę wyników. Łatwo jest zrozumieć, dlaczego - niemal cała zdolność predykcyjna musi pochodzić z chronologicznej połowy sieci, ponieważ wiadomo, że antychronologiczna połowa ma znacznie gorsze wyniki w tym zadaniu (ponownie, ponieważ niedawna przeszłość ma w tym przypadku znacznie większe znaczenie niż odległa przeszłość). Jednocześnie obecność antychronologicznej połowy podwaja pojemność sieci i powoduje, że zaczyna się ona przeuczać znacznie wcześniej.\nJednak dwukierunkowe sieci RNN doskonale nadają się do danych tekstowych lub innych rodzajów danych, w których kolejność ma znaczenie, ale gdzie kolejność, której używasz, nie ma znaczenia. W rzeczywistości aż do roku 2016 dwukierunkowe LSTM były uważane za najnowocześniejsze w wielu zadaniach przetwarzania języka naturalnego (przed pojawieniem się architektury Transformer, o której będzie nieco później).\nIstnieje wiele innych rzeczy, które można wypróbować w celu poprawy wydajności prognozowania temperatury:\n\nDostosować liczbę neuronów w każdej warstwie rekurencyjnej, a także ilość porzuconych neurnonów. Obecne wybory są w dużej mierze arbitralne, a zatem prawdopodobnie nieoptymalne.\nDostosować szybkość uczenia optymalizatora RMSprop lub wypróbować inny optymalizator.\nUżyć stosu kilku warstw gęstych layer_dense() jako regresora na wierzchu warstwy rekurencyjnej, zamiast pojedynczej.\nUlepszyć dane wejściowe do modelu - użyć dłuższych lub krótszych sekwencji lub innej częstotliwości próbkowania lub wykonać inżynierię cech.\n\n\n\n\n\n\n\nWskazówka\n\n\n\nGłębokie uczenie jest bardziej sztuką niż nauką. Możemy dostarczać wskazówek, które sugerują, co może działać lub nie działać w danym problemie, ale ostatecznie każdy zbiór danych jest wyjątkowy; będziesz musiał empirycznie ocenić różne strategie. Obecnie nie istnieje żadna teoria, która z góry powiedziałaby, co powinniśmy zrobić, aby optymalnie rozwiązać dany problem.\n\n\n\n\n\n\n\n\nOstrzeżenie\n\n\n\nNiektórzy czytelnicy z pewnością będą chcieli skorzystać z technik, które tu przedstawiliśmy i wypróbować je w problemie prognozowania przyszłych cen papierów wartościowych na giełdzie (lub kursów wymiany walut itp.). Rynki mają jednak zupełnie inną charakterystykę statystyczną niż zjawiska naturalne, takie jak wzorce pogodowe. Jeśli chodzi o rynki, przeszłe wyniki nie są dobrym predyktorem przyszłych zwrotów3. Z drugiej strony uczenie maszynowe ma zastosowanie do zbiorów danych, w których przeszłość jest dobrym predyktorem przyszłości, takich jak pogoda, zużycie energii elektrycznej lub ruch pieszych na danym odcinku drogi.\nZawsze pamiętajmy, że cały handel papierami wartościowymi jest zasadniczo arbitrażem informacyjnym: zdobywaniem przewagi poprzez wykorzystanie danych lub spostrzeżeń, których brakuje innym uczestnikom rynku. Próba wykorzystania dobrze znanych technik uczenia maszynowego i publicznie dostępnych danych w celu pokonania rynków jest w rzeczywistości ślepym zaułkiem, ponieważ nie będzie dawać żadnej przewagi informacyjnej w porównaniu do wszystkich innych.\n\n\n\n\n3 patrzenie w lusterko wsteczne nie jest najlepszą metodą prowadzenia auta 🙉 🤔\n\nBengio, Y., P. Simard, i P. Frasconi. 1994. „Learning long-term dependencies with gradient descent is difficult”. IEEE Transactions on Neural Networks 5 (2): 157–66. https://doi.org/10.1109/72.279181.\n\n\nCho, Kyunghyun, Bart van Merrienboer, Dzmitry Bahdanau, i Yoshua Bengio. b.d. „On the Properties of Neural Machine Translation: Encoder-Decoder Approaches”. https://doi.org/10.48550/arXiv.1409.1259.\n\n\nHochreiter, Sepp, i Jürgen Schmidhuber. 1997. „Long Short-Term Memory”. Neural Computation 9 (8): 1735–80. https://doi.org/10.1162/neco.1997.9.8.1735.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Rodzaje szeregów czasowych</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatura",
    "section": "",
    "text": "Bengio, Y., P. Simard, and P. Frasconi. 1994. “Learning Long-Term\nDependencies with Gradient Descent Is Difficult.” IEEE\nTransactions on Neural Networks 5 (2): 157–66. https://doi.org/10.1109/72.279181.\n\n\nBorchani, Hanen, Gherardo Varando, Concha Bielza, and Pedro Larrañaga.\n2015. “A Survey on Multi-Output Regression.” WIREs Data\nMining and Knowledge Discovery 5 (5): 216–33. https://doi.org/10.1002/widm.1157.\n\n\nBreiman, Leo, J. H. Friedman, Richard A. Olshen, and Charles J. Stone.\n2017. Classification and Regression Trees. Routledge. http://search.ebscohost.com/login.aspx?direct=true&db=edsebk&AN=1619230&lang=pl&site=eds-live&scope=site.\n\n\nCho, Kyunghyun, Bart van Merrienboer, Dzmitry Bahdanau, and Yoshua\nBengio. n.d. “On the Properties of Neural Machine Translation:\nEncoder-Decoder Approaches.” https://doi.org/10.48550/arXiv.1409.1259.\n\n\nEvgeniou, Theodoros, and Massimiliano Pontil. 2004. “Regularized\nMulti–Task Learning.” Proceedings of the Tenth ACM SIGKDD\nInternational Conference on Knowledge Discovery and Data Mining,\nAugust. https://doi.org/10.1145/1014052.1014067.\n\n\nFaddoul, Jean Baptiste, Boris Chidlovskii, Rémi Gilleron, and Fabien\nTorre. 2012. “Learning Multiple Tasks with Boosted Decision\nTrees.” In Proceedings of the 2012th European Conference on\nMachine Learning and Knowledge Discovery in Databases - Volume Part\ni, 681–96. ECMLPKDD’12. Springer-Verlag.\n\n\nFaddoul, Jean Baptiste, Boris Chidlovskii, Fabien Torre, and Remi\nGilleron. 2010. “Boosting Multi-Task Weak Learners with\nApplications to Textual and Social Data.” In 2010 Ninth\nInternational Conference on Machine Learning and Applications,\n367–72. IEEE. https://doi.org/10.1109/ICMLA.2010.61.\n\n\nGlocker, Ben, Olivier Pauly, Ender Konukoglu, and Antonio Criminisi.\n2012. “Joint Classification-Regression Forests for Spatially\nStructured Multi-Object Segmentation.” In Computer Vision –\nECCV 2012, edited by Andrew Fitzgibbon, Svetlana Lazebnik, Pietro\nPerona, Yoichi Sato, and Cordelia Schmid, 7575:870–81. Springer Berlin\nHeidelberg. http://link.springer.com/10.1007/978-3-642-33765-9_62.\n\n\nHochreiter, Sepp, and Jürgen Schmidhuber. 1997. “Long\nShort-Term Memory.” Neural Computation 9\n(8): 1735–80. https://doi.org/10.1162/neco.1997.9.8.1735.\n\n\nIzenman, Alan Julian. 1975. “Reduced-Rank Regression for the\nMultivariate Linear Model.” Journal of Multivariate\nAnalysis 5 (2): 248–64.\n\n\nKocev, Dragi, Celine Vens, Jan Struyf, and Sašo Džeroski. 2013.\n“Tree Ensembles for Predicting Structured Outputs.”\nPattern Recognition 46 (3): 817–33. https://doi.org/10.1016/j.patcog.2012.09.023.\n\n\nMelki, Gabriella, Alberto Cano, Vojislav Kecman, and Sebastián Ventura.\n2017. “Multi-Target Support Vector Regression via Correlation\nRegressor Chains.” Information Sciences 415–416\n(November): 53–69. https://doi.org/10.1016/j.ins.2017.06.017.\n\n\nQuinlan, J Ross. 1993. C4. 5: Programs for Machine Learning.\nMorgan Kaufmann.\n\n\nSantana, Everton Jose, Felipe Rodrigues dos Santos, Saulo Martiello\nMastelini, Fabio Luiz Melquiades, and Sylvio Barbon Jr. 2020.\n“Improved Prediction of Soil Properties with Multi-Target Stacked\nGeneralisation on EDXRF Spectra.” arXiv Preprint\narXiv:2002.04312. https://arxiv.org/abs/2002.04312.\n\n\nSegal, Mark Robert. 1992. “Tree-Structured Methods for\nLongitudinal Data.” Journal of the American Statistical\nAssociation 87 (418): 407–18. https://doi.org/10.2307/2290271.\n\n\nSpyromitros-Xioufis, Eleftherios, Grigorios Tsoumakas, William Groves,\nand Ioannis Vlahavas. 2016. “Multi-Target Regression\nvia Input Space Expansion: Treating Targets as\nInputs.” Machine Learning 104 (1): 55–98.\nhttps://doi.org/10.1007/s10994-016-5546-z.\n\n\nStruyf, Jan, and Sašo Džeroski. 2006. “Constraint Based Induction\nof Multi-Objective Regression Trees.” In Knowledge Discovery\nin Inductive Databases, edited by Francesco Bonchi and\nJean-François Boulicaut, 222–33. Lecture Notes in Computer Science.\nSpringer. https://doi.org/10.1007/11733492_13.\n\n\nTawiah, Clifford, and Victor Sheng. 2013. “Empirical Comparison of\nMulti-Label Classification Algorithms.” In Proceedings of the\nAAAI Conference on Artificial\nIntelligence, 27:1645–46.\n\n\nTsoumakas, Grigorios, and Ioannis Katakis. 2007. “Multi-Label\nClassification: An Overview.” International\nJournal of Data Warehousing and Mining (IJDWM) 3 (3): 1–13.\n\n\nVazquez, Emmanuel, and Eric Walter. 2003. “Multi-Output Suppport\nVector Regression.” IFAC Proceedings Volumes, 13th IFAC\nsymposium on system identification (SYSID 2003), rotterdam, the\nnetherlands, 27-29 august, 2003, 36 (16): 1783–88. https://doi.org/10.1016/S1474-6670(17)35018-8.\n\n\nXu, Yitian, Rui Guo, and Laisheng Wang. 2013. “A Twin Multi-Class\nClassification Support Vector Machine.” Cognitive\nComputation 5 (4): 580–88. https://doi.org/10.1007/s12559-012-9179-7.\n\n\nZhang, Zhendong, and Cheolkon Jung. n.d. “GBDT-MO: Gradient\nBoosted Decision Trees for Multiple Outputs.” https://doi.org/10.48550/arXiv.1909.04373.",
    "crumbs": [
      "Literatura"
    ]
  }
]