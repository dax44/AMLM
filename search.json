[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zaawansowane metody uczenia maszynowego",
    "section": "",
    "text": "WstÄ™p\nKsiÄ…Å¼ka ta jest napisana na potrzeby prowadzenia zajÄ™Ä‡ na kierunku InÅ¼ynieria i analiza danych z przedmiotu Zaawansowane metody uczenia maszynowego. Jest swego rodzaju autorskim podejÅ›ciem do tematu, przedstawiajÄ…cym wybrane metody uczenia maszynowego, ktÃ³re rzadziej wystÄ™pujÄ… w opracowaniach na temat uczenia maszynowego.\nUczenie maszynowe stanowi obszar intensywnego rozwoju, ktÃ³ry obejmuje szereg technik umoÅ¼liwiajÄ…cych bardziej skomplikowane i wydajne modele predykcyjne. WÅ›rÃ³d tych metod warto wyrÃ³Å¼niÄ‡ gÅ‚Ä™bokie sieci neuronowe, zwÅ‚aszcza konwolucyjne sieci neuronowe (CNN) i rekurencyjne sieci neuronowe (RNN). CNN sÄ… wykorzystywane w zadaniach przetwarzania obrazÃ³w, gdzie potrafiÄ… efektywnie ekstrahowaÄ‡ hierarchiczne cechy z danych wejÅ›ciowych, natomiast RNN sÄ… efektywne w analizie sekwencji danych, takich jak jÄ™zyk naturalny. Ponadto, metody uczenia maszynowego obejmujÄ… techniki transferu wiedzy, uczenie ze wzmocnieniem, generatywne modele, takie jak generatywne sieci przeciwdziedzinowe (GAN), czy teÅ¼ autokodery. Te nowoczesne podejÅ›cia umoÅ¼liwiajÄ… modelom uczÄ…cym siÄ™ wykonywanie bardziej zÅ‚oÅ¼onych zadaÅ„, a takÅ¼e adaptacjÄ™ do rÃ³Å¼norodnych danych wejÅ›ciowych, co sprawia, Å¼e sÄ… one stosowane w obszarach takich jak rozpoznawanie obrazÃ³w, przetwarzanie jÄ™zyka naturalnego, czy nawet w autonomicznych systemach decyzyjnych.\nPonadto, zaawansowane metody uczenia maszynowego obejmujÄ… takÅ¼e techniki regularyzacji, optymalizacji i inÅ¼ynieriÄ™ cech. Regularyzacja ma na celu zapobieganie przeuczeniu poprzez kontrolowanie zÅ‚oÅ¼onoÅ›ci modelu, natomiast optymalizacja skupia siÄ™ na dostosowywaniu wag modelu w celu minimalizacji funkcji straty. InÅ¼ynieria cech polega na rÄ™cznym lub automatycznym dostosowywaniu danych wejÅ›ciowych w celu uzyskania lepszych wynikÃ³w modelu. DziÄ™ki tym zaawansowanym metodom, uczenie maszynowe staje siÄ™ coraz bardziej potÄ™Å¼nym narzÄ™dziem w analizie danych i podejmowaniu skomplikowanych decyzji w rÃ³Å¼nych dziedzinach.\nModele predykcyjne dla wielu wyjÅ›Ä‡, czyli tzw. multi-target regression and classification, stanowiÄ… kolejny istotny obszar w dziedzinie uczenia maszynowego. W przypadku multi-target regression, celem jest przewidywanie wielu wartoÅ›ci wyjÅ›ciowych dla danego zestawu wejÅ›ciowego, co czÄ™sto spotyka siÄ™ w zÅ‚oÅ¼onych problemach predykcyjnych, takich jak prognozowanie wielu parametrÃ³w jednoczeÅ›nie. Z kolei w przypadku multi-target classification, model ma za zadanie przypisanie jednego lub wiÄ™cej klas dla kaÅ¼dego przykÅ‚adu wejÅ›ciowego. Te modele sÄ… powszechnie stosowane w rÃ³Å¼nych dziedzinach, takich jak bioinformatyka, finanse czy przemysÅ‚, gdzie jednoczesne przewidywanie wielu zmiennych jest kluczowe dla skutecznego rozwiÄ…zania problemu. WdroÅ¼enie takich zaawansowanych modeli predykcyjnych wymaga starannej obrÃ³bki danych, odpowiedniego dostosowania architektury modelu oraz precyzyjnej oceny wynikÃ³w, co sprawia, Å¼e sÄ… one istotnym narzÄ™dziem w obszarze analizy danych i podejmowania decyzji.\nModele jÄ™zykowe stanowiÄ… jeszcze jeden kluczowy obszar w dziedzinie uczenia maszynowego, skoncentrowany na zrozumieniu i generowaniu ludzkiego jÄ™zyka naturalnego. GÅ‚Ä™bokie sieci neuronowe, zwÅ‚aszcza rekurencyjne sieci neuronowe (RNN) i transformery, zostaÅ‚y skutecznie wykorzystane do tworzenia modeli jÄ™zykowych o zdolnoÅ›ciach przetwarzania i generowania tekstu na poziomie zbliÅ¼onym do ludzkiego. Te modele zdolne sÄ… do zrozumienia kontekstu, analizy gramatyki, a takÅ¼e generowania spÃ³jnych i sensownych odpowiedzi. Wykorzystywane sÄ… w rÃ³Å¼norodnych zastosowaniach, takich jak tÅ‚umaczenie maszynowe, generowanie tekstu, czy analiza nastroju w tekÅ›cie. Ponadto, pre-trenowane modele jÄ™zykowe, takie jak BERT czy GPT (Generative Pre-trained Transformer), zdobywajÄ… popularnoÅ›Ä‡, umoÅ¼liwiajÄ…c dostosowanie ich do rÃ³Å¼nych zadaÅ„ poprzez fine-tuning. W miarÄ™ postÄ™pu badaÅ„ i rozwoju w tej dziedzinie, modele jÄ™zykowe stajÄ… siÄ™ coraz bardziej zaawansowane, co przyczynia siÄ™ do doskonalenia komunikacji miÄ™dzy maszynami a ludÅºmi oraz do rozwijania nowych moÅ¼liwoÅ›ci w dziedzinie przetwarzania jÄ™zyka naturalnego.\nWspomniane powyÅ¼ej metody i modele bÄ™dÄ… stanowiÄ‡ treÅ›Ä‡ wykÅ‚adÃ³w z wspomnianego na wstÄ™pie przedmiotu.",
    "crumbs": [
      "WstÄ™p"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1Â  Wprowadzenie",
    "section": "",
    "text": "Witam w Å›wiecie zaawansowanych metod uczenia maszynowego ğŸ¤–, prezentowanej w niniejszej publikacji. KsiÄ…Å¼ka ta skupia siÄ™ na trzech gÅ‚Ã³wnych obszarach, zaczynajÄ…c od wielowymiarowych problemÃ³w predykcyjnych, przechodzÄ…c przez kompleksowe modele gÅ‚Ä™bokich sieci neuronowych, a koÅ„czÄ…c na zaawansowanych modelach jÄ™zykowych. Koncepcyjnie rozpoczniemy od omÃ³wienia multiple target regression and classification, gdzie przedstawimy skomplikowane zadania predykcyjne wymagajÄ…ce jednoczesnej prognozy wielu zmiennych. Przeanalizujemy praktyczne zastosowania tych modeli w obszarach, takich jak nauki spoÅ‚eczne, biologia i finanse.\nNastÄ™pnie poÅ›wiÄ™cimy uwagÄ™ gÅ‚Ä™bokim sieciom neuronowym, gÅ‚Ã³wnemu filarowi nowoczesnej sztucznej inteligencji. OmÃ³wimy ewolucjÄ™ od konwolucyjnych sieci neuronowych (CNN) do rekurencyjnych sieci neuronowych (RNN), zwracajÄ…c uwagÄ™ na ich zdolnoÅ›Ä‡ do efektywnego przetwarzania obrazÃ³w, sekwencji danych i rozwiÄ…zania bardziej zÅ‚oÅ¼onych problemÃ³w. W ramach tego obszaru, przyjrzymy siÄ™ rÃ³wnieÅ¼ technikom transferu wiedzy, uczenia ze wzmocnieniem oraz generatywnym modelom, takim jak generatywne sieci przeciwdziedzinowe (GAN), ktÃ³re poszerzajÄ… granice moÅ¼liwoÅ›ci maszynowego uczenia siÄ™.\n\n\n\nTrzeci kluczowy obszar, ktÃ³ry bÄ™dzie przedmiotem analizy, to modele jÄ™zykowe. RozwaÅ¼ania rozpoczniemy od gÅ‚Ä™bokich sieci neuronowych, a nastÄ™pnie skoncentrujemy siÄ™ na transformatorach, ktÃ³re rewolucjonizujÄ… przetwarzanie jÄ™zyka naturalnego ğŸ‘…. Przedstawimy praktyczne zastosowania tych modeli, zwÅ‚aszcza w tÅ‚umaczeniu maszynowym, generowaniu tekstu i analizie sentymentu. Ponadto, omÃ³wimy pre-trenowane modele jÄ™zykowe, takie jak BERT czy GPT, jako kluczowe narzÄ™dzia adaptacyjne, zdolne do fine-tuningu w zaleÅ¼noÅ›ci od konkretnego zadania.\nKaÅ¼dy podejmowany temat bÄ™dzie wzbogacony o implementacjÄ™ analizowanych metod w realnych scenariuszach. OmÃ³wimy kroki od obrÃ³bki danych, przez dostosowywanie architektury modelu, aÅ¼ po ocenÄ™ wynikÃ³w. W tym kontekÅ›cie poruszymy takÅ¼e aspekty etyczne i wyzwania zwiÄ…zane z zastosowaniem zaawansowanych modeli uczenia maszynowego.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Wprowadzenie</span>"
    ]
  },
  {
    "objectID": "multi_target_models.html",
    "href": "multi_target_models.html",
    "title": "2Â  Modele z wieloma wyjÅ›ciami",
    "section": "",
    "text": "2.1 Typy modeli z wieloma zmiennymi wynikowymi\nWÅ›rÃ³d nadzorowanych modeli uczenia maszynowego z wieloma zmiennymi wynikowymi moÅ¼na wymieniÄ‡ zarÃ³wno te dedykowane do klasyfikacji, jak i regresji. Modele te sÄ… znane jako modele z wieloma wyjÅ›ciami (klasyfikacyjne) lub modele z wieloma wyjÅ›ciami (regresyjne), w zaleÅ¼noÅ›ci od rodzaju problemu, ktÃ³ry rozwiÄ…zujÄ….",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Modele z wieloma wyjÅ›ciami</span>"
    ]
  },
  {
    "objectID": "multi_target_models.html#typy-modeli-z-wieloma-zmiennymi-wynikowymi",
    "href": "multi_target_models.html#typy-modeli-z-wieloma-zmiennymi-wynikowymi",
    "title": "2Â  Modele z wieloma wyjÅ›ciami",
    "section": "",
    "text": "Modele z wieloma wyjÅ›ciami (klasyfikacyjne)\nW przypadku klasyfikacji, gdy mamy wiele kategorii (klas) jako zmiennÄ… wynikowÄ…, modele te sÄ… nazywane modelami z wieloma wyjÅ›ciami. PrzykÅ‚ady obejmujÄ… algorytmy takie jak regresja logistyczna, metoda k najbliÅ¼szych sÄ…siadÃ³w (k-NN) czy algorytmy drzew decyzyjnych, ktÃ³re zostaÅ‚y dostosowane do obsÅ‚ugi wielu klas.\nPrzykÅ‚adowe zadanie: ZaÅ‚Ã³Å¼my, Å¼e mamy zbiÃ³r danych dotyczÄ…cy rÃ³Å¼nych rodzajÃ³w owocÃ³w (np. jabÅ‚ek, pomaraÅ„czy, bananÃ³w) i chcemy stworzyÄ‡ model, ktÃ³ry jednoczeÅ›nie przewiduje gatunek owocu oraz kolor owocu. Mamy wiÄ™c dwie zmienne wynikowe: gatunek (klasyfikacja wieloklasowa) i kolor (klasyfikacja wieloklasowa).\nModele z wieloma wyjÅ›ciami (regresyjne).\nW przypadku regresji, gdzie zmiennÄ… wynikowÄ… jest wektor wartoÅ›ci numerycznych, modele te sÄ… nazywane modelami z wieloma wyjÅ›ciami. PrzykÅ‚ady obejmujÄ… algorytmy regresji liniowej lub nieliniowej, algorytmy oparte na drzewach decyzyjnych, czy teÅ¼ bardziej zaawansowane modele, takie jak sieci neuronowe.\nPrzykÅ‚adowe zadanie: ZakÅ‚adamy, Å¼e mamy zbiÃ³r danych zawierajÄ…cy informacje o pracownikach, takie jak doÅ›wiadczenie zawodowe, poziom wyksztaÅ‚cenia, liczba godzin pracy tygodniowo itp. Chcemy stworzyÄ‡ model, ktÃ³ry jednoczeÅ›nie przewiduje zarobki pracownikÃ³w oraz ich poziom satysfakcji zawodowej.\nModele wielozadaniowe.\nModele wielozadaniowe to rodzaj nadzorowanego uczenia maszynowego, w ktÃ³rym model jest trenowany jednoczeÅ›nie do rozwiÄ…zania kilku zadaÅ„. Te zadania mogÄ… obejmowaÄ‡ zarÃ³wno klasyfikacjÄ™, jak i regresjÄ™. DziÄ™ki wspÃ³lnemu trenowaniu modelu na wielu zadaniach, moÅ¼na uzyskaÄ‡ korzyÅ›ci w postaci wspÃ³lnego wykorzystywania wiedzy miÄ™dzy zadaniami.\nPrzykÅ‚adowe zadanie: ZaÅ‚Ã³Å¼my, Å¼e mamy zbiÃ³r danych dotyczÄ…cy zakupÃ³w klientÃ³w w sklepie internetowym. Dla kaÅ¼dego klienta mamy informacje o rÃ³Å¼nych aspektach zakupÃ³w, takich jak czas dostawy, Å‚atwoÅ›Ä‡ obsÅ‚ugi strony, jakoÅ›Ä‡ produktÃ³w itp. Chcemy stworzyÄ‡ model, ktÃ³ry jednoczeÅ›nie przewiduje dwie zmienne wynikowe: jakoÅ›Ä‡ obsÅ‚ugi klienta (skala jakoÅ›ciowa, np. â€œNiskaâ€, â€œÅšredniaâ€, â€œWysokaâ€) oraz caÅ‚kowity wydatek klienta (zmienna iloÅ›ciowa, np. kwota zakupÃ³w).\nModele hierarchiczne.\nW niektÃ³rych przypadkach, szczegÃ³lnie gdy mamy hierarchiÄ™ zmiennych wynikowych, modele te mogÄ… byÄ‡ budowane w sposÃ³b hierarchiczny. PrzykÅ‚adowo, w problemie klasyfikacji obrazÃ³w z hierarchiÄ… kategorii (na przykÅ‚ad rozpoznawanie gatunkÃ³w zwierzÄ…t), model moÅ¼e byÄ‡ zaprojektowany do rozpoznawania zarÃ³wno ogÃ³lnych, jak i bardziej szczegÃ³Å‚owych kategorii.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Modele z wieloma wyjÅ›ciami</span>"
    ]
  },
  {
    "objectID": "multi_target_models.html#rÃ³Å¼nie-podejÅ›cia-do-modelowania-z-wieloma-wyjÅ›ciami",
    "href": "multi_target_models.html#rÃ³Å¼nie-podejÅ›cia-do-modelowania-z-wieloma-wyjÅ›ciami",
    "title": "2Â  Modele z wieloma wyjÅ›ciami",
    "section": "2.2 RÃ³Å¼nie podejÅ›cia do modelowania z wieloma wyjÅ›ciami",
    "text": "2.2 RÃ³Å¼nie podejÅ›cia do modelowania z wieloma wyjÅ›ciami\nIstniejÄ… dwa ogÃ³lne podejÅ›cia do rozwiÄ…zywania problemÃ³w wieloetykietowych: transformacja problemu i adaptacja algorytmu. Transformacja problemu polega na manipulowaniu zbiorem danych w taki sposÃ³b, Å¼e problem wieloetykietowy staje siÄ™ jednym lub kilkoma problemami jednoetykietowymi (Tawiah i Sheng 2013). Adaptacja algorytmu polega na tym, Å¼e sam algorytm jest w stanie poradziÄ‡ sobie bezpoÅ›rednio z problemem wieloetykietowym. Okazuje siÄ™, Å¼e wiele, choÄ‡ nie wszystkie, metody adaptacji algorytmÃ³w metod adaptacji algorytmÃ³w w rzeczywistoÅ›ci wykorzystuje transformacjÄ™ problemu (Tsoumakas i Katakis 2007).\n\n2.2.1 Transformacja problemu\nTechniki te przewidujÄ… stworzenie indywidualnego modelu dla kaÅ¼dego celu, a nastÄ™pnie poÅ‚Ä…czenie oddzielnych modeli w celu uzyskania ogÃ³lnej prognozy. Metody transformacji problemÃ³w okazaÅ‚y siÄ™ lepsze od metod adaptacji algorytmÃ³w pod wzglÄ™dem dokÅ‚adnoÅ›ci (Spyromitros-Xioufis i in. 2016). Co wiÄ™cej, podstawowa zasada sprawia, Å¼e metody transformacji problemu sÄ… niezaleÅ¼ne od algorytmu. W konsekwencji, moÅ¼na je Å‚atwo dostosowaÄ‡ do danego problemu poprzez zastosowanie odpowiednich bazowych metod uczÄ…cych. Punkt ten ma rÃ³wnieÅ¼ szczegÃ³lne znaczenie dla modeli typu ensemble, ktÃ³re Å‚Ä…czÄ… oszacowania z wielu potencjalnie rÃ³Å¼nych algorytmÃ³w w ostatecznÄ… prognozÄ™. Niedawno Spyromitros-Xioufis i in. (2016) zaproponowali rozszerzenie znanych metod transformacji klasyfikacji wieloetykietowej, aby poradziÄ‡ sobie z problemem regresji wielowynikowej i modelowaÄ‡ zaleÅ¼noÅ›ci miÄ™dzy celami. W szczegÃ³lnoÅ›ci wprowadzili oni dwa nowe podejÅ›cia do regresji wielocelowej, skÅ‚adanie regresorÃ³w wielocelowych i Å‚aÅ„cuchy regresorÃ³w, inspirowane popularnymi i skutecznymi podejÅ›ciami do klasyfikacji wieloznaczeniowej.\nPodstawowÄ… koncepcjÄ… w metodach transformacji problemÃ³w jest wykorzystanie poprzednich modeli do nowego przewidywania poprzez rozszerzonÄ… przestrzeÅ„ cech (Borchani i in. 2015). Stacked generalization to podejÅ›cie do meta-uczenia, ktÃ³re wykorzystuje dane wyjÅ›ciowe wczeÅ›niej wyuczonych modeli do uczenia siÄ™ nowego modelu. W zwiÄ…zku z tym poczÄ…tkowe dane wyjÅ›ciowe modelu sÄ… traktowane jako nowe cechy i sÄ… ukÅ‚adane w stos do poczÄ…tkowego wektora cech przed ponownym uczeniem. W oryginalnym sformuÅ‚owaniu przewidziano tylko dwuetapowÄ… procedurÄ™, tj. poczÄ…tkowe modele wyuczone z poczÄ…tkowego wektora cech odpowiadajÄ… odpowiednio modelom i danym poziomu 0, a powiÄ™kszony wektor cech i ponownie wyuczony model sÄ… okreÅ›lane odpowiednio jako dane poziomu 1 i generalizator. JednakÅ¼e, rozsÄ…dnie rzecz biorÄ…c, ten proces ukÅ‚adania pojedynczego celu (ang. Single-target Stacking - STS) moÅ¼e byÄ‡ rÃ³wnieÅ¼ przeprowadzany w wielu iteracjach. Aby wdroÅ¼yÄ‡ tÄ™ zasadÄ™ dla problemÃ³w z wieloma celami, w ktÃ³rych kodowane sÄ… rÃ³wnieÅ¼ moÅ¼liwe korelacje miÄ™dzy zmiennymi docelowymi, wprowadzono koncepcjÄ™ ukÅ‚adania wielu celÃ³w (ang. Multi-target Stacking - MTS) (Borchani i in. 2015). Analogicznie do STS, szkolenie modelu MTS moÅ¼na uznaÄ‡ za procedurÄ™ dwuetapowÄ…. W pierwszym etapie uczone sÄ… niezaleÅ¼ne modele dla kaÅ¼dej zmiennej docelowej. NastÄ™pnie uczone sÄ… meta-modele dla kaÅ¼dej zmiennej docelowej z rozszerzonymi wektorami cech, ktÃ³re zawierajÄ… poczÄ…tkowe wektory cech, a takÅ¼e oszacowania poziomu 0 pozostaÅ‚ych zmiennych docelowych. Podobne pomysÅ‚y byÅ‚y rÃ³wnieÅ¼ stosowane w kontekÅ›cie modeli zespoÅ‚owych, tj. uczenia siÄ™ kilku modeli poziomu 0 dla kaÅ¼dej zmiennej docelowej, ktÃ³re sÄ… Å‚Ä…czone w procedurze uogÃ³lniania poziomu 1 dla wielu zmiennych docelowych (Santana i in. 2020).\n\n2.2.1.1 Single-target stacking\nMetoda ta jest stosowana przede wszystkim z zadaniach regresyjnych z wieloma wyjÅ›ciami. RozwaÅ¼my zbiÃ³r danych \\(D = \\left\\{\\left(\\mathbf{x}^{(1)}, \\mathbf{y}^{(1)}\\right), \\ldots, \\left(\\mathbf{x}^{(N)}, \\mathbf{y}^{(N)}\\right)\\right\\}\\), skÅ‚adajÄ…cy siÄ™ z \\(N\\) obserwacji, ktÃ³re sÄ… realizacjami zmiennych losowych \\(X_1,\\ldots,X_m, Y_1,\\ldots,Y_d\\). Zatem kaÅ¼de wejÅ›cie do modelu jest charakteryzowane przez \\(m\\) zmiennych \\(\\mathbf{x}{(l)}=\\left(x_1^{(l)},\\ldots, x_j^{(l)}, \\ldots, x_m^{(l)} \\right)\\) oraz \\(d\\) odpowiadajÄ…cych im wyjÅ›Ä‡ \\(\\mathbf{y}{(l)}=\\left(y_1^{(l)},\\ldots, y_i^{(l)}, \\ldots, y_d^{(l)} \\right)\\), gdzie \\(l\\in\\{1,\\ldots,N\\}, j\\in\\{1,\\ldots,m\\}, i\\in\\{1,\\ldots,d\\}\\). Naszym celem w zadaniu regresyjnym (MTR - Multi-target Regression) jest nauczenie takiego modelu \\(h\\), ktÃ³ry przeksztaÅ‚ca \\(\\mathbf{x}\\) w \\(\\mathbf{y}\\).\nW podejÅ›ciu STS w pierwszym kroku budowanych jest \\(d\\) niezaleÅ¼nych modeli przewidujÄ…cych pojedyncze wyjÅ›cie. Po tej czynnoÅ›ci meta-model jest trenowany na zbiorze \\(D_i'\\), ktÃ³ry jest wzbogaconym zbiorem \\(D_i\\) o predykcje zmiennej \\(Y_i\\), czyli\n\\[\nD_i'=\\left\\{\\left(\\mathbf{x}'^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}'^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}'^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_i^{(l)} \\right)\\). W zaleÅ¼noÅ›ci czy rozpatrujemy algorytm STS niekumulatywny, czy kumulatywny, drugi krok iteracji wyglÄ…da nieco inaczej:\n\nniekumulatywny\n\\[\n\\bar{D}_i''=\\left\\{\\left(\\mathbf{x}''^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}''^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}''^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_i'^{(l)} \\right)\\)\nkumulatywny\n\\[\n\\bar{\\bar{D}}_i''=\\left\\{\\left(\\mathbf{x}''^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}''^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}''^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_i^{(l)},\\hat{y}_i'^{(l)} \\right)\\).\n\n\n\n\nSingle-target stacking\n\n\n\n\n2.2.1.2 Multi-target stacking\nW przeciwieÅ„stwie do STS, MTS zostaÅ‚ zaprojektowany do dzielenia siÄ™ wiedzÄ… w skorelowanych zmiennych docelowych w ramach procedury Å‚Ä…czenia w stosy. Podobnie, najpierw uczone sÄ… modele pojedynczego celu. NastÄ™pnie tworzony jest zestaw meta-modeli, ktÃ³re zawierajÄ… model dla kaÅ¼dej zmiennej docelowej \\(Y_i,\\) \\(i \\in \\{1, \\ldots, d\\}\\). W ten sposÃ³b uwzglÄ™dniane sÄ… szacunki dotyczÄ…ce pozostaÅ‚ych zmiennych docelowych z pierwszego etapu, tj. model jest uczony z przeksztaÅ‚conego zbioru\n\\[\nD_i'=\\left\\{\\left(\\mathbf{x}'^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}'^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}'^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, \\hat{y}_1^{(l)},\\ldots,\\hat{y}_d^{(l)} \\right)\\). W metodzie MTS istniejÄ… rÃ³wnieÅ¼ dwa sposoby skÅ‚adania kolejnych iteracji. PrzebiegajÄ… one w podobny sposÃ³b jak w przypadku STS.\n\n\n\nMulti-target stacking\n\n\nIstnieje jeszcze trzecia metoda powszechnie stosowana do predykcji wielowyniowej zwana Regressor Chains lub Classifier Chains w zaleÅ¼noÅ›ci od celu zadania. IdÄ™ dziaÅ‚ania tej metody przedstawiÄ™ na przykÅ‚adzie modelu regresyjnego.\n\n\n2.2.1.3 Regressor Chains\nRC opierajÄ… siÄ™ na idei dopasowywania modeli pojedynczego celu wzdÅ‚uÅ¼ wybranej permutacji, tj. Å‚aÅ„cucha. Najpierw losowana jest permutacja w odniesieniu do zmiennych docelowych. Proces ten moÅ¼na przeprowadziÄ‡ w sposÃ³b losowy (Spyromitros-Xioufis i in. 2016) lub uporzÄ…dkowany (Melki i in. 2017). Wybrana permutacja jest wykorzystywana do zbudowania oddzielnego modelu regresji dla zmiennych docelowych zgodnie z kolejnoÅ›ciÄ… permutacji. Aby wykorzystaÄ‡ tÄ™ strukturÄ™ do MTR, rzeczywiste wartoÅ›ci zmiennych docelowych sÄ… dostarczane do kolejnych modeli podczas uczenia siÄ™ wzdÅ‚uÅ¼ Å‚aÅ„cucha. Na podstawie peÅ‚nego Å‚aÅ„cucha lub wybranego zestawu \\(C = (Y_1,\\ldots,Y_d)\\), pierwszy model jest ograniczony do ustalenia predykcji dla \\(Y_1\\). NastÄ™pnie, kolejno dla \\(Y_i\\) uczone sÄ… modele na podstawie zbioru\n\\[\nD_i'=\\left\\{\\left(\\mathbf{x}'^{(1)}, \\mathbf{y}_i^{(1)}\\right), \\ldots, \\left(\\mathbf{x}'^{(N)}, \\mathbf{y}_i^{(N)}\\right)\\right\\},\n\\]\ngdzie \\(\\mathbf{x}'^{(l)} =\\left(x_1^{(l)},\\ldots, x_m^{(l)}, y_1^{(l)},\\ldots, y_{i-1}^{(l)} \\right)\\). Ten algorytm ma rÃ³wnieÅ¼ dwie odmiany (niekumulatywnÄ… i kumulatywnÄ…) w zaleÅ¼noÅ›ci od ksztaÅ‚tu kolejnych iteracji.\n\n\n\nRegressor chains\n\n\nPoniewaÅ¼, jak moÅ¼na siÄ™ spodziewaÄ‡ wyniki modelowania w znaczny sposÃ³b zaleÅ¼Ä… od wylosowanej permutacji, to w metodzie zaproponowanej przez Melki i in. (2017) aby uniknÄ…Ä‡ tego efektu buduje siÄ™ \\(k\\) modeli dla rÃ³Å¼nych permutacji i Å‚Ä…czy siÄ™ wyniki w podobny sposÃ³b jak w lasach losowych.\n\n\n\n\n\n\n\n\n\nAdnotacja\n\n\n\nSÅ‚owo komentarza jeÅ›li chodzi o dostÄ™pnoÅ›Ä‡ tych metod w jÄ™zykach programowania. Niestety wspomniane metody w R nie sÄ… zaimplementowane w sposÃ³b, ktÃ³ry pozwalaÅ‚by na bezpieczne uÅ¼ywanie przygotowanych rozwiÄ…zaÅ„. Istnieje kilka wzmianek1 na ten temat. TwÃ³rcy dwÃ³ch gÅ‚Ã³wnych frameworkÃ³w do uczenia maszynowego, czyli mlr3 oraz tidymodels przygotowujÄ… implementacje tych metod. Dodatkowo istnieje rozwiÄ…zanie w wersji eksperymentalnej mtr-toolkit, ktÃ³re pozwala na wykonanie modelowania z wieloma wyjÅ›ciami, ktÃ³rym moÅ¼na siÄ™ posiÅ‚kowaÄ‡.\nNiestety w przypadku Python-a nie jest duÅ¼o lepiej. Wprawdzie w pakiecie scikit-learn istniejÄ… implementacje pozwalajÄ…ce na predykcje wielowyjÅ›ciowe w obu typach zadaÅ„ poprzez MultiOutputRegressor i MultiOutputClassifier, ale dokonujÄ… one predykcji naiwnej poprzez zÅ‚oÅ¼enie w listÄ™ wynikÃ³w pojedynczych modeli dla kaÅ¼dej zmiennej. Nieco lepiej sprawa wyglÄ…da w przypadku metod Å‚aÅ„cuchowych, poniewaÅ¼ zarÃ³wno dla klasyfikacji, jak i regresji sÄ… metody to realizujÄ…ce (ClassifierChain i RegressorChain).\n\n\n1Â na dzieÅ„ dzisiejszy, czyli poczÄ…tek 2024 roku\n\n\n2.2.2 Adaptacja algorytmu\nNiestety tej metody nie da siÄ™ zastosowaÄ‡ do kaÅ¼dego typu modelu.\n\n\n\n\nBorchani, Hanen, Gherardo Varando, Concha Bielza, i Pedro LarraÃ±aga. 2015. â€A Survey on Multi-Output Regressionâ€. WIREs Data Mining and Knowledge Discovery 5 (5): 216â€“33. https://doi.org/10.1002/widm.1157.\n\n\nMelki, Gabriella, Alberto Cano, Vojislav Kecman, i SebastiÃ¡n Ventura. 2017. â€Multi-Target Support Vector Regression via Correlation Regressor Chainsâ€. Information Sciences 415â€“416 (listopad): 53â€“69. https://doi.org/10.1016/j.ins.2017.06.017.\n\n\nSantana, Everton Jose, Felipe Rodrigues dos Santos, Saulo Martiello Mastelini, Fabio Luiz Melquiades, i Sylvio Barbon Jr. 2020. â€Improved Prediction of Soil Properties with Multi-Target Stacked Generalisation on EDXRF Spectraâ€. arXiv preprint arXiv:2002.04312. https://arxiv.org/abs/2002.04312.\n\n\nSpyromitros-Xioufis, Eleftherios, Grigorios Tsoumakas, William Groves, i Ioannis Vlahavas. 2016. â€Multi-Target Regression via Input Space Expansion: Treating Targets as Inputsâ€. Machine Learning 104 (1): 55â€“98. https://doi.org/10.1007/s10994-016-5546-z.\n\n\nTawiah, Clifford, i Victor Sheng. 2013. â€Empirical Comparison of Multi-Label Classification Algorithmsâ€. W Proceedings of the AAAI Conference on Artificial Intelligence, 27:1645â€“46.\n\n\nTsoumakas, Grigorios, i Ioannis Katakis. 2007. â€Multi-Label Classification: An Overviewâ€. International Journal of Data Warehousing and Mining (IJDWM) 3 (3): 1â€“13.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Modele z wieloma wyjÅ›ciami</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatura",
    "section": "",
    "text": "Borchani, Hanen, Gherardo Varando, Concha Bielza, and Pedro LarraÃ±aga.\n2015. â€œA Survey on Multi-Output Regression.â€ WIREs Data\nMining and Knowledge Discovery 5 (5): 216â€“33. https://doi.org/10.1002/widm.1157.\n\n\nMelki, Gabriella, Alberto Cano, Vojislav Kecman, and SebastiÃ¡n Ventura.\n2017. â€œMulti-Target Support Vector Regression via Correlation\nRegressor Chains.â€ Information Sciences 415â€“416\n(November): 53â€“69. https://doi.org/10.1016/j.ins.2017.06.017.\n\n\nSantana, Everton Jose, Felipe Rodrigues dos Santos, Saulo Martiello\nMastelini, Fabio Luiz Melquiades, and Sylvio Barbon Jr. 2020.\nâ€œImproved Prediction of Soil Properties with Multi-Target Stacked\nGeneralisation on EDXRF Spectra.â€ arXiv Preprint\narXiv:2002.04312. https://arxiv.org/abs/2002.04312.\n\n\nSpyromitros-Xioufis, Eleftherios, Grigorios Tsoumakas, William Groves,\nand Ioannis Vlahavas. 2016. â€œMulti-Target Regression\nvia Input Space Expansion: Treating Targets as\nInputs.â€ Machine Learning 104 (1): 55â€“98.\nhttps://doi.org/10.1007/s10994-016-5546-z.\n\n\nTawiah, Clifford, and Victor Sheng. 2013. â€œEmpirical Comparison of\nMulti-Label Classification Algorithms.â€ In Proceedings of the\nAAAI Conference on Artificial\nIntelligence, 27:1645â€“46.\n\n\nTsoumakas, Grigorios, and Ioannis Katakis. 2007. â€œMulti-Label\nClassification: An Overview.â€ International\nJournal of Data Warehousing and Mining (IJDWM) 3 (3): 1â€“13.",
    "crumbs": [
      "Literatura"
    ]
  }
]