<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pl" xml:lang="pl"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.537">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Zaawansowane metody uczenia maszynowego - 2&nbsp; Modele z wieloma wyjściami</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./examples.html" rel="next">
<link href="./intro.html" rel="prev">
<link href="./images/cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Brak wyników",
    "search-matching-documents-text": "dopasowane dokumenty",
    "search-copy-link-title": "Kopiuj link do wyszukiwania",
    "search-hide-matches-text": "Ukryj dodatkowe dopasowania",
    "search-more-match-text": "więcej dopasowań w tym dokumencie",
    "search-more-matches-text": "więcej dopasowań w tym dokumencie",
    "search-clear-button-title": "Wyczyść",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Anuluj",
    "search-submit-button-title": "Zatwierdź",
    "search-label": "Szukaj"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Przełącz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./multi_target_models.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Modele z wieloma wyjściami</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Przełącz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Zaawansowane metody uczenia maszynowego</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://twitter.com" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
    <a href="https://github.com/dax44/AMLM/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/intent/tweet?url=|url|" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Przełącz tryb ciemny"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Przełącz tryb czytnika">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Szukaj"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wstęp</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Wprowadzenie</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multi_target_models.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Modele z wieloma wyjściami</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Przykłady - metody klasyczne</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./examples2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Przykłady NN</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">DNN dla danych sekwencyjnych</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Literatura</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Spis treści</h2>
   
  <ul>
  <li><a href="#typy-modeli-z-wieloma-zmiennymi-wynikowymi" id="toc-typy-modeli-z-wieloma-zmiennymi-wynikowymi" class="nav-link active" data-scroll-target="#typy-modeli-z-wieloma-zmiennymi-wynikowymi"><span class="header-section-number">2.1</span> Typy modeli z wieloma zmiennymi wynikowymi</a></li>
  <li><a href="#różnie-podejścia-do-modelowania-z-wieloma-wyjściami" id="toc-różnie-podejścia-do-modelowania-z-wieloma-wyjściami" class="nav-link" data-scroll-target="#różnie-podejścia-do-modelowania-z-wieloma-wyjściami"><span class="header-section-number">2.2</span> Różnie podejścia do modelowania z wieloma wyjściami</a>
  <ul class="collapse">
  <li><a href="#transformacja-problemu" id="toc-transformacja-problemu" class="nav-link" data-scroll-target="#transformacja-problemu"><span class="header-section-number">2.2.1</span> Transformacja problemu</a></li>
  <li><a href="#adaptacja-algorytmu" id="toc-adaptacja-algorytmu" class="nav-link" data-scroll-target="#adaptacja-algorytmu"><span class="header-section-number">2.2.2</span> Adaptacja algorytmu</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/dax44/AMLM/issues/new" class="toc-action"><i class="bi bi-github"></i>Zgłoś problem</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Modele z wieloma wyjściami</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Modele z wieloma zmiennymi wynikowymi otwierają drzwi do głębokiego zrozumienia analizy statystycznej i uczenia maszynowego. Istotną motywacją dla zastosowania tych modeli jest potrzeba uwzględnienia jednoczesnego wpływu wielu czynników na zróżnicowane aspekty badanego zjawiska. W kontrze do tradycyjnych modeli, których celem jest prognozowanie jednej konkretnej zmiennej wynikowej, modele z wieloma zmiennymi pozwalają na kompleksową analizę systemów, w których wiele współzależnych zmiennych kształtuje końcowy rezultat.</p>
<p>Te modele znajdują zastosowanie zwłaszcza w sytuacjach, w których badane zjawisko jest wielowymiarowe, a jednoczesne oddziaływanie wielu czynników jest istotne. W dziedzinach takich jak badania społeczne czy ekonomiczne, gdzie liczne zmienne wpływają na dane zjawisko, modele z wieloma zmiennymi pozwalają na bardziej holistyczne zrozumienie tych interakcji. Różnicą kluczową w porównaniu do modeli jednowymiarowych jest zdolność modeli z wieloma zmiennymi do równoczesnego uwzględniania wielu aspektów, co umożliwia bardziej kompleksowe oddanie struktury rzeczywistości. Wartość dodana tych modeli kryje się w ich zdolności do precyzyjnego modelowania bardziej złożonych relacji między zmiennymi, co staje się niezbędne w obliczu rosnącej ilości dostępnych danych oraz potrzeby dokładniejszego zrozumienia skomplikowanych struktur zjawisk.</p>
<p>Jednym z przykładów wykorzystania modeli z wieloma zmiennymi na wyjściu może być prognozowanie wyników finansowych przedsiębiorstwa. W tym przypadku, zamiast koncentrować się wyłącznie na jednym wskaźniku, takim jak zysk netto, model z wieloma zmiennymi uwzględniałby różnorodne czynniki wpływające na kondycję finansową firmy. Wskaźniki takie jak przychody, koszty operacyjne, inwestycje kapitałowe, oraz czynniki makroekonomiczne mogą stanowić zbiór zmiennych wynikowych. Model taki pozwalałby na holistyczną analizę wpływu różnych czynników na zdolność przedsiębiorstwa do generowania zysku, dostarczając bardziej kompleksowych prognoz i lepszych narzędzi do podejmowania decyzji strategicznych.</p>
<p>Stosowanie oddzielnych modeli dla każdej zmiennej wynikowej, zwłaszcza w przypadku złożonych systemów czy wielowymiarowych danych, może prowadzić do suboptymalnych rezultatów i utrudniać skuteczne modelowanie rzeczywistych zależności między zmiennymi. Taka strategia może nie uwzględniać skomplikowanych relacji między poszczególnymi zmiennymi, co prowadzi do niepełnego zrozumienia struktury danego zjawiska. Ponadto, prowadzi to do redundancji w procesie uczenia, gdzie modele nie wykorzystują informacji zawartej w innych zmiennych, co ogranicza ich zdolność do trafnej prognozy. Zastosowanie jednego modelu z wieloma zmiennymi wynikowymi pozwala na uwzględnienie wzajemnych interakcji między zmiennymi, co skutkuje bardziej kompleksowym i precyzyjnym modelem, zdolnym lepiej odzwierciedlić złożoność analizowanego systemu.</p>
<p>W kontekście prognozowania wyników finansowych przedsiębiorstwa, użycie oddzielnych modeli dla każdej zmiennej wynikowej, takiej jak przychody, koszty operacyjne czy inwestycje kapitałowe, mogłoby prowadzić do ograniczonej perspektywy i niewłaściwej oceny sytuacji finansowej firmy. Oddzielne modele dla poszczególnych wskaźników mogą nie uwzględniać skomplikowanych wzajemnych relacji między tymi zmiennymi, co wprowadzałoby niedokładności w prognozach. Na przykład, wzrost kosztów operacyjnych może być związany z równoczesnym wzrostem przychodów, co niekoniecznie wynikałoby z oddzielnej analizy tych zmiennych. Korzystanie z jednego modelu uwzględniającego wszystkie te zmienne pozwala na bardziej holistyczną ocenę sytuacji finansowej, umożliwiając identyfikację ukrytych zależności i skomplikowanych interakcji między poszczególnymi aspektami działalności przedsiębiorstwa. Dzięki temu podejściu możliwe jest dostarczenie bardziej precyzyjnych prognoz, co jest kluczowe dla skutecznego zarządzania finansami i podejmowania strategicznych decyzji.</p>
<section id="typy-modeli-z-wieloma-zmiennymi-wynikowymi" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="typy-modeli-z-wieloma-zmiennymi-wynikowymi"><span class="header-section-number">2.1</span> Typy modeli z wieloma zmiennymi wynikowymi</h2>
<p>Wśród nadzorowanych modeli uczenia maszynowego z wieloma zmiennymi wynikowymi można wymienić zarówno te dedykowane do klasyfikacji, jak i regresji. Modele te są znane jako modele z wieloma wyjściami (klasyfikacyjne) lub modele z wieloma wyjściami (regresyjne), w zależności od rodzaju problemu, który rozwiązują.</p>
<ol type="1">
<li><p><strong>Modele z wieloma wyjściami (klasyfikacyjne)</strong></p>
<p>W przypadku klasyfikacji, gdy mamy wiele kategorii (klas) jako zmienną wynikową, modele te są nazywane modelami z wieloma wyjściami. Przykłady obejmują algorytmy takie jak regresja logistyczna, metoda k najbliższych sąsiadów (k-NN) czy algorytmy drzew decyzyjnych, które zostały dostosowane do obsługi wielu klas.</p>
<p>Przykładowe zadanie: Załóżmy, że mamy zbiór danych dotyczący różnych rodzajów owoców (np. jabłek, pomarańczy, bananów) i chcemy stworzyć model, który jednocześnie przewiduje gatunek owocu oraz kolor owocu. Mamy więc dwie zmienne wynikowe: gatunek (klasyfikacja wieloklasowa) i kolor (klasyfikacja wieloklasowa).</p></li>
<li><p><strong>Modele z wieloma wyjściami (regresyjne).</strong></p>
<p>W przypadku regresji, gdzie zmienną wynikową jest wektor wartości numerycznych, modele te są nazywane modelami z wieloma wyjściami. Przykłady obejmują algorytmy regresji liniowej lub nieliniowej, algorytmy oparte na drzewach decyzyjnych, czy też bardziej zaawansowane modele, takie jak sieci neuronowe.</p>
<p>Przykładowe zadanie: Zakładamy, że mamy zbiór danych zawierający informacje o pracownikach, takie jak doświadczenie zawodowe, poziom wykształcenia, liczba godzin pracy tygodniowo itp. Chcemy stworzyć model, który jednocześnie przewiduje zarobki pracowników oraz ich poziom satysfakcji zawodowej.</p></li>
<li><p><strong>Modele wielozadaniowe.</strong></p>
<p>Modele wielozadaniowe to rodzaj nadzorowanego uczenia maszynowego, w którym model jest trenowany jednocześnie do rozwiązania kilku zadań. Te zadania mogą obejmować zarówno klasyfikację, jak i regresję. Dzięki wspólnemu trenowaniu modelu na wielu zadaniach, można uzyskać korzyści w postaci wspólnego wykorzystywania wiedzy między zadaniami.</p>
<p>Przykładowe zadanie: Załóżmy, że mamy zbiór danych dotyczący zakupów klientów w sklepie internetowym. Dla każdego klienta mamy informacje o różnych aspektach zakupów, takich jak czas dostawy, łatwość obsługi strony, jakość produktów itp. Chcemy stworzyć model, który jednocześnie przewiduje dwie zmienne wynikowe: jakość obsługi klienta (skala jakościowa, np. “Niska”, “Średnia”, “Wysoka”) oraz całkowity wydatek klienta (zmienna ilościowa, np. kwota zakupów).</p></li>
<li><p><strong>Modele hierarchiczne.</strong></p>
<p>W niektórych przypadkach, szczególnie gdy mamy hierarchię zmiennych wynikowych, modele te mogą być budowane w sposób hierarchiczny. Przykładowo, w problemie klasyfikacji obrazów z hierarchią kategorii (na przykład rozpoznawanie gatunków zwierząt), model może być zaprojektowany do rozpoznawania zarówno ogólnych, jak i bardziej szczegółowych kategorii.</p></li>
</ol>
</section>
<section id="różnie-podejścia-do-modelowania-z-wieloma-wyjściami" class="level2 page-columns page-full" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="różnie-podejścia-do-modelowania-z-wieloma-wyjściami"><span class="header-section-number">2.2</span> Różnie podejścia do modelowania z wieloma wyjściami</h2>
<p>Istnieją dwa ogólne podejścia do rozwiązywania problemów wieloetykietowych: transformacja problemu i adaptacja algorytmu. Transformacja problemu polega na manipulowaniu zbiorem danych w taki sposób, że problem wieloetykietowy staje się jednym lub kilkoma problemami jednoetykietowymi <span class="citation" data-cites="tawiahEmpiricalComparisonMultilabel2013">(<a href="references.html#ref-tawiahEmpiricalComparisonMultilabel2013" role="doc-biblioref">Tawiah i Sheng 2013</a>)</span>. Adaptacja algorytmu polega na tym, że sam algorytm jest w stanie poradzić sobie bezpośrednio z problemem wieloetykietowym. Okazuje się, że wiele, choć nie wszystkie, metody adaptacji algorytmów metod adaptacji algorytmów w rzeczywistości wykorzystuje transformację problemu <span class="citation" data-cites="tsoumakasMultilabelClassificationOverview2007">(<a href="references.html#ref-tsoumakasMultilabelClassificationOverview2007" role="doc-biblioref">Tsoumakas i Katakis 2007</a>)</span>.</p>
<section id="transformacja-problemu" class="level3 page-columns page-full" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="transformacja-problemu"><span class="header-section-number">2.2.1</span> Transformacja problemu</h3>
<p>Techniki te przewidują stworzenie indywidualnego modelu dla każdego celu, a następnie połączenie oddzielnych modeli w celu uzyskania ogólnej prognozy. Metody transformacji problemów okazały się lepsze od metod adaptacji algorytmów pod względem dokładności <span class="citation" data-cites="spyromitros-xioufisMultiTargetRegressionInput2016">(<a href="references.html#ref-spyromitros-xioufisMultiTargetRegressionInput2016" role="doc-biblioref">Spyromitros-Xioufis i in. 2016</a>)</span>. Co więcej, podstawowa zasada sprawia, że metody transformacji problemu są niezależne od algorytmu. W konsekwencji, można je łatwo dostosować do danego problemu poprzez zastosowanie odpowiednich bazowych metod uczących. Punkt ten ma również szczególne znaczenie dla modeli typu ensemble, które łączą oszacowania z wielu potencjalnie różnych algorytmów w ostateczną prognozę. Niedawno <span class="citation" data-cites="spyromitros-xioufisMultiTargetRegressionInput2016">Spyromitros-Xioufis i in. (<a href="references.html#ref-spyromitros-xioufisMultiTargetRegressionInput2016" role="doc-biblioref">2016</a>)</span> zaproponowali rozszerzenie znanych metod transformacji klasyfikacji wieloetykietowej, aby poradzić sobie z problemem regresji wielowynikowej i modelować zależności między celami. W szczególności wprowadzili oni dwa nowe podejścia do regresji wielocelowej, składanie regresorów wielocelowych i łańcuchy regresorów, inspirowane popularnymi i skutecznymi podejściami do klasyfikacji wieloznaczeniowej.</p>
<p>Podstawową koncepcją w metodach transformacji problemów jest wykorzystanie poprzednich modeli do nowego przewidywania poprzez rozszerzoną przestrzeń cech <span class="citation" data-cites="borchaniSurveyMultioutputRegression2015">(<a href="references.html#ref-borchaniSurveyMultioutputRegression2015" role="doc-biblioref">Borchani i in. 2015</a>)</span>. <em>Stacked generalization</em> to podejście do meta-uczenia, które wykorzystuje dane wyjściowe wcześniej wyuczonych modeli do uczenia się nowego modelu. W związku z tym początkowe dane wyjściowe modelu są traktowane jako nowe cechy i są układane w stos do początkowego wektora cech przed ponownym uczeniem. W oryginalnym sformułowaniu przewidziano tylko dwuetapową procedurę, tj. początkowe modele wyuczone z początkowego wektora cech odpowiadają odpowiednio modelom i danym poziomu 0, a powiększony wektor cech i ponownie wyuczony model są określane odpowiednio jako dane poziomu 1 i generalizator. Jednakże, rozsądnie rzecz biorąc, ten proces układania pojedynczego celu (ang. <em>Single-target Stacking</em> - STS) może być również przeprowadzany w wielu iteracjach. Aby wdrożyć tę zasadę dla problemów z wieloma celami, w których kodowane są również możliwe korelacje między zmiennymi docelowymi, wprowadzono koncepcję układania wielu celów (ang. <em>Multi-target Stacking</em> - MTS) <span class="citation" data-cites="borchaniSurveyMultioutputRegression2015">(<a href="references.html#ref-borchaniSurveyMultioutputRegression2015" role="doc-biblioref">Borchani i in. 2015</a>)</span>. Analogicznie do STS, szkolenie modelu MTS można uznać za procedurę dwuetapową. W pierwszym etapie uczone są niezależne modele dla każdej zmiennej docelowej. Następnie uczone są meta-modele dla każdej zmiennej docelowej z rozszerzonymi wektorami cech, które zawierają początkowe wektory cech, a także oszacowania poziomu 0 pozostałych zmiennych docelowych. Podobne pomysły były również stosowane w kontekście modeli zespołowych, tj. uczenia się kilku modeli poziomu 0 dla każdej zmiennej docelowej, które są łączone w procedurze uogólniania poziomu 1 dla wielu zmiennych docelowych <span class="citation" data-cites="santanaImprovedPredictionSoil2020">(<a href="references.html#ref-santanaImprovedPredictionSoil2020" role="doc-biblioref">Santana i in. 2020</a>)</span>.</p>
<section id="single-target-stacking" class="level4" data-number="2.2.1.1">
<h4 data-number="2.2.1.1" class="anchored" data-anchor-id="single-target-stacking"><span class="header-section-number">2.2.1.1</span> Single-target stacking</h4>
<p>Metoda ta jest stosowana przede wszystkim z zadaniach regresyjnych z wieloma wyjściami. Rozważmy zbiór danych <span class="math inline">\(D = \left\{\left(\mathbf{x}^{(1)}, \mathbf{y}^{(1)}\right), \ldots, \left(\mathbf{x}^{(N)}, \mathbf{y}^{(N)}\right)\right\}\)</span>, składający się z <span class="math inline">\(N\)</span> obserwacji, które są realizacjami zmiennych losowych <span class="math inline">\(X_1,\ldots,X_m, Y_1,\ldots,Y_d\)</span>. Zatem każde wejście do modelu jest charakteryzowane przez <span class="math inline">\(m\)</span> zmiennych <span class="math inline">\(\mathbf{x}{(l)}=\left(x_1^{(l)},\ldots, x_j^{(l)}, \ldots, x_m^{(l)} \right)\)</span> oraz <span class="math inline">\(d\)</span> odpowiadających im wyjść <span class="math inline">\(\mathbf{y}{(l)}=\left(y_1^{(l)},\ldots, y_i^{(l)}, \ldots, y_d^{(l)} \right)\)</span>, gdzie <span class="math inline">\(l\in\{1,\ldots,N\}, j\in\{1,\ldots,m\}, i\in\{1,\ldots,d\}\)</span>. Naszym celem w zadaniu regresyjnym (MTR - <em>Multi-target Regression</em>) jest nauczenie takiego modelu <span class="math inline">\(h\)</span>, który przekształca <span class="math inline">\(\mathbf{x}\)</span> w <span class="math inline">\(\mathbf{y}\)</span>.</p>
<p>W podejściu STS w pierwszym kroku budowanych jest <span class="math inline">\(d\)</span> niezależnych modeli przewidujących pojedyncze wyjście. Po tej czynności meta-model jest trenowany na zbiorze <span class="math inline">\(D_i'\)</span>, który jest wzbogaconym zbiorem <span class="math inline">\(D_i\)</span> o predykcje zmiennej <span class="math inline">\(Y_i\)</span>, czyli</p>
<p><span class="math display">\[
D_i'=\left\{\left(\mathbf{x}'^{(1)}, \mathbf{y}_i^{(1)}\right), \ldots, \left(\mathbf{x}'^{(N)}, \mathbf{y}_i^{(N)}\right)\right\},
\]</span></p>
<p>gdzie <span class="math inline">\(\mathbf{x}'^{(l)} =\left(x_1^{(l)},\ldots, x_m^{(l)}, \hat{y}_i^{(l)} \right)\)</span>. W zależności czy rozpatrujemy algorytm STS niekumulatywny, czy kumulatywny, drugi krok iteracji wygląda nieco inaczej:</p>
<ul>
<li><p>niekumulatywny</p>
<p><span class="math display">\[
\bar{D}_i''=\left\{\left(\mathbf{x}''^{(1)}, \mathbf{y}_i^{(1)}\right), \ldots, \left(\mathbf{x}''^{(N)}, \mathbf{y}_i^{(N)}\right)\right\},
\]</span></p>
<p>gdzie <span class="math inline">\(\mathbf{x}''^{(l)} =\left(x_1^{(l)},\ldots, x_m^{(l)}, \hat{y}_i'^{(l)} \right)\)</span></p></li>
<li><p>kumulatywny</p>
<p><span class="math display">\[
\bar{\bar{D}}_i''=\left\{\left(\mathbf{x}''^{(1)}, \mathbf{y}_i^{(1)}\right), \ldots, \left(\mathbf{x}''^{(N)}, \mathbf{y}_i^{(N)}\right)\right\},
\]</span></p>
<p>gdzie <span class="math inline">\(\mathbf{x}''^{(l)} =\left(x_1^{(l)},\ldots, x_m^{(l)}, \hat{y}_i^{(l)},\hat{y}_i'^{(l)} \right)\)</span>.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2024-01-9 o 18.38.32.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
<figcaption>Single-target stacking</figcaption>
</figure>
</div>
</section>
<section id="multi-target-stacking" class="level4" data-number="2.2.1.2">
<h4 data-number="2.2.1.2" class="anchored" data-anchor-id="multi-target-stacking"><span class="header-section-number">2.2.1.2</span> Multi-target stacking</h4>
<p>W przeciwieństwie do STS, MTS został zaprojektowany do dzielenia się wiedzą w skorelowanych zmiennych docelowych w ramach procedury łączenia w stosy. Podobnie, najpierw uczone są modele pojedynczego celu. Następnie tworzony jest zestaw meta-modeli, które zawierają model dla każdej zmiennej docelowej <span class="math inline">\(Y_i,\)</span> <span class="math inline">\(i \in \{1, \ldots, d\}\)</span>. W ten sposób uwzględniane są szacunki dotyczące pozostałych zmiennych docelowych z pierwszego etapu, tj. model jest uczony z przekształconego zbioru</p>
<p><span class="math display">\[
D_i'=\left\{\left(\mathbf{x}'^{(1)}, \mathbf{y}_i^{(1)}\right), \ldots, \left(\mathbf{x}'^{(N)}, \mathbf{y}_i^{(N)}\right)\right\},
\]</span></p>
<p>gdzie <span class="math inline">\(\mathbf{x}'^{(l)} =\left(x_1^{(l)},\ldots, x_m^{(l)}, \hat{y}_1^{(l)},\ldots,\hat{y}_d^{(l)} \right)\)</span>. W metodzie MTS istnieją również dwa sposoby składania kolejnych iteracji. Przebiegają one w podobny sposób jak w przypadku STS.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2024-01-9 o 18.39.01.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
<figcaption>Multi-target stacking</figcaption>
</figure>
</div>
<p>Istnieje jeszcze trzecia metoda powszechnie stosowana do predykcji wielowyniowej zwana <em>Regressor Chains</em> lub <em>Classifier Chains</em> w zależności od celu zadania. Idę działania tej metody przedstawię na przykładzie modelu regresyjnego.</p>
</section>
<section id="regressor-chains" class="level4 page-columns page-full" data-number="2.2.1.3">
<h4 data-number="2.2.1.3" class="anchored" data-anchor-id="regressor-chains"><span class="header-section-number">2.2.1.3</span> Regressor Chains</h4>
<p>RC opierają się na idei dopasowywania modeli pojedynczego celu wzdłuż wybranej permutacji, tj. łańcucha. Najpierw losowana jest permutacja w odniesieniu do zmiennych docelowych. Proces ten można przeprowadzić w sposób losowy <span class="citation" data-cites="spyromitros-xioufisMultiTargetRegressionInput2016">(<a href="references.html#ref-spyromitros-xioufisMultiTargetRegressionInput2016" role="doc-biblioref">Spyromitros-Xioufis i in. 2016</a>)</span> lub uporządkowany <span class="citation" data-cites="melkiMultitargetSupportVector2017">(<a href="references.html#ref-melkiMultitargetSupportVector2017" role="doc-biblioref">Melki i in. 2017</a>)</span>. Wybrana permutacja jest wykorzystywana do zbudowania oddzielnego modelu regresji dla zmiennych docelowych zgodnie z kolejnością permutacji. Aby wykorzystać tę strukturę do MTR, rzeczywiste wartości zmiennych docelowych są dostarczane do kolejnych modeli podczas uczenia się wzdłuż łańcucha. Na podstawie pełnego łańcucha lub wybranego zestawu <span class="math inline">\(C = (Y_1,\ldots,Y_d)\)</span>, pierwszy model jest ograniczony do ustalenia predykcji dla <span class="math inline">\(Y_1\)</span>. Następnie, kolejno dla <span class="math inline">\(Y_i\)</span> uczone są modele na podstawie zbioru</p>
<p><span class="math display">\[
D_i'=\left\{\left(\mathbf{x}'^{(1)}, \mathbf{y}_i^{(1)}\right), \ldots, \left(\mathbf{x}'^{(N)}, \mathbf{y}_i^{(N)}\right)\right\},
\]</span></p>
<p>gdzie <span class="math inline">\(\mathbf{x}'^{(l)} =\left(x_1^{(l)},\ldots, x_m^{(l)}, y_1^{(l)},\ldots, y_{i-1}^{(l)} \right)\)</span>. Ten algorytm ma również dwie odmiany (niekumulatywną i kumulatywną) w zależności od kształtu kolejnych iteracji.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2024-01-9 o 19.10.54.png" class="img-fluid figure-img"></p>
<figcaption>Regressor chains</figcaption>
</figure>
</div>
<p>Ponieważ, jak można się spodziewać wyniki modelowania w znaczny sposób zależą od wylosowanej permutacji, to w metodzie zaproponowanej przez <span class="citation" data-cites="melkiMultitargetSupportVector2017">Melki i in. (<a href="references.html#ref-melkiMultitargetSupportVector2017" role="doc-biblioref">2017</a>)</span> aby uniknąć tego efektu buduje się <span class="math inline">\(k\)</span> modeli dla różnych permutacji i łączy się wyniki w podobny sposób jak w lasach losowych.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="images/r_vs_python.png" class="img-fluid"></p>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Adnotacja
</div>
</div>
<div class="callout-body-container callout-body">
<p>Słowo komentarza jeśli chodzi o dostępność tych metod w językach programowania. Niestety wspomniane metody w R nie są zaimplementowane w sposób, który pozwalałby na bezpieczne używanie przygotowanych rozwiązań. Istnieje kilka wzmianek (na dzień dzisiejszy, czyli początek 2024 roku) na ten temat. Twórcy dwóch głównych frameworków do uczenia maszynowego, czyli <code>mlr3</code> oraz <code>tidymodels</code> przygotowują implementacje tych metod. Dodatkowo istnieje rozwiązanie w wersji eksperymentalnej <code>mtr-toolkit</code>, które pozwala na wykonanie modelowania z wieloma wyjściami, którym można się posiłkować. Na potrzeby klasyfikacji istnieje również pakiet <code>mldr</code> i <code>ultim</code>, które pozwalają na uczenie modeli klasyfikacyjnymi z wieloma wyjściami.</p>
<p>Niestety w przypadku Python-a nie jest dużo lepiej. Wprawdzie w pakiecie <code>scikit-learn</code> istnieją implementacje pozwalające na predykcje wielowyjściowe w obu typach zadań poprzez <code>MultiOutputRegressor</code> i <code>MultiOutputClassifier</code>, ale dokonują one predykcji naiwnej poprzez złożenie w listę wyników pojedynczych modeli dla każdej zmiennej. Nieco lepiej sprawa wygląda w przypadku metod łańcuchowych, ponieważ zarówno dla klasyfikacji, jak i regresji są metody to realizujące (<code>ClassifierChain</code> i <code>RegressorChain</code>).</p>
</div>
</div>
</section>
</section>
<section id="adaptacja-algorytmu" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="adaptacja-algorytmu"><span class="header-section-number">2.2.2</span> Adaptacja algorytmu</h3>
<p>Prostota podejścia transformacji problemu sprawia, że jest ono odpowiednie dla problemów, w których jego wady mają niewielki lub żaden wpływ - jednak dla złożonych problemów podejście adaptacji algorytmu może okazać się bardziej efektywne. Dodatkowo, dowody empiryczne sugerują, że uczenie się powiązanych zadań jednocześnie, a nie niezależnie, może poprawić wyniki predykcyjne <span class="citation" data-cites="evgeniou2004">(<a href="references.html#ref-evgeniou2004" role="doc-biblioref">Evgeniou i Pontil 2004</a>)</span>. Z drugiej strony, jeśli zadania są bardzo odmienne, wydajność predykcyjna może ucierpieć, gdy zadania są uczone razem, a nie niezależnie <span class="citation" data-cites="faddoulBoostingMultiTaskWeak2010">(<a href="references.html#ref-faddoulBoostingMultiTaskWeak2010" role="doc-biblioref">Faddoul i in. 2010</a>)</span>. W związku z tym możemy wyciągnąć następujące wnioski:</p>
<ul>
<li>jeśli zadania, których nasz predyktor ma się nauczyć, są powiązane, powinniśmy dążyć do znalezienia odpowiedniej metody adaptacji algorytmu;</li>
<li>jeśli zadania, których chcemy się nauczyć, nie są powiązane, powinniśmy zamiast tego dążyć do znalezienia odpowiedniej metody transformacji problemu.</li>
</ul>
<p>Wreszcie, powinniśmy wziąć pod uwagę rozmiar problemu i zdać sobie sprawę, że gdy zadania są niepowiązane, istnieje potencjalny kompromis między efektywnością czasową a wydajnością predykcyjną przy wyborze metody transformacji problemu lub metody adaptacji algorytmu. W przypadku niepowiązanych ze sobą zadań, metody transformacji problemu mogą zwiększać skuteczność predykcyjną, ale zmniejszać wydajność czasową w przypadku dużych problemów i odwrotnie.</p>
<p>Niestety tej metody nie da się zastosować do każdego typu modelu. Rodzina modeli, których adaptacja jest wykonana cały czas rośnie. Adaptacja modelu polega na przekształceniu go do postaci, w której da się wykonać predykcję dla wielu wyjść. Wśród modeli, których wersje <em>native</em> <em>multi-target</em> istnieją należy wymienić:</p>
<ul>
<li>regresja wieloraka <span class="citation" data-cites="izenmanReducedrankRegressionMultivariate1975">(<a href="references.html#ref-izenmanReducedrankRegressionMultivariate1975" role="doc-biblioref">Izenman 1975</a>)</span></li>
<li>kNN</li>
<li>drzewo decyzyjne <span class="citation" data-cites="struyfConstraintBasedInduction2006">(<a href="references.html#ref-struyfConstraintBasedInduction2006" role="doc-biblioref">Struyf i Džeroski 2006</a>)</span></li>
<li>las losowy <span class="citation" data-cites="kocevTreeEnsemblesPredicting2013">(<a href="references.html#ref-kocevTreeEnsemblesPredicting2013" role="doc-biblioref">Kocev i in. 2013</a>)</span></li>
<li>bagging <span class="citation" data-cites="kocevTreeEnsemblesPredicting2013">(<a href="references.html#ref-kocevTreeEnsemblesPredicting2013" role="doc-biblioref">Kocev i in. 2013</a>)</span></li>
<li>gradient boosting <span class="citation" data-cites="zhangGBDTMOGradientBoosted2019 faddoulLearningMultipleTasks2012">(<a href="references.html#ref-zhangGBDTMOGradientBoosted2019" role="doc-biblioref">Zhang i Jung, b.d.</a>; <a href="references.html#ref-faddoulLearningMultipleTasks2012" role="doc-biblioref">Faddoul i in. 2012</a>)</span></li>
<li>SVM <span class="citation" data-cites="xuTwinMultiClassClassification2013 vazquezMultiOutputSuppportVector2003">(<a href="references.html#ref-xuTwinMultiClassClassification2013" role="doc-biblioref">Xu, Guo, i Wang 2013</a>; <a href="references.html#ref-vazquezMultiOutputSuppportVector2003" role="doc-biblioref">Vazquez i Walter 2003</a>)</span></li>
<li>no i oczywiście sieci neuronowe.</li>
</ul>
<p>Nie sposób przedstawić w jaki sposób wprowadzone zostały zmiany we wszystkich algorytmach. Skupię się jednak na pokazaniu adaptacji drzew decyzyjnych do predykcji wielu wyjść jednocześnie, ponieważ jest to meta-model modeli takich jak lasy losowe, bagging czy boosting.</p>
<section id="adaptacja-klasyfikacyjnego-drzewa-decyzyjnego" class="level4" data-number="2.2.2.1">
<h4 data-number="2.2.2.1" class="anchored" data-anchor-id="adaptacja-klasyfikacyjnego-drzewa-decyzyjnego"><span class="header-section-number">2.2.2.1</span> Adaptacja klasyfikacyjnego drzewa decyzyjnego</h4>
<p><span class="citation" data-cites="faddoulLearningMultipleTasks2012">Faddoul i in. (<a href="references.html#ref-faddoulLearningMultipleTasks2012" role="doc-biblioref">2012</a>)</span> zaproponowali zmodyfikowaną wersję algorytmu drzewa decyzyjnego C4.5 <span class="citation" data-cites="quinlan1993">(<a href="references.html#ref-quinlan1993" role="doc-biblioref">Quinlan 1993</a>)</span>, która bezpośrednio obsługuje problemy klasyfikacji wielowyjściowej. Zmodyfikowana wersja (nazwana MT-DT) różni się od standardowej implementacji C4.5 w dwóch krytycznych aspektach: kryteriach podziału węzłów i procesie decyzyjnym. <span class="citation" data-cites="faddoulLearningMultipleTasks2012">Faddoul i in. (<a href="references.html#ref-faddoulLearningMultipleTasks2012" role="doc-biblioref">2012</a>)</span> proponują trzy różne podejścia do łączenia wielu miar przyrostu informacji w jedną miarę: wspólny przyrost informacji, suma nieważona i maksymalny przyrost informacji. Wspólny przyrost informacyjny jest definiowany przy użyciu konkatenacji wszystkich poszczególnych zadań, tj. względnej różnicy w entropii mierzonej we wszystkich zadaniach decyzyjnych. Autorzy pokazują, że nieważona suma (<a href="#eq-igu" class="quarto-xref">Równanie&nbsp;<span>2.1</span></a>) indywidualnych przyrostów informacyjnych wszystkich zadań jest równoważna wspólnemu przyrostowi informacyjnemu.</p>
<p><span id="eq-igu"><span class="math display">\[
IG_U=\sum_YIG_Y
\tag{2.1}\]</span></span></p>
<p>Maksymalny przyrost informacyjny, zgodnie z propozycją autorów jest definiowany po prostu jako maksymalny przyrost informacyjny wszystkich zadań:</p>
<p><span id="eq-igm"><span class="math display">\[
IG_M=\max_YIG_Y
\tag{2.2}\]</span></span></p>
<p>Badania eksperymentalne pokazały, że maksymalny przyrost informacyjny wykorzystany do budowania reguł podziału, charakteryzuje się wyższym poziomem dopasowania modeli, niż przy zastosowaniu <span class="math inline">\(IG_U\)</span> i <span class="math inline">\(IG_J\)</span>.</p>
<p>W przypadku klasyfikacji z jedną etykietą, algorytm indukcji drzewa decyzyjnego (taki jak C4.5) rekurencyjnie dzieli węzły, dodając (zazwyczaj dwa) elementy potomne, aż możliwe jest utworzenie liścia takiego, że znaczna większość (lub nawet wszystkie) jego przykładowych instancji należy do tej samej klasy. W przypadku wielu wyjść, indukcja drzewa niekoniecznie jest tak prosta. Rozważmy problem klasyfikacji wielowyjściowej z dwoma wyjściami binarnymi <span class="math inline">\(\nu_1\)</span> i <span class="math inline">\(\nu_2\)</span>; możliwe jest, że po <span class="math inline">\(t\)</span> podziałach, węzeł zawiera tylko wartości pozytywne dla <span class="math inline">\(\nu_1\)</span>, ale mieszankę wartości pozytywnych i negatywnych dla <span class="math inline">\(\nu_2\)</span> - stąd, podczas konstruowania drzew decyzyjnych dla wielu jednoczesnych zadań, należy pamiętać, że proces decyzyjny dla pewnego zadania może wymagać krótszej ścieżki decyzyjnej niż inne zadania w ramach tego samego problemu wielowyjściowego. MT-DT radzi sobie z tym, sprawdzając w każdym węźle, czy możliwe jest utworzenie węzła terminalnego dla któregokolwiek z zadań - w powyższym przykładzie spowodowałoby to utworzenie drzewa, w którym wewnętrzny węzeł <span class="math inline">\(t_1\)</span> jest oznaczony jako węzeł zatrzymania dla <span class="math inline">\(\nu_1\)</span>, oznaczony klasą pozytywną. Ponieważ celem jest prognozowanie dla obu wyjść binarnych, <span class="math inline">\(t_1\)</span> nie jest węzłem liścia - zamiast tego rekurencyjne dzielenie jest kontynuowane od <span class="math inline">\(t_1\)</span>, aż do znalezienia węzła <span class="math inline">\(t_2\)</span> takiego, że <span class="math inline">\(t_2\)</span> jest wystarczająco czysty w odniesieniu do <span class="math inline">\(\nu_2\)</span>, aby można było utworzyć regułę klasyfikacji dla drugiego zadania binarnego. W tym momencie węzły decyzyjne (węzły wewnętrzne lub liście) zostały znalezione dla wszystkich wyników (<span class="math inline">\(\nu_1\)</span> i <span class="math inline">\(\nu_2\)</span>), a algorytm indukcji drzewa rekurencyjnego może zostać zakończony.</p>
<p>Nic dziwnego, że klasyfikacja przy użyciu już zbudowanego modelu MT-DT przebiega według tej samej formuły, co jego indukcja - podczas przechodzenia przez drzewo każdy węzeł jest sprawdzany w celu ustalenia, czy można podjąć decyzję dla któregokolwiek z aktualnie nierozstrzygniętych zadań. W przykładzie <span class="math inline">\(\nu_1\)</span>, <span class="math inline">\(\nu_2\)</span>, klasyfikacja zostanie dokonana dla <span class="math inline">\(\nu_1\)</span> w węźle <span class="math inline">\(t_1\)</span>, ponieważ jest on oznaczony jako węzeł zatrzymania dla <span class="math inline">\(\nu_1\)</span>; następnie przejście jest kontynuowane do momentu napotkania <span class="math inline">\(t_2\)</span> i klasyfikacja może zostać dokonana dla <span class="math inline">\(\nu_2\)</span>. W tym momencie wszystkie wyjścia zostały sklasyfikowane, a przechodzenie może się zakończyć, zwracając dwie wartości w <span class="math inline">\(t_1\)</span> i <span class="math inline">\(t_2\)</span> jako klasyfikacje odpowiednio dla <span class="math inline">\(\nu_1\)</span> i <span class="math inline">\(\nu_2\)</span>.</p>
</section>
<section id="adaptacja-regresyjnego-drzewa-decyzyjnego" class="level4" data-number="2.2.2.2">
<h4 data-number="2.2.2.2" class="anchored" data-anchor-id="adaptacja-regresyjnego-drzewa-decyzyjnego"><span class="header-section-number">2.2.2.2</span> Adaptacja regresyjnego drzewa decyzyjnego</h4>
<p><span class="citation" data-cites="segalTreeStructuredMethodsLongitudinal1992">Segal (<a href="references.html#ref-segalTreeStructuredMethodsLongitudinal1992" role="doc-biblioref">1992</a>)</span> zaproponował rozwiązanie dla drzew regresyjnych o wielu wyjściach (MRT), które są w stanie przewidywać wyniki dla wielu powiązanych zadań regresyjnych; te wielowyjściowe drzewa regresyjne są oparte na funkcji podziału najmniejszych kwadratów zaproponowanej w ramach CART <span class="citation" data-cites="breiman2017">(<a href="references.html#ref-breiman2017" role="doc-biblioref">Breiman i in. 2017</a>)</span>. W przypadku drzewa regresyjnego o jednej odpowiedzi celem jest minimalizacja następującej funkcji celu:</p>
<p><span class="math display">\[
\phi(t) = SS(t)-SS(t_L)-SS(t_R)
\]</span></p>
<p>gdzie <span class="math inline">\(SS(t)\)</span> jest zdefiniowana następująco</p>
<p><span class="math display">\[
SS(t) = \sum_{i\in t}(y_i-\bar{y}(t))^2.
\]</span></p>
<p><span class="citation" data-cites="segalTreeStructuredMethodsLongitudinal1992">Segal (<a href="references.html#ref-segalTreeStructuredMethodsLongitudinal1992" role="doc-biblioref">1992</a>)</span> dodał ważenie macierzą kowariancji do błędu kwadratowego, co prowadzi algorytm drzewa do tworzenia węzłów potomnych, które reprezentują jednorodne klastry w odniesieniu do zestawu odpowiedzi wyjściowych:</p>
<p><span class="math display">\[
SS(t) = \sum_{i\in t}(y_i-\bar{y}(t))'V^{-1}(t)(y_i-\bar{y}(t)),
\]</span></p>
<p>gdzie <span class="math inline">\(V(t)\)</span> oznacza macierz kowariancji w węźle <span class="math inline">\(t\)</span>.</p>
</section>
<section id="adaptacja-drzew-decyzyjnych-do-realizacji-obu-zadań" class="level4" data-number="2.2.2.3">
<h4 data-number="2.2.2.3" class="anchored" data-anchor-id="adaptacja-drzew-decyzyjnych-do-realizacji-obu-zadań"><span class="header-section-number">2.2.2.3</span> Adaptacja drzew decyzyjnych do realizacji obu zadań</h4>
<p>Jak wspomniano wcześniej, jedną z kluczowych motywacji do podejmowania prób rozwiązywania problemów rozpoznawania wzorców z wieloma wyjściami przy użyciu metod adaptacji algorytmów jest oczekiwanie, że pojedynczy model wytrenowany na zestawie powiązanych zadań wykaże poprawę wydajności predykcyjnej w porównaniu do zestawu indywidualnych modeli, z których każdy został wytrenowany na pojedynczym zadaniu. Rodzi to pytanie: co jeśli problem wielowynikowy zawiera zarówno zadania klasyfikacji, jak i regresji? Jeśli zadania są niepowiązane, rozwiązanie takiego wspólnego problemu klasyfikacyjno-regresyjnego nie musi być trudniejsze niż szkolenie zestawu klasyfikatorów i regresorów dla poszczególnych zadań; jeśli jednak zadania są powiązane, oczekujemy, że metoda adaptacji algorytmu zapewni lepsze wyniki pod względem wydajności predykcyjnej.</p>
<p><span class="citation" data-cites="glockerJointClassificationRegressionForests2012">Glocker i in. (<a href="references.html#ref-glockerJointClassificationRegressionForests2012" role="doc-biblioref">2012</a>)</span> zaproponował algorytm indukcji drzewa, który jednocześnie rozwiązuje jedno zadanie klasyfikacji i jedno zadanie regresji. Podobnie jak MT-DT i MRT, wspólne drzewo klasyfikacyjno-regresyjne (JCRT) rozwiązuje wiele jednoczesnych zadań predykcji poprzez modyfikację funkcji podziału węzła w kroku indukcyjnym i oznaczenie węzłów końcowych odpowiednimi wartościami dla każdego zadania. Ze względu na charakter wspólnych problemów klasyfikacyjno-regresyjnych, zmodyfikowana funkcja podziału jest wymagana do jednoczesnego uwzględnienia błędu zarówno części klasyfikacyjnej, jak i regresyjnej. Funkcja podziału zaproponowana przez <span class="citation" data-cites="glockerJointClassificationRegressionForests2012">Glocker i in. (<a href="references.html#ref-glockerJointClassificationRegressionForests2012" role="doc-biblioref">2012</a>)</span> wykorzystuje funkcję entropii składającą się z trzech części:</p>
<ul>
<li>po pierwsze, entropia Shannona jest obliczana dla części klasyfikacji;</li>
<li>po drugie, ważona entropia różnicowa jest obliczana dla części regresji;</li>
<li>po trzecie, ze względu na fakt, że entropia Shannona i entropia różnicowa istnieją w różnych zakresach, stosuje się krok normalizacji w celu połączenia dwóch entropii. Entropia Shannona jest obliczana tak, jak opisano wcześniej:</li>
</ul>
<p><span class="math display">\[
H_c(t) = \sum_{c\in C}p(c|x)\log p(c|x).
\]</span></p>
<p>Miara entropii różniczkowej stosowana przez <span class="citation" data-cites="glockerJointClassificationRegressionForests2012">Glocker i in. (<a href="references.html#ref-glockerJointClassificationRegressionForests2012" role="doc-biblioref">2012</a>)</span> dla regresyjnej części problemu jest obliczana w podobny sposób, z dwiema kluczowymi różnicami:</p>
<ul>
<li>zamiast sumowania prawdopodobieństw wartości nominalnych, entropia jest definiowana przez różniczkę funkcji prawdopodobieństwa wyjścia o wartości rzeczywistej;</li>
<li>dodatkowo funkcja prawdopodobieństwa jest ważona w klasach:</li>
</ul>
<p><span class="math display">\[
H_{r|c}(t) = \sum_{c\in C}p(c|x)\int_{r\in \mathbb{R}^n}-p(r|c,x)\log p(r|c,x)dr.
\]</span></p>
<p>Następnie dokonywana jest normalizacja ze względu na oba zadania, gdzie punktem odniesienie jest entropia w korzeniu:</p>
<p><span class="math display">\[
H(t) = \frac12\left(\frac{H_c(t)}{H_c(t_0)}+\frac{H_{r|c}(t)}{H_{r|c}(t_0)}\right).
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Adnotacja
</div>
</div>
<div class="callout-body-container callout-body">
<p>Jedyne implementacje, które znalazłem dla obu języków programowania (R i Python) dotyczyły lasów losowych. W R pakiet nazywa się <code>randomForestSRC</code>, a w Pythonie <code>morfist</code>. Pozwalają one zarówno na wykonywanie wielowyjściowych zadań klasyfikacyjnych i regresyjnych, jak również zadań mieszanych. Oczywiście wspomniane wyżej typy zadań można realizować przy użyciu sieci neuronowych w obu językach programowania.</p>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-borchaniSurveyMultioutputRegression2015" class="csl-entry" role="listitem">
Borchani, Hanen, Gherardo Varando, Concha Bielza, i Pedro Larrañaga. 2015. <span>„A Survey on Multi-Output Regression”</span>. <em>WIREs Data Mining and Knowledge Discovery</em> 5 (5): 216–33. <a href="https://doi.org/10.1002/widm.1157">https://doi.org/10.1002/widm.1157</a>.
</div>
<div id="ref-breiman2017" class="csl-entry" role="listitem">
Breiman, Leo, J. H. Friedman, Richard A. Olshen, i Charles J. Stone. 2017. <em>Classification and Regression Trees.</em> Routledge. <a href="http://search.ebscohost.com/login.aspx?direct=true&amp;db=edsebk&amp;AN=1619230&amp;lang=pl&amp;site=eds-live&amp;scope=site">http://search.ebscohost.com/login.aspx?direct=true&amp;db=edsebk&amp;AN=1619230&amp;lang=pl&amp;site=eds-live&amp;scope=site</a>.
</div>
<div id="ref-evgeniou2004" class="csl-entry" role="listitem">
Evgeniou, Theodoros, i Massimiliano Pontil. 2004. <span>„Regularized multi–task learning”</span>. <em>Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</em>, sierpień. <a href="https://doi.org/10.1145/1014052.1014067">https://doi.org/10.1145/1014052.1014067</a>.
</div>
<div id="ref-faddoulLearningMultipleTasks2012" class="csl-entry" role="listitem">
Faddoul, Jean Baptiste, Boris Chidlovskii, Rémi Gilleron, i Fabien Torre. 2012. <span>„Learning multiple tasks with boosted decision trees”</span>. W <em>Proceedings of the 2012th European Conference on Machine Learning and Knowledge Discovery in Databases - Volume Part I</em>, 681–96. ECMLPKDD’12. Springer-Verlag.
</div>
<div id="ref-faddoulBoostingMultiTaskWeak2010" class="csl-entry" role="listitem">
Faddoul, Jean Baptiste, Boris Chidlovskii, Fabien Torre, i Remi Gilleron. 2010. <span>„Boosting Multi-Task Weak Learners with Applications to Textual and Social Data”</span>. W <em>2010 Ninth International Conference on Machine Learning and Applications</em>, 367–72. IEEE. <a href="https://doi.org/10.1109/ICMLA.2010.61">https://doi.org/10.1109/ICMLA.2010.61</a>.
</div>
<div id="ref-glockerJointClassificationRegressionForests2012" class="csl-entry" role="listitem">
Glocker, Ben, Olivier Pauly, Ender Konukoglu, i Antonio Criminisi. 2012. <span>„Joint Classification-Regression Forests for Spatially Structured Multi-object Segmentation”</span>. W <em>Computer Vision – ECCV 2012</em>, zredagowane przez Andrew Fitzgibbon, Svetlana Lazebnik, Pietro Perona, Yoichi Sato, i Cordelia Schmid, 7575:870–81. Springer Berlin Heidelberg. <a href="http://link.springer.com/10.1007/978-3-642-33765-9_62">http://link.springer.com/10.1007/978-3-642-33765-9_62</a>.
</div>
<div id="ref-izenmanReducedrankRegressionMultivariate1975" class="csl-entry" role="listitem">
Izenman, Alan Julian. 1975. <span>„Reduced-rank regression for the multivariate linear model”</span>. <em>Journal of multivariate analysis</em> 5 (2): 248–64.
</div>
<div id="ref-kocevTreeEnsemblesPredicting2013" class="csl-entry" role="listitem">
Kocev, Dragi, Celine Vens, Jan Struyf, i Sašo Džeroski. 2013. <span>„Tree ensembles for predicting structured outputs”</span>. <em>Pattern Recognition</em> 46 (3): 817–33. <a href="https://doi.org/10.1016/j.patcog.2012.09.023">https://doi.org/10.1016/j.patcog.2012.09.023</a>.
</div>
<div id="ref-melkiMultitargetSupportVector2017" class="csl-entry" role="listitem">
Melki, Gabriella, Alberto Cano, Vojislav Kecman, i Sebastián Ventura. 2017. <span>„Multi-Target Support Vector Regression via Correlation Regressor Chains”</span>. <em>Information Sciences</em> 415–416 (listopad): 53–69. <a href="https://doi.org/10.1016/j.ins.2017.06.017">https://doi.org/10.1016/j.ins.2017.06.017</a>.
</div>
<div id="ref-quinlan1993" class="csl-entry" role="listitem">
Quinlan, J Ross. 1993. <em>C4. 5: Programs for Machine Learning</em>. Morgan Kaufmann.
</div>
<div id="ref-santanaImprovedPredictionSoil2020" class="csl-entry" role="listitem">
Santana, Everton Jose, Felipe Rodrigues dos Santos, Saulo Martiello Mastelini, Fabio Luiz Melquiades, i Sylvio Barbon Jr. 2020. <span>„Improved Prediction of Soil Properties with Multi-Target Stacked Generalisation on <span>EDXRF</span> Spectra”</span>. <em>arXiv preprint arXiv:2002.04312</em>. <a href="https://arxiv.org/abs/2002.04312">https://arxiv.org/abs/2002.04312</a>.
</div>
<div id="ref-segalTreeStructuredMethodsLongitudinal1992" class="csl-entry" role="listitem">
Segal, Mark Robert. 1992. <span>„Tree-Structured Methods for Longitudinal Data”</span>. <em>Journal of the American Statistical Association</em> 87 (418): 407–18. <a href="https://doi.org/10.2307/2290271">https://doi.org/10.2307/2290271</a>.
</div>
<div id="ref-spyromitros-xioufisMultiTargetRegressionInput2016" class="csl-entry" role="listitem">
Spyromitros-Xioufis, Eleftherios, Grigorios Tsoumakas, William Groves, i Ioannis Vlahavas. 2016. <span>„Multi-<span>Target Regression</span> via <span>Input Space Expansion</span>: <span>Treating Targets</span> as <span>Inputs</span>”</span>. <em>Machine Learning</em> 104 (1): 55–98. <a href="https://doi.org/10.1007/s10994-016-5546-z">https://doi.org/10.1007/s10994-016-5546-z</a>.
</div>
<div id="ref-struyfConstraintBasedInduction2006" class="csl-entry" role="listitem">
Struyf, Jan, i Sašo Džeroski. 2006. <span>„Constraint Based Induction of Multi-objective Regression Trees”</span>. W <em>Knowledge Discovery in Inductive Databases</em>, zredagowane przez Francesco Bonchi i Jean-François Boulicaut, 222–33. Lecture Notes w Computer Science. Springer. <a href="https://doi.org/10.1007/11733492_13">https://doi.org/10.1007/11733492_13</a>.
</div>
<div id="ref-tawiahEmpiricalComparisonMultilabel2013" class="csl-entry" role="listitem">
Tawiah, Clifford, i Victor Sheng. 2013. <span>„Empirical Comparison of Multi-Label Classification Algorithms”</span>. W <em>Proceedings of the <span>AAAI Conference</span> on <span>Artificial Intelligence</span></em>, 27:1645–46.
</div>
<div id="ref-tsoumakasMultilabelClassificationOverview2007" class="csl-entry" role="listitem">
Tsoumakas, Grigorios, i Ioannis Katakis. 2007. <span>„Multi-Label Classification: <span>An</span> Overview”</span>. <em>International Journal of Data Warehousing and Mining (IJDWM)</em> 3 (3): 1–13.
</div>
<div id="ref-vazquezMultiOutputSuppportVector2003" class="csl-entry" role="listitem">
Vazquez, Emmanuel, i Eric Walter. 2003. <span>„Multi-Output Suppport Vector Regression”</span>. <em>IFAC Proceedings Volumes</em>, 13th IFAC Symposium on System Identification (SYSID 2003), Rotterdam, The Netherlands, 27-29 August, 2003, 36 (16): 1783–88. <a href="https://doi.org/10.1016/S1474-6670(17)35018-8">https://doi.org/10.1016/S1474-6670(17)35018-8</a>.
</div>
<div id="ref-xuTwinMultiClassClassification2013" class="csl-entry" role="listitem">
Xu, Yitian, Rui Guo, i Laisheng Wang. 2013. <span>„A Twin Multi-Class Classification Support Vector Machine”</span>. <em>Cognitive Computation</em> 5 (4): 580–88. <a href="https://doi.org/10.1007/s12559-012-9179-7">https://doi.org/10.1007/s12559-012-9179-7</a>.
</div>
<div id="ref-zhangGBDTMOGradientBoosted2019" class="csl-entry" role="listitem">
Zhang, Zhendong, i Cheolkon Jung. b.d. <span>„GBDT-MO: Gradient Boosted Decision Trees for Multiple Outputs”</span>. <a href="https://doi.org/10.48550/arXiv.1909.04373">https://doi.org/10.48550/arXiv.1909.04373</a>.
</div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Skopiowano!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Skopiowano!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link  aria-label=" &lt;span="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Wprowadzenie</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./examples.html" class="pagination-link" aria-label="<span class='chapter-number'>3</span>&nbsp; <span class='chapter-title'>Przykłady - metody klasyczne</span>">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Przykłady - metody klasyczne</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Zaawansowane metody uczenia maszynowego, Dariusz Majerek</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/dax44/AMLM/issues/new" class="toc-action"><i class="bi bi-github"></i>Zgłoś problem</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Książka została napisana w <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>